{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larasauser/2024_MLEES/blob/main/Labs/S1_2_Training_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Week 1 Notebook 2 ‚Äì Training Models**\n",
        "\n",
        "This week's notebook is based off of the exercises in Chapter 4 of G√©ron's book."
      ],
      "metadata": {
        "id": "5Tt5C4PoIRl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Setup\n",
        "Let's begin like in the last notebook: importing a few common modules, ensuring MatplotLib plots figures inline and preparing a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so once again we strongly recommend you use Python 3 instead), as well as Scikit-Learn ‚â•0.20.\n",
        "\n",
        "You don't need to worry about understanding everything that is written in this section."
      ],
      "metadata": {
        "id": "666iBNeL8-7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S_OXSp49IOF2"
      },
      "outputs": [],
      "source": [
        "#@title  Run this cell for preliminary requirements. Double click it if you want to check out the source :)\n",
        "\n",
        "# Python ‚â•3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "# Scikit-Learn ‚â•0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To make this notebook's output stable across runs\n",
        "rnd_seed = 42\n",
        "rnd_gen = np.random.default_rng(rnd_seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"classification\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "#Ensure the palmerspenguins dataset is installed\n",
        "%pip install palmerpenguins --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Setup"
      ],
      "metadata": {
        "id": "RtuO7Elb9LuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will be working with the [*Palmer Penguins dataset*](https://allisonhorst.github.io/palmerpenguins/articles/intro.html). Each entry in the dataset includes the penguin's species, island, sex, flipper length, body mass, bill length, bill depth, and the year the study was carried out. Let's take a moment and observe our subjects! <br>\n",
        "\n",
        "<center> <font size=+30>üêß</font><br>\n",
        "In order: Ad√©lie (Pygoscelis adeliae),  Chinstrap (Pygoscelis antarcticus), and Gentoo (Pygoscelis papua) penguins <br>\n",
        "\n",
        "<img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EY2OrrxSOSlIiQZ4FQ719YAB80_joiBs9e58jtlSf4H_eQ?download=1' width=32% >\n",
        "<img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EVuvzIGBs_JGihnUSWBGQ1IBjv-ZtUDUo7cXeWtyx9g6Og?download=1' width=32%></img>\n",
        "<img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EXrZM1rJOXRLlmdPTm-BP2gBCgs1qfQiknp29lX4p_7GtQ?download=1' width=32%></img>\n",
        "\n",
        "</center>\n",
        "\n",
        "As you can imagine, this dataset is normally used to train *multiclass*/*multinomial* classification algorithms and not *binary* classification algorithms, since there *are* more than 2 classes.\n",
        "\n",
        "\"*Three classes, even!*\" - an observant TA\n",
        "\n",
        "For this exercise, however, we will implement the binary classification algorithm referred to as the *logistic regression* algorithm (also called logit regression)."
      ],
      "metadata": {
        "id": "wKsvLXdmzqD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load the Palmer Penguins Dataset!\n",
        "from palmerpenguins import load_penguins\n",
        "data = load_penguins()"
      ],
      "metadata": {
        "id": "emWru72owjEI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like with the Titanic dataset in the previous notebook, the data here is loaded as a Pandas DataFrame. Feel free to play around with it in the cell below!"
      ],
      "metadata": {
        "id": "kbk8zvwOf2-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The following code will make the dataframe be shown in an interactive table\n",
        "# inside of Google colab. Use data.head(5) if you're running this locally\n",
        "\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "AR2NqgIdTcuk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "outputId": "251db10b-e847-4b5f-b8c6-cfd6483bdac2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
              "0       Adelie  Torgersen            39.1           18.7              181.0   \n",
              "1       Adelie  Torgersen            39.5           17.4              186.0   \n",
              "2       Adelie  Torgersen            40.3           18.0              195.0   \n",
              "3       Adelie  Torgersen             NaN            NaN                NaN   \n",
              "4       Adelie  Torgersen            36.7           19.3              193.0   \n",
              "..         ...        ...             ...            ...                ...   \n",
              "339  Chinstrap      Dream            55.8           19.8              207.0   \n",
              "340  Chinstrap      Dream            43.5           18.1              202.0   \n",
              "341  Chinstrap      Dream            49.6           18.2              193.0   \n",
              "342  Chinstrap      Dream            50.8           19.0              210.0   \n",
              "343  Chinstrap      Dream            50.2           18.7              198.0   \n",
              "\n",
              "     body_mass_g     sex  year  \n",
              "0         3750.0    male  2007  \n",
              "1         3800.0  female  2007  \n",
              "2         3250.0  female  2007  \n",
              "3            NaN     NaN  2007  \n",
              "4         3450.0  female  2007  \n",
              "..           ...     ...   ...  \n",
              "339       4000.0    male  2009  \n",
              "340       3400.0  female  2009  \n",
              "341       3775.0    male  2009  \n",
              "342       4100.0    male  2009  \n",
              "343       3775.0  female  2009  \n",
              "\n",
              "[344 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-165a32c8-6b44-4276-bb53-7bf358192d5a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>male</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>Dream</td>\n",
              "      <td>55.8</td>\n",
              "      <td>19.8</td>\n",
              "      <td>207.0</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>male</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>Dream</td>\n",
              "      <td>43.5</td>\n",
              "      <td>18.1</td>\n",
              "      <td>202.0</td>\n",
              "      <td>3400.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>Dream</td>\n",
              "      <td>49.6</td>\n",
              "      <td>18.2</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3775.0</td>\n",
              "      <td>male</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>Dream</td>\n",
              "      <td>50.8</td>\n",
              "      <td>19.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>4100.0</td>\n",
              "      <td>male</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>Dream</td>\n",
              "      <td>50.2</td>\n",
              "      <td>18.7</td>\n",
              "      <td>198.0</td>\n",
              "      <td>3775.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>344 rows √ó 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-165a32c8-6b44-4276-bb53-7bf358192d5a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-165a32c8-6b44-4276-bb53-7bf358192d5a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-165a32c8-6b44-4276-bb53-7bf358192d5a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-726f25bd-16af-431c-9b7c-6cfc5b342fb2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-726f25bd-16af-431c-9b7c-6cfc5b342fb2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-726f25bd-16af-431c-9b7c-6cfc5b342fb2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fa377089-51ae-425f-b600-a80f2f387b4b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fa377089-51ae-425f-b600-a80f2f387b4b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 344,\n  \"fields\": [\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Adelie\",\n          \"Gentoo\",\n          \"Chinstrap\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"island\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Torgersen\",\n          \"Biscoe\",\n          \"Dream\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bill_length_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.4595837139265315,\n        \"min\": 32.1,\n        \"max\": 59.6,\n        \"num_unique_values\": 164,\n        \"samples\": [\n          49.4,\n          43.8,\n          43.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bill_depth_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9747931568167814,\n        \"min\": 13.1,\n        \"max\": 21.5,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          16.9,\n          18.7,\n          18.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flipper_length_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.061713679356888,\n        \"min\": 172.0,\n        \"max\": 231.0,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          201.0,\n          180.0,\n          211.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body_mass_g\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 801.9545356980955,\n        \"min\": 2700.0,\n        \"max\": 6300.0,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          4350.0,\n          4150.0,\n          5700.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2007,\n        \"max\": 2009,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2007,\n          2008\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            },
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/81954c9606dcf997/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.1,\n            'f': \"39.1\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3750.0,\n            'f': \"3750.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.5,\n            'f': \"39.5\",\n        },\n{\n            'v': 17.4,\n            'f': \"17.4\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 40.3,\n            'f': \"40.3\",\n        },\n{\n            'v': 18.0,\n            'f': \"18.0\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3250.0,\n            'f': \"3250.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 36.7,\n            'f': \"36.7\",\n        },\n{\n            'v': 19.3,\n            'f': \"19.3\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.3,\n            'f': \"39.3\",\n        },\n{\n            'v': 20.6,\n            'f': \"20.6\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.9,\n            'f': \"38.9\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3625.0,\n            'f': \"3625.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 7,\n            'f': \"7\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.2,\n            'f': \"39.2\",\n        },\n{\n            'v': 19.6,\n            'f': \"19.6\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4675.0,\n            'f': \"4675.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 8,\n            'f': \"8\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 34.1,\n            'f': \"34.1\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3475.0,\n            'f': \"3475.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 9,\n            'f': \"9\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 42.0,\n            'f': \"42.0\",\n        },\n{\n            'v': 20.2,\n            'f': \"20.2\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 4250.0,\n            'f': \"4250.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 10,\n            'f': \"10\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 37.8,\n            'f': \"37.8\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 11,\n            'f': \"11\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 37.8,\n            'f': \"37.8\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 180.0,\n            'f': \"180.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 12,\n            'f': \"12\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 17.6,\n            'f': \"17.6\",\n        },\n{\n            'v': 182.0,\n            'f': \"182.0\",\n        },\n{\n            'v': 3200.0,\n            'f': \"3200.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 13,\n            'f': \"13\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.6,\n            'f': \"38.6\",\n        },\n{\n            'v': 21.2,\n            'f': \"21.2\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 14,\n            'f': \"14\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 34.6,\n            'f': \"34.6\",\n        },\n{\n            'v': 21.1,\n            'f': \"21.1\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 15,\n            'f': \"15\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 36.6,\n            'f': \"36.6\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 16,\n            'f': \"16\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.7,\n            'f': \"38.7\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 17,\n            'f': \"17\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 42.5,\n            'f': \"42.5\",\n        },\n{\n            'v': 20.7,\n            'f': \"20.7\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 4500.0,\n            'f': \"4500.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 18,\n            'f': \"18\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 34.4,\n            'f': \"34.4\",\n        },\n{\n            'v': 18.4,\n            'f': \"18.4\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 3325.0,\n            'f': \"3325.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 19,\n            'f': \"19\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 46.0,\n            'f': \"46.0\",\n        },\n{\n            'v': 21.5,\n            'f': \"21.5\",\n        },\n{\n            'v': 194.0,\n            'f': \"194.0\",\n        },\n{\n            'v': 4200.0,\n            'f': \"4200.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 20,\n            'f': \"20\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.8,\n            'f': \"37.8\",\n        },\n{\n            'v': 18.3,\n            'f': \"18.3\",\n        },\n{\n            'v': 174.0,\n            'f': \"174.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 21,\n            'f': \"21\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.7,\n            'f': \"37.7\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 180.0,\n            'f': \"180.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 22,\n            'f': \"22\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.9,\n            'f': \"35.9\",\n        },\n{\n            'v': 19.2,\n            'f': \"19.2\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 23,\n            'f': \"23\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.2,\n            'f': \"38.2\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 24,\n            'f': \"24\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.8,\n            'f': \"38.8\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 180.0,\n            'f': \"180.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 25,\n            'f': \"25\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.3,\n            'f': \"35.3\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 26,\n            'f': \"26\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 40.6,\n            'f': \"40.6\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 183.0,\n            'f': \"183.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 27,\n            'f': \"27\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 40.5,\n            'f': \"40.5\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3200.0,\n            'f': \"3200.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 28,\n            'f': \"28\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.9,\n            'f': \"37.9\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 172.0,\n            'f': \"172.0\",\n        },\n{\n            'v': 3150.0,\n            'f': \"3150.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 29,\n            'f': \"29\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 40.5,\n            'f': \"40.5\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 180.0,\n            'f': \"180.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 30,\n            'f': \"30\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.5,\n            'f': \"39.5\",\n        },\n{\n            'v': 16.7,\n            'f': \"16.7\",\n        },\n{\n            'v': 178.0,\n            'f': \"178.0\",\n        },\n{\n            'v': 3250.0,\n            'f': \"3250.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 31,\n            'f': \"31\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.2,\n            'f': \"37.2\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 178.0,\n            'f': \"178.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 32,\n            'f': \"32\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.5,\n            'f': \"39.5\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 33,\n            'f': \"33\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.9,\n            'f': \"40.9\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 34,\n            'f': \"34\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.4,\n            'f': \"36.4\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3325.0,\n            'f': \"3325.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 35,\n            'f': \"35\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.2,\n            'f': \"39.2\",\n        },\n{\n            'v': 21.1,\n            'f': \"21.1\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 36,\n            'f': \"36\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 38.8,\n            'f': \"38.8\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 37,\n            'f': \"37\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 42.2,\n            'f': \"42.2\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 180.0,\n            'f': \"180.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 38,\n            'f': \"38\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.6,\n            'f': \"37.6\",\n        },\n{\n            'v': 19.3,\n            'f': \"19.3\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 39,\n            'f': \"39\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.8,\n            'f': \"39.8\",\n        },\n{\n            'v': 19.1,\n            'f': \"19.1\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 4650.0,\n            'f': \"4650.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 40,\n            'f': \"40\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.5,\n            'f': \"36.5\",\n        },\n{\n            'v': 18.0,\n            'f': \"18.0\",\n        },\n{\n            'v': 182.0,\n            'f': \"182.0\",\n        },\n{\n            'v': 3150.0,\n            'f': \"3150.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 41,\n            'f': \"41\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.8,\n            'f': \"40.8\",\n        },\n{\n            'v': 18.4,\n            'f': \"18.4\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 42,\n            'f': \"42\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.0,\n            'f': \"36.0\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3100.0,\n            'f': \"3100.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 43,\n            'f': \"43\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 44.1,\n            'f': \"44.1\",\n        },\n{\n            'v': 19.7,\n            'f': \"19.7\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 44,\n            'f': \"44\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.0,\n            'f': \"37.0\",\n        },\n{\n            'v': 16.9,\n            'f': \"16.9\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3000.0,\n            'f': \"3000.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 45,\n            'f': \"45\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.6,\n            'f': \"39.6\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 4600.0,\n            'f': \"4600.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 46,\n            'f': \"46\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 182.0,\n            'f': \"182.0\",\n        },\n{\n            'v': 3425.0,\n            'f': \"3425.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 47,\n            'f': \"47\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.5,\n            'f': \"37.5\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 179.0,\n            'f': \"179.0\",\n        },\n{\n            'v': 2975.0,\n            'f': \"2975.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 48,\n            'f': \"48\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.0,\n            'f': \"36.0\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 49,\n            'f': \"49\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 42.3,\n            'f': \"42.3\",\n        },\n{\n            'v': 21.2,\n            'f': \"21.2\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 50,\n            'f': \"50\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 39.6,\n            'f': \"39.6\",\n        },\n{\n            'v': 17.7,\n            'f': \"17.7\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 51,\n            'f': \"51\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 40.1,\n            'f': \"40.1\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 52,\n            'f': \"52\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.0,\n            'f': \"35.0\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 53,\n            'f': \"53\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 42.0,\n            'f': \"42.0\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 200.0,\n            'f': \"200.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 54,\n            'f': \"54\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 34.5,\n            'f': \"34.5\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 2900.0,\n            'f': \"2900.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 55,\n            'f': \"55\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.4,\n            'f': \"41.4\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 56,\n            'f': \"56\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 39.0,\n            'f': \"39.0\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 57,\n            'f': \"57\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 40.6,\n            'f': \"40.6\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 58,\n            'f': \"58\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 36.5,\n            'f': \"36.5\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 2850.0,\n            'f': \"2850.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 59,\n            'f': \"59\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.6,\n            'f': \"37.6\",\n        },\n{\n            'v': 19.1,\n            'f': \"19.1\",\n        },\n{\n            'v': 194.0,\n            'f': \"194.0\",\n        },\n{\n            'v': 3750.0,\n            'f': \"3750.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 60,\n            'f': \"60\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.7,\n            'f': \"35.7\",\n        },\n{\n            'v': 16.9,\n            'f': \"16.9\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3150.0,\n            'f': \"3150.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 61,\n            'f': \"61\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.3,\n            'f': \"41.3\",\n        },\n{\n            'v': 21.1,\n            'f': \"21.1\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 62,\n            'f': \"62\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.6,\n            'f': \"37.6\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 63,\n            'f': \"63\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 18.2,\n            'f': \"18.2\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 64,\n            'f': \"64\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 36.4,\n            'f': \"36.4\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 2850.0,\n            'f': \"2850.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 65,\n            'f': \"65\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.6,\n            'f': \"41.6\",\n        },\n{\n            'v': 18.0,\n            'f': \"18.0\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 66,\n            'f': \"66\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.5,\n            'f': \"35.5\",\n        },\n{\n            'v': 16.2,\n            'f': \"16.2\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3350.0,\n            'f': \"3350.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 67,\n            'f': \"67\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 19.1,\n            'f': \"19.1\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 4100.0,\n            'f': \"4100.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 68,\n            'f': \"68\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 35.9,\n            'f': \"35.9\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3050.0,\n            'f': \"3050.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 69,\n            'f': \"69\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 41.8,\n            'f': \"41.8\",\n        },\n{\n            'v': 19.4,\n            'f': \"19.4\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 4450.0,\n            'f': \"4450.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 70,\n            'f': \"70\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 33.5,\n            'f': \"33.5\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 71,\n            'f': \"71\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.7,\n            'f': \"39.7\",\n        },\n{\n            'v': 18.4,\n            'f': \"18.4\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 72,\n            'f': \"72\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.6,\n            'f': \"39.6\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 73,\n            'f': \"73\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 45.8,\n            'f': \"45.8\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 74,\n            'f': \"74\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 35.5,\n            'f': \"35.5\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 75,\n            'f': \"75\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 42.8,\n            'f': \"42.8\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4250.0,\n            'f': \"4250.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 76,\n            'f': \"76\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 40.9,\n            'f': \"40.9\",\n        },\n{\n            'v': 16.8,\n            'f': \"16.8\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 77,\n            'f': \"77\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 37.2,\n            'f': \"37.2\",\n        },\n{\n            'v': 19.4,\n            'f': \"19.4\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 78,\n            'f': \"78\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 36.2,\n            'f': \"36.2\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 79,\n            'f': \"79\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 42.1,\n            'f': \"42.1\",\n        },\n{\n            'v': 19.1,\n            'f': \"19.1\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4000.0,\n            'f': \"4000.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 80,\n            'f': \"80\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 34.6,\n            'f': \"34.6\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3200.0,\n            'f': \"3200.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 81,\n            'f': \"81\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 42.9,\n            'f': \"42.9\",\n        },\n{\n            'v': 17.6,\n            'f': \"17.6\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 82,\n            'f': \"82\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 36.7,\n            'f': \"36.7\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 83,\n            'f': \"83\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 35.1,\n            'f': \"35.1\",\n        },\n{\n            'v': 19.4,\n            'f': \"19.4\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 4200.0,\n            'f': \"4200.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 84,\n            'f': \"84\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.3,\n            'f': \"37.3\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3350.0,\n            'f': \"3350.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 85,\n            'f': \"85\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 41.3,\n            'f': \"41.3\",\n        },\n{\n            'v': 20.3,\n            'f': \"20.3\",\n        },\n{\n            'v': 194.0,\n            'f': \"194.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 86,\n            'f': \"86\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.3,\n            'f': \"36.3\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 87,\n            'f': \"87\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.9,\n            'f': \"36.9\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 88,\n            'f': \"88\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 38.3,\n            'f': \"38.3\",\n        },\n{\n            'v': 19.2,\n            'f': \"19.2\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 89,\n            'f': \"89\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 38.9,\n            'f': \"38.9\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 90,\n            'f': \"90\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 35.7,\n            'f': \"35.7\",\n        },\n{\n            'v': 18.0,\n            'f': \"18.0\",\n        },\n{\n            'v': 202.0,\n            'f': \"202.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 91,\n            'f': \"91\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 205.0,\n            'f': \"205.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 92,\n            'f': \"92\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 34.0,\n            'f': \"34.0\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 93,\n            'f': \"93\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.6,\n            'f': \"39.6\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 4450.0,\n            'f': \"4450.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 94,\n            'f': \"94\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.2,\n            'f': \"36.2\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 95,\n            'f': \"95\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.8,\n            'f': \"40.8\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 96,\n            'f': \"96\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 38.1,\n            'f': \"38.1\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 97,\n            'f': \"97\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.3,\n            'f': \"40.3\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 4350.0,\n            'f': \"4350.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 98,\n            'f': \"98\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 33.1,\n            'f': \"33.1\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 178.0,\n            'f': \"178.0\",\n        },\n{\n            'v': 2900.0,\n            'f': \"2900.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 99,\n            'f': \"99\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 43.2,\n            'f': \"43.2\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 4100.0,\n            'f': \"4100.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 100,\n            'f': \"100\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.0,\n            'f': \"35.0\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 3725.0,\n            'f': \"3725.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 101,\n            'f': \"101\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.0,\n            'f': \"41.0\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        },\n{\n            'v': 4725.0,\n            'f': \"4725.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 102,\n            'f': \"102\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.7,\n            'f': \"37.7\",\n        },\n{\n            'v': 16.0,\n            'f': \"16.0\",\n        },\n{\n            'v': 183.0,\n            'f': \"183.0\",\n        },\n{\n            'v': 3075.0,\n            'f': \"3075.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 103,\n            'f': \"103\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.8,\n            'f': \"37.8\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 4250.0,\n            'f': \"4250.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 104,\n            'f': \"104\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.9,\n            'f': \"37.9\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 2925.0,\n            'f': \"2925.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 105,\n            'f': \"105\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 39.7,\n            'f': \"39.7\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 106,\n            'f': \"106\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.6,\n            'f': \"38.6\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 3750.0,\n            'f': \"3750.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 107,\n            'f': \"107\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.2,\n            'f': \"38.2\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 108,\n            'f': \"108\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.1,\n            'f': \"38.1\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3175.0,\n            'f': \"3175.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 109,\n            'f': \"109\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 43.2,\n            'f': \"43.2\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 4775.0,\n            'f': \"4775.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 110,\n            'f': \"110\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.1,\n            'f': \"38.1\",\n        },\n{\n            'v': 16.5,\n            'f': \"16.5\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3825.0,\n            'f': \"3825.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 111,\n            'f': \"111\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 45.6,\n            'f': \"45.6\",\n        },\n{\n            'v': 20.3,\n            'f': \"20.3\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 4600.0,\n            'f': \"4600.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 112,\n            'f': \"112\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 39.7,\n            'f': \"39.7\",\n        },\n{\n            'v': 17.7,\n            'f': \"17.7\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3200.0,\n            'f': \"3200.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 113,\n            'f': \"113\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 42.2,\n            'f': \"42.2\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 4275.0,\n            'f': \"4275.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 114,\n            'f': \"114\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 39.6,\n            'f': \"39.6\",\n        },\n{\n            'v': 20.7,\n            'f': \"20.7\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 115,\n            'f': \"115\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 42.7,\n            'f': \"42.7\",\n        },\n{\n            'v': 18.3,\n            'f': \"18.3\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 4075.0,\n            'f': \"4075.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 116,\n            'f': \"116\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.6,\n            'f': \"38.6\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 2900.0,\n            'f': \"2900.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 117,\n            'f': \"117\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 37.3,\n            'f': \"37.3\",\n        },\n{\n            'v': 20.5,\n            'f': \"20.5\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 3775.0,\n            'f': \"3775.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 118,\n            'f': \"118\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 35.7,\n            'f': \"35.7\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3350.0,\n            'f': \"3350.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 119,\n            'f': \"119\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3325.0,\n            'f': \"3325.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 120,\n            'f': \"120\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 36.2,\n            'f': \"36.2\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3150.0,\n            'f': \"3150.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 121,\n            'f': \"121\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 37.7,\n            'f': \"37.7\",\n        },\n{\n            'v': 19.8,\n            'f': \"19.8\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 122,\n            'f': \"122\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 40.2,\n            'f': \"40.2\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 176.0,\n            'f': \"176.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 123,\n            'f': \"123\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 41.4,\n            'f': \"41.4\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 202.0,\n            'f': \"202.0\",\n        },\n{\n            'v': 3875.0,\n            'f': \"3875.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 124,\n            'f': \"124\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 35.2,\n            'f': \"35.2\",\n        },\n{\n            'v': 15.9,\n            'f': \"15.9\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3050.0,\n            'f': \"3050.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 125,\n            'f': \"125\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 40.6,\n            'f': \"40.6\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 4000.0,\n            'f': \"4000.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 126,\n            'f': \"126\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.8,\n            'f': \"38.8\",\n        },\n{\n            'v': 17.6,\n            'f': \"17.6\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3275.0,\n            'f': \"3275.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 127,\n            'f': \"127\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 41.5,\n            'f': \"41.5\",\n        },\n{\n            'v': 18.3,\n            'f': \"18.3\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 128,\n            'f': \"128\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.0,\n            'f': \"39.0\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3050.0,\n            'f': \"3050.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 129,\n            'f': \"129\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 44.1,\n            'f': \"44.1\",\n        },\n{\n            'v': 18.0,\n            'f': \"18.0\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4000.0,\n            'f': \"4000.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 130,\n            'f': \"130\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.5,\n            'f': \"38.5\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3325.0,\n            'f': \"3325.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 131,\n            'f': \"131\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 43.1,\n            'f': \"43.1\",\n        },\n{\n            'v': 19.2,\n            'f': \"19.2\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 132,\n            'f': \"132\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.8,\n            'f': \"36.8\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 133,\n            'f': \"133\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.5,\n            'f': \"37.5\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 4475.0,\n            'f': \"4475.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 134,\n            'f': \"134\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 38.1,\n            'f': \"38.1\",\n        },\n{\n            'v': 17.6,\n            'f': \"17.6\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3425.0,\n            'f': \"3425.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 135,\n            'f': \"135\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 136,\n            'f': \"136\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 35.6,\n            'f': \"35.6\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3175.0,\n            'f': \"3175.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 137,\n            'f': \"137\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.2,\n            'f': \"40.2\",\n        },\n{\n            'v': 20.1,\n            'f': \"20.1\",\n        },\n{\n            'v': 200.0,\n            'f': \"200.0\",\n        },\n{\n            'v': 3975.0,\n            'f': \"3975.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 138,\n            'f': \"138\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.0,\n            'f': \"37.0\",\n        },\n{\n            'v': 16.5,\n            'f': \"16.5\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 139,\n            'f': \"139\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.7,\n            'f': \"39.7\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 4250.0,\n            'f': \"4250.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 140,\n            'f': \"140\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.2,\n            'f': \"40.2\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 141,\n            'f': \"141\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.6,\n            'f': \"40.6\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3475.0,\n            'f': \"3475.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 142,\n            'f': \"142\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 32.1,\n            'f': \"32.1\",\n        },\n{\n            'v': 15.5,\n            'f': \"15.5\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 3050.0,\n            'f': \"3050.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 143,\n            'f': \"143\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.7,\n            'f': \"40.7\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3725.0,\n            'f': \"3725.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 144,\n            'f': \"144\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.3,\n            'f': \"37.3\",\n        },\n{\n            'v': 16.8,\n            'f': \"16.8\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 3000.0,\n            'f': \"3000.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 145,\n            'f': \"145\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.0,\n            'f': \"39.0\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 146,\n            'f': \"146\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.2,\n            'f': \"39.2\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 4250.0,\n            'f': \"4250.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 147,\n            'f': \"147\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.6,\n            'f': \"36.6\",\n        },\n{\n            'v': 18.4,\n            'f': \"18.4\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 3475.0,\n            'f': \"3475.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 148,\n            'f': \"148\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.0,\n            'f': \"36.0\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 149,\n            'f': \"149\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.8,\n            'f': \"37.8\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3750.0,\n            'f': \"3750.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 150,\n            'f': \"150\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.0,\n            'f': \"36.0\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 151,\n            'f': \"151\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 41.5,\n            'f': \"41.5\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 4000.0,\n            'f': \"4000.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 152,\n            'f': \"152\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.1,\n            'f': \"46.1\",\n        },\n{\n            'v': 13.2,\n            'f': \"13.2\",\n        },\n{\n            'v': 211.0,\n            'f': \"211.0\",\n        },\n{\n            'v': 4500.0,\n            'f': \"4500.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 153,\n            'f': \"153\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.0,\n            'f': \"50.0\",\n        },\n{\n            'v': 16.3,\n            'f': \"16.3\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5700.0,\n            'f': \"5700.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 154,\n            'f': \"154\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.7,\n            'f': \"48.7\",\n        },\n{\n            'v': 14.1,\n            'f': \"14.1\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4450.0,\n            'f': \"4450.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 155,\n            'f': \"155\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.0,\n            'f': \"50.0\",\n        },\n{\n            'v': 15.2,\n            'f': \"15.2\",\n        },\n{\n            'v': 218.0,\n            'f': \"218.0\",\n        },\n{\n            'v': 5700.0,\n            'f': \"5700.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 156,\n            'f': \"156\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.6,\n            'f': \"47.6\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5400.0,\n            'f': \"5400.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 157,\n            'f': \"157\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.5,\n            'f': \"46.5\",\n        },\n{\n            'v': 13.5,\n            'f': \"13.5\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4550.0,\n            'f': \"4550.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 158,\n            'f': \"158\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.4,\n            'f': \"45.4\",\n        },\n{\n            'v': 14.6,\n            'f': \"14.6\",\n        },\n{\n            'v': 211.0,\n            'f': \"211.0\",\n        },\n{\n            'v': 4800.0,\n            'f': \"4800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 159,\n            'f': \"159\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.7,\n            'f': \"46.7\",\n        },\n{\n            'v': 15.3,\n            'f': \"15.3\",\n        },\n{\n            'v': 219.0,\n            'f': \"219.0\",\n        },\n{\n            'v': 5200.0,\n            'f': \"5200.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 160,\n            'f': \"160\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.3,\n            'f': \"43.3\",\n        },\n{\n            'v': 13.4,\n            'f': \"13.4\",\n        },\n{\n            'v': 209.0,\n            'f': \"209.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 161,\n            'f': \"161\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.8,\n            'f': \"46.8\",\n        },\n{\n            'v': 15.4,\n            'f': \"15.4\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5150.0,\n            'f': \"5150.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 162,\n            'f': \"162\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 40.9,\n            'f': \"40.9\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4650.0,\n            'f': \"4650.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 163,\n            'f': \"163\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.0,\n            'f': \"49.0\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 164,\n            'f': \"164\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.5,\n            'f': \"45.5\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4650.0,\n            'f': \"4650.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 165,\n            'f': \"165\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.4,\n            'f': \"48.4\",\n        },\n{\n            'v': 14.6,\n            'f': \"14.6\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 5850.0,\n            'f': \"5850.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 166,\n            'f': \"166\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.8,\n            'f': \"45.8\",\n        },\n{\n            'v': 14.6,\n            'f': \"14.6\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4200.0,\n            'f': \"4200.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 167,\n            'f': \"167\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.3,\n            'f': \"49.3\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 5850.0,\n            'f': \"5850.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 168,\n            'f': \"168\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 42.0,\n            'f': \"42.0\",\n        },\n{\n            'v': 13.5,\n            'f': \"13.5\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 169,\n            'f': \"169\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.2,\n            'f': \"49.2\",\n        },\n{\n            'v': 15.2,\n            'f': \"15.2\",\n        },\n{\n            'v': 221.0,\n            'f': \"221.0\",\n        },\n{\n            'v': 6300.0,\n            'f': \"6300.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 170,\n            'f': \"170\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.2,\n            'f': \"46.2\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 209.0,\n            'f': \"209.0\",\n        },\n{\n            'v': 4800.0,\n            'f': \"4800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 171,\n            'f': \"171\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.7,\n            'f': \"48.7\",\n        },\n{\n            'v': 15.1,\n            'f': \"15.1\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 5350.0,\n            'f': \"5350.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 172,\n            'f': \"172\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.2,\n            'f': \"50.2\",\n        },\n{\n            'v': 14.3,\n            'f': \"14.3\",\n        },\n{\n            'v': 218.0,\n            'f': \"218.0\",\n        },\n{\n            'v': 5700.0,\n            'f': \"5700.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 173,\n            'f': \"173\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.1,\n            'f': \"45.1\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 174,\n            'f': \"174\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.5,\n            'f': \"46.5\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 175,\n            'f': \"175\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.3,\n            'f': \"46.3\",\n        },\n{\n            'v': 15.8,\n            'f': \"15.8\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5050.0,\n            'f': \"5050.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 176,\n            'f': \"176\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 42.9,\n            'f': \"42.9\",\n        },\n{\n            'v': 13.1,\n            'f': \"13.1\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 177,\n            'f': \"177\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.1,\n            'f': \"46.1\",\n        },\n{\n            'v': 15.1,\n            'f': \"15.1\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5100.0,\n            'f': \"5100.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 178,\n            'f': \"178\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.5,\n            'f': \"44.5\",\n        },\n{\n            'v': 14.3,\n            'f': \"14.3\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4100.0,\n            'f': \"4100.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 179,\n            'f': \"179\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.8,\n            'f': \"47.8\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5650.0,\n            'f': \"5650.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 180,\n            'f': \"180\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.2,\n            'f': \"48.2\",\n        },\n{\n            'v': 14.3,\n            'f': \"14.3\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4600.0,\n            'f': \"4600.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 181,\n            'f': \"181\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.0,\n            'f': \"50.0\",\n        },\n{\n            'v': 15.3,\n            'f': \"15.3\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 182,\n            'f': \"182\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.3,\n            'f': \"47.3\",\n        },\n{\n            'v': 15.3,\n            'f': \"15.3\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 5250.0,\n            'f': \"5250.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 183,\n            'f': \"183\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 42.8,\n            'f': \"42.8\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 209.0,\n            'f': \"209.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 184,\n            'f': \"184\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.1,\n            'f': \"45.1\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 207.0,\n            'f': \"207.0\",\n        },\n{\n            'v': 5050.0,\n            'f': \"5050.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 185,\n            'f': \"185\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 59.6,\n            'f': \"59.6\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 6050.0,\n            'f': \"6050.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 186,\n            'f': \"186\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.1,\n            'f': \"49.1\",\n        },\n{\n            'v': 14.8,\n            'f': \"14.8\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5150.0,\n            'f': \"5150.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 187,\n            'f': \"187\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.4,\n            'f': \"48.4\",\n        },\n{\n            'v': 16.3,\n            'f': \"16.3\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5400.0,\n            'f': \"5400.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 188,\n            'f': \"188\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 42.6,\n            'f': \"42.6\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 4950.0,\n            'f': \"4950.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 189,\n            'f': \"189\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.4,\n            'f': \"44.4\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 219.0,\n            'f': \"219.0\",\n        },\n{\n            'v': 5250.0,\n            'f': \"5250.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 190,\n            'f': \"190\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.0,\n            'f': \"44.0\",\n        },\n{\n            'v': 13.6,\n            'f': \"13.6\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4350.0,\n            'f': \"4350.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 191,\n            'f': \"191\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.7,\n            'f': \"48.7\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 5350.0,\n            'f': \"5350.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 192,\n            'f': \"192\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 42.7,\n            'f': \"42.7\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 193,\n            'f': \"193\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.6,\n            'f': \"49.6\",\n        },\n{\n            'v': 16.0,\n            'f': \"16.0\",\n        },\n{\n            'v': 225.0,\n            'f': \"225.0\",\n        },\n{\n            'v': 5700.0,\n            'f': \"5700.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 194,\n            'f': \"194\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.3,\n            'f': \"45.3\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 195,\n            'f': \"195\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.6,\n            'f': \"49.6\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4750.0,\n            'f': \"4750.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 196,\n            'f': \"196\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.5,\n            'f': \"50.5\",\n        },\n{\n            'v': 15.9,\n            'f': \"15.9\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 197,\n            'f': \"197\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.6,\n            'f': \"43.6\",\n        },\n{\n            'v': 13.9,\n            'f': \"13.9\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 4900.0,\n            'f': \"4900.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 198,\n            'f': \"198\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.5,\n            'f': \"45.5\",\n        },\n{\n            'v': 13.9,\n            'f': \"13.9\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4200.0,\n            'f': \"4200.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 199,\n            'f': \"199\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.5,\n            'f': \"50.5\",\n        },\n{\n            'v': 15.9,\n            'f': \"15.9\",\n        },\n{\n            'v': 225.0,\n            'f': \"225.0\",\n        },\n{\n            'v': 5400.0,\n            'f': \"5400.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 200,\n            'f': \"200\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.9,\n            'f': \"44.9\",\n        },\n{\n            'v': 13.3,\n            'f': \"13.3\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 5100.0,\n            'f': \"5100.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 201,\n            'f': \"201\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 15.8,\n            'f': \"15.8\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5300.0,\n            'f': \"5300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 202,\n            'f': \"202\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.6,\n            'f': \"46.6\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4850.0,\n            'f': \"4850.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 203,\n            'f': \"203\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.5,\n            'f': \"48.5\",\n        },\n{\n            'v': 14.1,\n            'f': \"14.1\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5300.0,\n            'f': \"5300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 204,\n            'f': \"204\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.1,\n            'f': \"45.1\",\n        },\n{\n            'v': 14.4,\n            'f': \"14.4\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 205,\n            'f': \"205\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.1,\n            'f': \"50.1\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 225.0,\n            'f': \"225.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 206,\n            'f': \"206\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.5,\n            'f': \"46.5\",\n        },\n{\n            'v': 14.4,\n            'f': \"14.4\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 4900.0,\n            'f': \"4900.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 207,\n            'f': \"207\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.0,\n            'f': \"45.0\",\n        },\n{\n            'v': 15.4,\n            'f': \"15.4\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5050.0,\n            'f': \"5050.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 208,\n            'f': \"208\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.8,\n            'f': \"43.8\",\n        },\n{\n            'v': 13.9,\n            'f': \"13.9\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 209,\n            'f': \"209\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.5,\n            'f': \"45.5\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 210,\n            'f': \"210\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.2,\n            'f': \"43.2\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4450.0,\n            'f': \"4450.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 211,\n            'f': \"211\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.4,\n            'f': \"50.4\",\n        },\n{\n            'v': 15.3,\n            'f': \"15.3\",\n        },\n{\n            'v': 224.0,\n            'f': \"224.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 212,\n            'f': \"212\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.3,\n            'f': \"45.3\",\n        },\n{\n            'v': 13.8,\n            'f': \"13.8\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4200.0,\n            'f': \"4200.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 213,\n            'f': \"213\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.2,\n            'f': \"46.2\",\n        },\n{\n            'v': 14.9,\n            'f': \"14.9\",\n        },\n{\n            'v': 221.0,\n            'f': \"221.0\",\n        },\n{\n            'v': 5300.0,\n            'f': \"5300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 214,\n            'f': \"214\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.7,\n            'f': \"45.7\",\n        },\n{\n            'v': 13.9,\n            'f': \"13.9\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 215,\n            'f': \"215\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 54.3,\n            'f': \"54.3\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 231.0,\n            'f': \"231.0\",\n        },\n{\n            'v': 5650.0,\n            'f': \"5650.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 216,\n            'f': \"216\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.8,\n            'f': \"45.8\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 219.0,\n            'f': \"219.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 217,\n            'f': \"217\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.8,\n            'f': \"49.8\",\n        },\n{\n            'v': 16.8,\n            'f': \"16.8\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5700.0,\n            'f': \"5700.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 218,\n            'f': \"218\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.2,\n            'f': \"46.2\",\n        },\n{\n            'v': 14.4,\n            'f': \"14.4\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4650.0,\n            'f': \"4650.0\",\n        },\nNaN,\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 219,\n            'f': \"219\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.5,\n            'f': \"49.5\",\n        },\n{\n            'v': 16.2,\n            'f': \"16.2\",\n        },\n{\n            'v': 229.0,\n            'f': \"229.0\",\n        },\n{\n            'v': 5800.0,\n            'f': \"5800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 220,\n            'f': \"220\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.5,\n            'f': \"43.5\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 221,\n            'f': \"221\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.7,\n            'f': \"50.7\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 223.0,\n            'f': \"223.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 222,\n            'f': \"222\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.7,\n            'f': \"47.7\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4750.0,\n            'f': \"4750.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 223,\n            'f': \"223\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.4,\n            'f': \"46.4\",\n        },\n{\n            'v': 15.6,\n            'f': \"15.6\",\n        },\n{\n            'v': 221.0,\n            'f': \"221.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 224,\n            'f': \"224\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.2,\n            'f': \"48.2\",\n        },\n{\n            'v': 15.6,\n            'f': \"15.6\",\n        },\n{\n            'v': 221.0,\n            'f': \"221.0\",\n        },\n{\n            'v': 5100.0,\n            'f': \"5100.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 225,\n            'f': \"225\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.5,\n            'f': \"46.5\",\n        },\n{\n            'v': 14.8,\n            'f': \"14.8\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 5200.0,\n            'f': \"5200.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 226,\n            'f': \"226\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.4,\n            'f': \"46.4\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 227,\n            'f': \"227\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.6,\n            'f': \"48.6\",\n        },\n{\n            'v': 16.0,\n            'f': \"16.0\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5800.0,\n            'f': \"5800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 228,\n            'f': \"228\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.5,\n            'f': \"47.5\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 209.0,\n            'f': \"209.0\",\n        },\n{\n            'v': 4600.0,\n            'f': \"4600.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 229,\n            'f': \"229\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 51.1,\n            'f': \"51.1\",\n        },\n{\n            'v': 16.3,\n            'f': \"16.3\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 6000.0,\n            'f': \"6000.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 230,\n            'f': \"230\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 13.8,\n            'f': \"13.8\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 4750.0,\n            'f': \"4750.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 231,\n            'f': \"231\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 16.4,\n            'f': \"16.4\",\n        },\n{\n            'v': 223.0,\n            'f': \"223.0\",\n        },\n{\n            'v': 5950.0,\n            'f': \"5950.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 232,\n            'f': \"232\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.1,\n            'f': \"49.1\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4625.0,\n            'f': \"4625.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 233,\n            'f': \"233\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 52.5,\n            'f': \"52.5\",\n        },\n{\n            'v': 15.6,\n            'f': \"15.6\",\n        },\n{\n            'v': 221.0,\n            'f': \"221.0\",\n        },\n{\n            'v': 5450.0,\n            'f': \"5450.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 234,\n            'f': \"234\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.4,\n            'f': \"47.4\",\n        },\n{\n            'v': 14.6,\n            'f': \"14.6\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4725.0,\n            'f': \"4725.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 235,\n            'f': \"235\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.0,\n            'f': \"50.0\",\n        },\n{\n            'v': 15.9,\n            'f': \"15.9\",\n        },\n{\n            'v': 224.0,\n            'f': \"224.0\",\n        },\n{\n            'v': 5350.0,\n            'f': \"5350.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 236,\n            'f': \"236\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.9,\n            'f': \"44.9\",\n        },\n{\n            'v': 13.8,\n            'f': \"13.8\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4750.0,\n            'f': \"4750.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 237,\n            'f': \"237\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.8,\n            'f': \"50.8\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 228.0,\n            'f': \"228.0\",\n        },\n{\n            'v': 5600.0,\n            'f': \"5600.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 238,\n            'f': \"238\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.4,\n            'f': \"43.4\",\n        },\n{\n            'v': 14.4,\n            'f': \"14.4\",\n        },\n{\n            'v': 218.0,\n            'f': \"218.0\",\n        },\n{\n            'v': 4600.0,\n            'f': \"4600.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 239,\n            'f': \"239\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 51.3,\n            'f': \"51.3\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 218.0,\n            'f': \"218.0\",\n        },\n{\n            'v': 5300.0,\n            'f': \"5300.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 240,\n            'f': \"240\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.5,\n            'f': \"47.5\",\n        },\n{\n            'v': 14.0,\n            'f': \"14.0\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4875.0,\n            'f': \"4875.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 241,\n            'f': \"241\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 52.1,\n            'f': \"52.1\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 242,\n            'f': \"242\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.5,\n            'f': \"47.5\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 218.0,\n            'f': \"218.0\",\n        },\n{\n            'v': 4950.0,\n            'f': \"4950.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 243,\n            'f': \"243\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 52.2,\n            'f': \"52.2\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 228.0,\n            'f': \"228.0\",\n        },\n{\n            'v': 5400.0,\n            'f': \"5400.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 244,\n            'f': \"244\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.5,\n            'f': \"45.5\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4750.0,\n            'f': \"4750.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 245,\n            'f': \"245\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.5,\n            'f': \"49.5\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 224.0,\n            'f': \"224.0\",\n        },\n{\n            'v': 5650.0,\n            'f': \"5650.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 246,\n            'f': \"246\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.5,\n            'f': \"44.5\",\n        },\n{\n            'v': 14.7,\n            'f': \"14.7\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4850.0,\n            'f': \"4850.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 247,\n            'f': \"247\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.8,\n            'f': \"50.8\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 226.0,\n            'f': \"226.0\",\n        },\n{\n            'v': 5200.0,\n            'f': \"5200.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 248,\n            'f': \"248\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.4,\n            'f': \"49.4\",\n        },\n{\n            'v': 15.8,\n            'f': \"15.8\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4925.0,\n            'f': \"4925.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 249,\n            'f': \"249\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.9,\n            'f': \"46.9\",\n        },\n{\n            'v': 14.6,\n            'f': \"14.6\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 4875.0,\n            'f': \"4875.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 250,\n            'f': \"250\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.4,\n            'f': \"48.4\",\n        },\n{\n            'v': 14.4,\n            'f': \"14.4\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        },\n{\n            'v': 4625.0,\n            'f': \"4625.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 251,\n            'f': \"251\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 51.1,\n            'f': \"51.1\",\n        },\n{\n            'v': 16.5,\n            'f': \"16.5\",\n        },\n{\n            'v': 225.0,\n            'f': \"225.0\",\n        },\n{\n            'v': 5250.0,\n            'f': \"5250.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 252,\n            'f': \"252\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.5,\n            'f': \"48.5\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 219.0,\n            'f': \"219.0\",\n        },\n{\n            'v': 4850.0,\n            'f': \"4850.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 253,\n            'f': \"253\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 55.9,\n            'f': \"55.9\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 228.0,\n            'f': \"228.0\",\n        },\n{\n            'v': 5600.0,\n            'f': \"5600.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 254,\n            'f': \"254\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.2,\n            'f': \"47.2\",\n        },\n{\n            'v': 15.5,\n            'f': \"15.5\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 4975.0,\n            'f': \"4975.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 255,\n            'f': \"255\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.1,\n            'f': \"49.1\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 228.0,\n            'f': \"228.0\",\n        },\n{\n            'v': 5500.0,\n            'f': \"5500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 256,\n            'f': \"256\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.3,\n            'f': \"47.3\",\n        },\n{\n            'v': 13.8,\n            'f': \"13.8\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4725.0,\n            'f': \"4725.0\",\n        },\nNaN,\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 257,\n            'f': \"257\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.8,\n            'f': \"46.8\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5500.0,\n            'f': \"5500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 258,\n            'f': \"258\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 41.7,\n            'f': \"41.7\",\n        },\n{\n            'v': 14.7,\n            'f': \"14.7\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 259,\n            'f': \"259\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 53.4,\n            'f': \"53.4\",\n        },\n{\n            'v': 15.8,\n            'f': \"15.8\",\n        },\n{\n            'v': 219.0,\n            'f': \"219.0\",\n        },\n{\n            'v': 5500.0,\n            'f': \"5500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 260,\n            'f': \"260\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.3,\n            'f': \"43.3\",\n        },\n{\n            'v': 14.0,\n            'f': \"14.0\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4575.0,\n            'f': \"4575.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 261,\n            'f': \"261\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.1,\n            'f': \"48.1\",\n        },\n{\n            'v': 15.1,\n            'f': \"15.1\",\n        },\n{\n            'v': 209.0,\n            'f': \"209.0\",\n        },\n{\n            'v': 5500.0,\n            'f': \"5500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 262,\n            'f': \"262\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.5,\n            'f': \"50.5\",\n        },\n{\n            'v': 15.2,\n            'f': \"15.2\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 263,\n            'f': \"263\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.8,\n            'f': \"49.8\",\n        },\n{\n            'v': 15.9,\n            'f': \"15.9\",\n        },\n{\n            'v': 229.0,\n            'f': \"229.0\",\n        },\n{\n            'v': 5950.0,\n            'f': \"5950.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 264,\n            'f': \"264\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.5,\n            'f': \"43.5\",\n        },\n{\n            'v': 15.2,\n            'f': \"15.2\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 4650.0,\n            'f': \"4650.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 265,\n            'f': \"265\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 51.5,\n            'f': \"51.5\",\n        },\n{\n            'v': 16.3,\n            'f': \"16.3\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5500.0,\n            'f': \"5500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 266,\n            'f': \"266\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.2,\n            'f': \"46.2\",\n        },\n{\n            'v': 14.1,\n            'f': \"14.1\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 4375.0,\n            'f': \"4375.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 267,\n            'f': \"267\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 55.1,\n            'f': \"55.1\",\n        },\n{\n            'v': 16.0,\n            'f': \"16.0\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5850.0,\n            'f': \"5850.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 268,\n            'f': \"268\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.5,\n            'f': \"44.5\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 4875.0,\n            'f': \"4875.0\",\n        },\nNaN,\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 269,\n            'f': \"269\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.8,\n            'f': \"48.8\",\n        },\n{\n            'v': 16.2,\n            'f': \"16.2\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 6000.0,\n            'f': \"6000.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 270,\n            'f': \"270\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.2,\n            'f': \"47.2\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4925.0,\n            'f': \"4925.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 271,\n            'f': \"271\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\nNaN,\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 272,\n            'f': \"272\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.8,\n            'f': \"46.8\",\n        },\n{\n            'v': 14.3,\n            'f': \"14.3\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 4850.0,\n            'f': \"4850.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 273,\n            'f': \"273\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.4,\n            'f': \"50.4\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 5750.0,\n            'f': \"5750.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 274,\n            'f': \"274\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 14.8,\n            'f': \"14.8\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 5200.0,\n            'f': \"5200.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 275,\n            'f': \"275\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.9,\n            'f': \"49.9\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 5400.0,\n            'f': \"5400.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 276,\n            'f': \"276\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.5,\n            'f': \"46.5\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 277,\n            'f': \"277\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.0,\n            'f': \"50.0\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 278,\n            'f': \"278\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.3,\n            'f': \"51.3\",\n        },\n{\n            'v': 19.2,\n            'f': \"19.2\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 279,\n            'f': \"279\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.4,\n            'f': \"45.4\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 3525.0,\n            'f': \"3525.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 280,\n            'f': \"280\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.7,\n            'f': \"52.7\",\n        },\n{\n            'v': 19.8,\n            'f': \"19.8\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 3725.0,\n            'f': \"3725.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 281,\n            'f': \"281\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 282,\n            'f': \"282\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.1,\n            'f': \"46.1\",\n        },\n{\n            'v': 18.2,\n            'f': \"18.2\",\n        },\n{\n            'v': 178.0,\n            'f': \"178.0\",\n        },\n{\n            'v': 3250.0,\n            'f': \"3250.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 283,\n            'f': \"283\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.3,\n            'f': \"51.3\",\n        },\n{\n            'v': 18.2,\n            'f': \"18.2\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 3750.0,\n            'f': \"3750.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 284,\n            'f': \"284\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.0,\n            'f': \"46.0\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 285,\n            'f': \"285\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.3,\n            'f': \"51.3\",\n        },\n{\n            'v': 19.9,\n            'f': \"19.9\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 286,\n            'f': \"286\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.6,\n            'f': \"46.6\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 287,\n            'f': \"287\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.7,\n            'f': \"51.7\",\n        },\n{\n            'v': 20.3,\n            'f': \"20.3\",\n        },\n{\n            'v': 194.0,\n            'f': \"194.0\",\n        },\n{\n            'v': 3775.0,\n            'f': \"3775.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 288,\n            'f': \"288\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 47.0,\n            'f': \"47.0\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 289,\n            'f': \"289\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.0,\n            'f': \"52.0\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 290,\n            'f': \"290\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.9,\n            'f': \"45.9\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3575.0,\n            'f': \"3575.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 291,\n            'f': \"291\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.5,\n            'f': \"50.5\",\n        },\n{\n            'v': 19.6,\n            'f': \"19.6\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 292,\n            'f': \"292\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.3,\n            'f': \"50.3\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 293,\n            'f': \"293\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 58.0,\n            'f': \"58.0\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 294,\n            'f': \"294\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.4,\n            'f': \"46.4\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 295,\n            'f': \"295\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.2,\n            'f': \"49.2\",\n        },\n{\n            'v': 18.2,\n            'f': \"18.2\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 296,\n            'f': \"296\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 42.4,\n            'f': \"42.4\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 297,\n            'f': \"297\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 48.5,\n            'f': \"48.5\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 298,\n            'f': \"298\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 43.2,\n            'f': \"43.2\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 2900.0,\n            'f': \"2900.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 299,\n            'f': \"299\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.6,\n            'f': \"50.6\",\n        },\n{\n            'v': 19.4,\n            'f': \"19.4\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 300,\n            'f': \"300\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.7,\n            'f': \"46.7\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 301,\n            'f': \"301\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.0,\n            'f': \"52.0\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 302,\n            'f': \"302\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.5,\n            'f': \"50.5\",\n        },\n{\n            'v': 18.4,\n            'f': \"18.4\",\n        },\n{\n            'v': 200.0,\n            'f': \"200.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 303,\n            'f': \"303\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.5,\n            'f': \"49.5\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 200.0,\n            'f': \"200.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 304,\n            'f': \"304\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.4,\n            'f': \"46.4\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 305,\n            'f': \"305\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.8,\n            'f': \"52.8\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 205.0,\n            'f': \"205.0\",\n        },\n{\n            'v': 4550.0,\n            'f': \"4550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 306,\n            'f': \"306\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 40.9,\n            'f': \"40.9\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3200.0,\n            'f': \"3200.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 307,\n            'f': \"307\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 54.2,\n            'f': \"54.2\",\n        },\n{\n            'v': 20.8,\n            'f': \"20.8\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 308,\n            'f': \"308\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 42.5,\n            'f': \"42.5\",\n        },\n{\n            'v': 16.7,\n            'f': \"16.7\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3350.0,\n            'f': \"3350.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 309,\n            'f': \"309\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.0,\n            'f': \"51.0\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        },\n{\n            'v': 4100.0,\n            'f': \"4100.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 310,\n            'f': \"310\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.7,\n            'f': \"49.7\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 311,\n            'f': \"311\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 47.5,\n            'f': \"47.5\",\n        },\n{\n            'v': 16.8,\n            'f': \"16.8\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 312,\n            'f': \"312\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 47.6,\n            'f': \"47.6\",\n        },\n{\n            'v': 18.3,\n            'f': \"18.3\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3850.0,\n            'f': \"3850.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 313,\n            'f': \"313\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.0,\n            'f': \"52.0\",\n        },\n{\n            'v': 20.7,\n            'f': \"20.7\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4800.0,\n            'f': \"4800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 314,\n            'f': \"314\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.9,\n            'f': \"46.9\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 2700.0,\n            'f': \"2700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 315,\n            'f': \"315\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 53.5,\n            'f': \"53.5\",\n        },\n{\n            'v': 19.9,\n            'f': \"19.9\",\n        },\n{\n            'v': 205.0,\n            'f': \"205.0\",\n        },\n{\n            'v': 4500.0,\n            'f': \"4500.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 316,\n            'f': \"316\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.0,\n            'f': \"49.0\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 317,\n            'f': \"317\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.2,\n            'f': \"46.2\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 318,\n            'f': \"318\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.9,\n            'f': \"50.9\",\n        },\n{\n            'v': 19.1,\n            'f': \"19.1\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 319,\n            'f': \"319\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.5,\n            'f': \"45.5\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 320,\n            'f': \"320\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.9,\n            'f': \"50.9\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 3675.0,\n            'f': \"3675.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 321,\n            'f': \"321\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.8,\n            'f': \"50.8\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 4450.0,\n            'f': \"4450.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 322,\n            'f': \"322\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.1,\n            'f': \"50.1\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 323,\n            'f': \"323\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.0,\n            'f': \"49.0\",\n        },\n{\n            'v': 19.6,\n            'f': \"19.6\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 324,\n            'f': \"324\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.5,\n            'f': \"51.5\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3250.0,\n            'f': \"3250.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 325,\n            'f': \"325\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.8,\n            'f': \"49.8\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3675.0,\n            'f': \"3675.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 326,\n            'f': \"326\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 48.1,\n            'f': \"48.1\",\n        },\n{\n            'v': 16.4,\n            'f': \"16.4\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 3325.0,\n            'f': \"3325.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 327,\n            'f': \"327\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.4,\n            'f': \"51.4\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 328,\n            'f': \"328\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.7,\n            'f': \"45.7\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 329,\n            'f': \"329\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.7,\n            'f': \"50.7\",\n        },\n{\n            'v': 19.7,\n            'f': \"19.7\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 330,\n            'f': \"330\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 42.5,\n            'f': \"42.5\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3350.0,\n            'f': \"3350.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 331,\n            'f': \"331\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.2,\n            'f': \"52.2\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 332,\n            'f': \"332\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3250.0,\n            'f': \"3250.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 333,\n            'f': \"333\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.3,\n            'f': \"49.3\",\n        },\n{\n            'v': 19.9,\n            'f': \"19.9\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 334,\n            'f': \"334\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.2,\n            'f': \"50.2\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 202.0,\n            'f': \"202.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 335,\n            'f': \"335\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.6,\n            'f': \"45.6\",\n        },\n{\n            'v': 19.4,\n            'f': \"19.4\",\n        },\n{\n            'v': 194.0,\n            'f': \"194.0\",\n        },\n{\n            'v': 3525.0,\n            'f': \"3525.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 336,\n            'f': \"336\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.9,\n            'f': \"51.9\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 206.0,\n            'f': \"206.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 337,\n            'f': \"337\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.8,\n            'f': \"46.8\",\n        },\n{\n            'v': 16.5,\n            'f': \"16.5\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 338,\n            'f': \"338\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.7,\n            'f': \"45.7\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 339,\n            'f': \"339\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 55.8,\n            'f': \"55.8\",\n        },\n{\n            'v': 19.8,\n            'f': \"19.8\",\n        },\n{\n            'v': 207.0,\n            'f': \"207.0\",\n        },\n{\n            'v': 4000.0,\n            'f': \"4000.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 340,\n            'f': \"340\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 43.5,\n            'f': \"43.5\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 202.0,\n            'f': \"202.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 341,\n            'f': \"341\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.6,\n            'f': \"49.6\",\n        },\n{\n            'v': 18.2,\n            'f': \"18.2\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3775.0,\n            'f': \"3775.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 342,\n            'f': \"342\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.8,\n            'f': \"50.8\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4100.0,\n            'f': \"4100.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 343,\n            'f': \"343\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.2,\n            'f': \"50.2\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3775.0,\n            'f': \"3775.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"species\"], [\"string\", \"island\"], [\"number\", \"bill_length_mm\"], [\"number\", \"bill_depth_mm\"], [\"number\", \"flipper_length_mm\"], [\"number\", \"body_mass_g\"], [\"string\", \"sex\"], [\"number\", \"year\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-4212e770-2219-48d6-8dd4-eb79b784773f\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4212e770-2219-48d6-8dd4-eb79b784773f')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-4212e770-2219-48d6-8dd4-eb79b784773f button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    "
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we mentioned before, there are three species of penguin in the dataset. However, today we'll be implementing a _binary classification algorithm_, which means we need to have exactly two target classes! Let's go ahead and filter the data so that we keep the Adelie and Gentoo species."
      ],
      "metadata": {
        "id": "nDFjkxZE1BA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define the species that we're interested in\n",
        "species = ['Adelie','Gentoo']\n",
        "\n",
        "# And use the .loc method in Pandas to keep only the two species mentioned above\n",
        "data = data.loc[data['species'].isin(species)]"
      ],
      "metadata": {
        "id": "kTUHBGUT1dTY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Today, we'll be learning to classify the penguins based on the length and depth of their bills.  Run the cell and take a look at the data! üîé\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# Dimensions for interactive plot\n",
        "dims = ['bill_length_mm', 'bill_depth_mm']\n",
        "colors = ['orange','black','lightseagreen']\n",
        "\n",
        "fig = px.scatter_matrix(\n",
        "                        data,\n",
        "                        dimensions=dims,\n",
        "                        color=\"species\",\n",
        "                        color_discrete_sequence = colors\n",
        "                        )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "fa4m4iPxgpu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "d7eb623b-2cb6-49ef-c36e-5c50088b0694"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a884ede2-2a93-4eb1-b3d5-444d2d826144\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a884ede2-2a93-4eb1-b3d5-444d2d826144\")) {                    Plotly.newPlot(                        \"a884ede2-2a93-4eb1-b3d5-444d2d826144\",                        [{\"dimensions\":[{\"axis\":{\"matches\":true},\"label\":\"bill_length_mm\",\"values\":[39.1,39.5,40.3,null,36.7,39.3,38.9,39.2,34.1,42.0,37.8,37.8,41.1,38.6,34.6,36.6,38.7,42.5,34.4,46.0,37.8,37.7,35.9,38.2,38.8,35.3,40.6,40.5,37.9,40.5,39.5,37.2,39.5,40.9,36.4,39.2,38.8,42.2,37.6,39.8,36.5,40.8,36.0,44.1,37.0,39.6,41.1,37.5,36.0,42.3,39.6,40.1,35.0,42.0,34.5,41.4,39.0,40.6,36.5,37.6,35.7,41.3,37.6,41.1,36.4,41.6,35.5,41.1,35.9,41.8,33.5,39.7,39.6,45.8,35.5,42.8,40.9,37.2,36.2,42.1,34.6,42.9,36.7,35.1,37.3,41.3,36.3,36.9,38.3,38.9,35.7,41.1,34.0,39.6,36.2,40.8,38.1,40.3,33.1,43.2,35.0,41.0,37.7,37.8,37.9,39.7,38.6,38.2,38.1,43.2,38.1,45.6,39.7,42.2,39.6,42.7,38.6,37.3,35.7,41.1,36.2,37.7,40.2,41.4,35.2,40.6,38.8,41.5,39.0,44.1,38.5,43.1,36.8,37.5,38.1,41.1,35.6,40.2,37.0,39.7,40.2,40.6,32.1,40.7,37.3,39.0,39.2,36.6,36.0,37.8,36.0,41.5]},{\"axis\":{\"matches\":true},\"label\":\"bill_depth_mm\",\"values\":[18.7,17.4,18.0,null,19.3,20.6,17.8,19.6,18.1,20.2,17.1,17.3,17.6,21.2,21.1,17.8,19.0,20.7,18.4,21.5,18.3,18.7,19.2,18.1,17.2,18.9,18.6,17.9,18.6,18.9,16.7,18.1,17.8,18.9,17.0,21.1,20.0,18.5,19.3,19.1,18.0,18.4,18.5,19.7,16.9,18.8,19.0,18.9,17.9,21.2,17.7,18.9,17.9,19.5,18.1,18.6,17.5,18.8,16.6,19.1,16.9,21.1,17.0,18.2,17.1,18.0,16.2,19.1,16.6,19.4,19.0,18.4,17.2,18.9,17.5,18.5,16.8,19.4,16.1,19.1,17.2,17.6,18.8,19.4,17.8,20.3,19.5,18.6,19.2,18.8,18.0,18.1,17.1,18.1,17.3,18.9,18.6,18.5,16.1,18.5,17.9,20.0,16.0,20.0,18.6,18.9,17.2,20.0,17.0,19.0,16.5,20.3,17.7,19.5,20.7,18.3,17.0,20.5,17.0,18.6,17.2,19.8,17.0,18.5,15.9,19.0,17.6,18.3,17.1,18.0,17.9,19.2,18.5,18.5,17.6,17.5,17.5,20.1,16.5,17.9,17.1,17.2,15.5,17.0,16.8,18.7,18.6,18.4,17.8,18.1,17.1,18.5]}],\"hovertemplate\":\"species=Adelie\\u003cbr\\u003e%{xaxis.title.text}=%{x}\\u003cbr\\u003e%{yaxis.title.text}=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Adelie\",\"marker\":{\"color\":\"orange\",\"symbol\":\"circle\"},\"name\":\"Adelie\",\"showlegend\":true,\"type\":\"splom\"},{\"dimensions\":[{\"axis\":{\"matches\":true},\"label\":\"bill_length_mm\",\"values\":[46.1,50.0,48.7,50.0,47.6,46.5,45.4,46.7,43.3,46.8,40.9,49.0,45.5,48.4,45.8,49.3,42.0,49.2,46.2,48.7,50.2,45.1,46.5,46.3,42.9,46.1,44.5,47.8,48.2,50.0,47.3,42.8,45.1,59.6,49.1,48.4,42.6,44.4,44.0,48.7,42.7,49.6,45.3,49.6,50.5,43.6,45.5,50.5,44.9,45.2,46.6,48.5,45.1,50.1,46.5,45.0,43.8,45.5,43.2,50.4,45.3,46.2,45.7,54.3,45.8,49.8,46.2,49.5,43.5,50.7,47.7,46.4,48.2,46.5,46.4,48.6,47.5,51.1,45.2,45.2,49.1,52.5,47.4,50.0,44.9,50.8,43.4,51.3,47.5,52.1,47.5,52.2,45.5,49.5,44.5,50.8,49.4,46.9,48.4,51.1,48.5,55.9,47.2,49.1,47.3,46.8,41.7,53.4,43.3,48.1,50.5,49.8,43.5,51.5,46.2,55.1,44.5,48.8,47.2,null,46.8,50.4,45.2,49.9]},{\"axis\":{\"matches\":true},\"label\":\"bill_depth_mm\",\"values\":[13.2,16.3,14.1,15.2,14.5,13.5,14.6,15.3,13.4,15.4,13.7,16.1,13.7,14.6,14.6,15.7,13.5,15.2,14.5,15.1,14.3,14.5,14.5,15.8,13.1,15.1,14.3,15.0,14.3,15.3,15.3,14.2,14.5,17.0,14.8,16.3,13.7,17.3,13.6,15.7,13.7,16.0,13.7,15.0,15.9,13.9,13.9,15.9,13.3,15.8,14.2,14.1,14.4,15.0,14.4,15.4,13.9,15.0,14.5,15.3,13.8,14.9,13.9,15.7,14.2,16.8,14.4,16.2,14.2,15.0,15.0,15.6,15.6,14.8,15.0,16.0,14.2,16.3,13.8,16.4,14.5,15.6,14.6,15.9,13.8,17.3,14.4,14.2,14.0,17.0,15.0,17.1,14.5,16.1,14.7,15.7,15.8,14.6,14.4,16.5,15.0,17.0,15.5,15.0,13.8,16.1,14.7,15.8,14.0,15.1,15.2,15.9,15.2,16.3,14.1,16.0,15.7,16.2,13.7,null,14.3,15.7,14.8,16.1]}],\"hovertemplate\":\"species=Gentoo\\u003cbr\\u003e%{xaxis.title.text}=%{x}\\u003cbr\\u003e%{yaxis.title.text}=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Gentoo\",\"marker\":{\"color\":\"black\",\"symbol\":\"circle\"},\"name\":\"Gentoo\",\"showlegend\":true,\"type\":\"splom\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"species\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"dragmode\":\"select\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a884ede2-2a93-4eb1-b3d5-444d2d826144');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a dataframe with all the information that we need. Let's go ahead and extract the bill length and depth to use as input data, storing it in $x$.\n",
        "Then we'll store the labels (i.e., the _targets_) in $y$.\n",
        "### **Q1) Extract the bill length and bill depth to use as the input vector $x$, and store the label (i.e., the target data) in $y$**\n"
      ],
      "metadata": {
        "id": "kGI9Ruq6BRPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints - Data Loading and Filtering\n",
        "\n",
        "'''\n",
        "Loading data into X:\n",
        "\n",
        "You can access multiple columns of a pandas dataframe using a list! The snippet\n",
        "below will return the species and island associated with each penguin in the\n",
        "database.\n",
        "\n",
        "In the cell below, you want to load the bill length and bull depth columns.\n",
        "Make sure you use the right column name! Copy it from the dataframe view we\n",
        "printed before, and make sure there aren't any extra spaces\n",
        "''';\n",
        "data[['species','island']];\n",
        "\n",
        "'''\n",
        "Finding the NaN row indices\n",
        "\n",
        "Pandas has a built-in function to determine if the value is a NaN (Not a Number)\n",
        "value.\n",
        "\n",
        "mydata.notna() will return True wherever the data isn't a NaN value, but we need\n",
        "to check if each row has _any_ NaN values - that's what the _all(axis=1)_ does.\n",
        "''';"
      ],
      "metadata": {
        "id": "9kwuG96d5GrS",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the bill length and depth into X\n",
        "X = data[['bill_length_mm', 'bill_depth_mm']]\n",
        "\n",
        "# Find out the rows where you don't have an valid input (i.e., rows with a nan value)\n",
        "indices = X.notna().all(axis=1)\n",
        "\n",
        "# Filter out the datapoints using the indices we found\n",
        "X = X[indices]\n",
        "\n",
        "# We'll also normalize the data using the mean and standard deviation\n",
        "X = (X - X.mean())/X.std()"
      ],
      "metadata": {
        "id": "mRognoEcPUmf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at the input dataset - if you did everything right, you'll\n",
        "# have 274 entries and printing out x.shape will return (274,2)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "0IoLpmkLugIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e3d33e-c0ec-404c-e0c2-0dc144c98062"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(274, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have our input data, but we need a target to predict. We previously filtered the data to only include Ad√©lie and Gentoo penguins, but we still have them as strings! Let's convert them to a binary representation (i.e., 0 or 1). Make sure you have the same penguins as in your input!\n",
        "\n",
        "### **Q2) Convert the species label to a binary classification, and filter the target data to match the input data.**"
      ],
      "metadata": {
        "id": "S63cMjGKLpd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints - Boolean Representation & Type Conversion\n",
        "\n",
        "'''\n",
        "Boolean Representation\n",
        "\n",
        "You can access the species data by calling data['species']\n",
        "\n",
        "== is the operator that lets you check if the data is equal to another value\n",
        "\n",
        "data['island'] == Torgesen\n",
        "will return True for each row if the penguin was studied in Torgesen, and False\n",
        "if it was studied in another island\n",
        "''';\n",
        "\n",
        "'''\n",
        "Type Conversion\n",
        "\n",
        "Pandas dataframes include a method to change the type of the data being called.\n",
        "\n",
        "data['bill_length_mm'].astype(int) will return the bill length data as integers\n",
        "''';"
      ],
      "metadata": {
        "id": "s3psibnt08RZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert species data into boolean form by checking if the species is Ad√©lie\n",
        "y = (data['species'] == 'Adelie')\n",
        "\n",
        "# Filter out the points for which we have NaN values. Reuse the indices from Q1!\n",
        "y = y[indices]\n",
        "# Convert the boolean data into an integer\n",
        "y = y.astype(int)"
      ],
      "metadata": {
        "id": "TEJwe-AvLvN2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out y! If everything is implemented correctly, you should see a panda\n",
        "# series full of ones and zeroes with 274 rows\n",
        "print(y)"
      ],
      "metadata": {
        "id": "x9WveIx-1w5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288cb05b-7058-478a-f9ec-1fecf87964e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      1\n",
            "1      1\n",
            "2      1\n",
            "4      1\n",
            "5      1\n",
            "      ..\n",
            "270    0\n",
            "272    0\n",
            "273    0\n",
            "274    0\n",
            "275    0\n",
            "Name: species, Length: 274, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a set of binary classification data we can use to train an algorithm.\n",
        "\n",
        "As we saw during our reading, we need to define three things in order to train our algorithm:\n",
        "> $\\cdot$ the type of algorithm we will train, \\\\\n",
        "> $\\cdot$ the cost function (which will tell us how close our prediction is to the truth), and \\\\\n",
        "> $\\cdot$ a method for updating the parameters in our model according to the value of the cost function (e.g., the gradient descent method).\n",
        "\n",
        "Let's begin by defining the type of algorithm we will use. We will train a logistic regression model to differentiate between two classes. A reminder of how the logistic regression algorithm works is given below.\n",
        "<br><br><br>\n",
        "The logistic regression algorithm will thus take an input $t$ that is a linear combination of the features:\n",
        "\n",
        "<a name=\"logit\"></a>\n",
        "\n",
        "<center> $t_{\\small{n}} = \\beta_{\\small{0}} + \\beta_{\\small{1}} \\cdot X_{1,n} + \\beta_{\\small{2}} \\cdot X_{2,n}$ </center>\n",
        "\n",
        "where\n",
        "* $n$ is the ID of the sample\n",
        "* $X_{\\small{0}}$ represents the bill length\n",
        "* $X_{\\small{1}}$ represents the bill width\n",
        "\n",
        "This input is then fed into the logistic function, $\\sigma$:\n",
        "\\begin{align}\n",
        "\\sigma: t\\mapsto \\dfrac{1}{1+e^ {-t}}\n",
        "\\end{align}\n",
        "\n",
        "Let's define the logistic function for later use."
      ],
      "metadata": {
        "id": "jvNBaOWZ9fXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q4) Define the logistic function**"
      ],
      "metadata": {
        "id": "PzrhQ2E-zkDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint - Exponential Function\n",
        "'''\n",
        "Numpy includes the exponential function in its library as numpy.exp\n",
        "https://numpy.org/doc/stable/reference/generated/numpy.exp.html\n",
        "''';\n",
        "\n",
        "np.exp(2);"
      ],
      "metadata": {
        "id": "oBvebKZVDWx0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic(in_val):\n",
        "    # Return the value of the logistic function\n",
        "    out_value = 1 / (1 + np.exp(-in_val))\n",
        "    return out_value"
      ],
      "metadata": {
        "id": "EdelvJlJzuE5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the logistic function has been defined, we can plot it (this will help us remember what it looks like!) Run the code below - you won't have to fill anything in for this one üòÄ But feel free to show the code and read through it - some of the functions used can be helpful to you down the line!"
      ],
      "metadata": {
        "id": "WqIkC1wZ0gAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this to plot the logistic function!\n",
        "# Let's generate an array of 20 points with values from -4 to +4\n",
        "t = np.linspace(-4,4,20)\n",
        "\n",
        "# Initiate a figure and axes object using matplotlib\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Draw the X and Y axes\n",
        "ax.axvline(0, c='black', alpha=1)\n",
        "ax.axhline(0, c='black', alpha=1)\n",
        "\n",
        "# Draw the threshold line (y_val=0,5) and asymptote (y=1)\n",
        "[ax.axhline(y_val, c='black', alpha=0.5, linestyle='dotted') for y_val in (0.5,1)]\n",
        "\n",
        "# Scale things to make the graph look nicer\n",
        "plt.autoscale(axis='x', tight=True)\n",
        "\n",
        "# Plot the logistic function. X values from the t vector, y values from logistic(t)\n",
        "ax.plot(t, logistic(t));\n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$\\\\sigma\\\\  \\\\left(t\\\\right)$')\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "lgt9dI6b9Zwa",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "b642d207-b011-4baa-e53b-c8f1731004fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the logistic function, we define inputs resulting in $\\sigma\\geq0.5$ as belonging to the ***one*** class, and any value below that is considered to belong to the ***zero*** class.\n",
        "\n",
        "We now have a function which lets us map the value of the bill length and width to the class to which the observation belongs (i.e., whether the length and width correspond to Ad√©lie or Gentoo penguins). However, there is a parameter vector **$\\theta$** with a number of parameters that we do not have a value for: <br> $\\theta = [ \\beta_{\\small{0}}, \\beta_{\\small{1}}$, $\\beta_{\\small{2}} ]$"
      ],
      "metadata": {
        "id": "0Ll1PKpjxqLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q5) Set up an array of random numbers between 0 and 1 representing the $\\theta$ vector.**\n"
      ],
      "metadata": {
        "id": "O_lT4EaK2ICa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints: Random Number Generation\n",
        "'''\n",
        "Random Number Generation\n",
        "Use `rnd_gen`! If you're not sure how to use it, consult the `default_rng`\n",
        "documentation at this address:\n",
        "https://numpy.org/doc/stable/reference/random/generator.html\n",
        "\n",
        "For instance, you may use the `random` method of `rnd_gen`.*\n",
        "''';\n",
        "\n",
        "'''\n",
        "The theta array should have 3 elements in it!\n",
        "''';"
      ],
      "metadata": {
        "id": "4ULzWzd750RT"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint: Code Snipppet\n",
        "'''\n",
        "rnd_gen.random((___,)) # length of array\n",
        "''';"
      ],
      "metadata": {
        "id": "R0uUE4VbEfgt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta = rnd_gen.random((3,)) # length of array\n",
        "print(theta)"
      ],
      "metadata": {
        "id": "-Vk05y1C2VBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aade6b3-29b9-4569-dc00-ed9ed53209af"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.77395605 0.43887844 0.85859792]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to determine whether a set of $\\beta$ values is better than the other, we need to quantify well the values are able to predict the class. This is where the cost function comes in.\n",
        "\n",
        "The cost function, $c$, will return a value close to zero when the prediction, $\\hat{p}$, is correct and a large value when it is wrong. In a binary classification problem, we can use the log loss function. For a single prediction and truth value, it is given by:\n",
        "\\begin{align}\n",
        "        \\text{c}(\\hat{p},y) = \\left\\{\n",
        "        \\begin{array}{cl}\n",
        "        -\\log(\\hat{p})& \\text{if}\\; y=1\\\\\n",
        "        -\\log(1-\\hat{p}) & \\text{if}\\; y=0\n",
        "        \\end{array}\n",
        "        \\right.\n",
        "    \\end{align}\n",
        "\n",
        "However, we want to apply the cost function to an n-dimensional set of predictions and truth values. Thankfully, we can find the average value of the log loss function $J$ for an an-dimensional set of $\\hat{y}$ & $y$ as follows:\n",
        "\n",
        "\\begin{align}\n",
        "        \\text{J}(\\mathbf{\\hat{p}},y) = - \\dfrac{1}{n} \\sum_{i=1}^{n}\n",
        "        \\left[ y_i\\cdot \\log\\left( \\hat{p}_i \\right) \\right] +\n",
        "        \\left[ \\left( 1 - y_i \\right) \\cdot \\log\\left( 1-\\hat{p}_i \\right) \\right]\n",
        "    \\end{align}\n",
        "\n",
        "We now have a formula that can be used to calculate the average cost over the training set of data.\n",
        "\n",
        "Now let's code üíª\n"
      ],
      "metadata": {
        "id": "s8KM_CeF2Ven"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q6) Define a log_loss function that takes in an arbitrarily large set of prediction and truths**\n",
        "\n",
        "*Hint 1: You need to encode the function $J$ above, for which Numpy's functions may be quite convenient (e.g., [`log`](https://numpy.org/doc/stable/reference/generated/numpy.log.html), [`mean`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html), etc.)*\n",
        "\n",
        "*Hint 2: Asserting the dimensions of the vector is a good way to check that your function is working correctly. [Here's a tutorial on how to use `assert`](https://swcarpentry.github.io/python-novice-inflammation/10-defensive/index.html#assertions). For instance, to assert that two vectors `X` and `y` have the same dimension, you may use:*\n",
        "```\n",
        "assert X.shape==y.shape\n",
        "```"
      ],
      "metadata": {
        "id": "XBLxwlSWMoo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint: Example code snippet\n",
        "'''\n",
        "J_vector  = -(y * np.log(p_hat + epsilon) + (1-y) * np.log(1-y_hat))\n",
        "J.mean()\n",
        "''';"
      ],
      "metadata": {
        "id": "Jmnzz4h_Cq01"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(p_hat, y, epsilon=1e-7):\n",
        "\n",
        "  # Begin by calculating the two possibilities for the cost function, i.e.\n",
        "  # 1: -log(p_hat + epsilon), and 2: -log(1- p_hat). We added an epsilon term\n",
        "  # to -log(p_hat) because we can run into mathematical problems if p_hat = 0.\n",
        "  term_1 = -np.log( p_hat + epsilon )\n",
        "  term_2 = -np.log( 1 - p_hat )\n",
        "\n",
        "  # We can almost calculate J! We'll need to 1) multiply term_1 by y, and\n",
        "  # 2) multiply term_2 by (1-y). We then add the new terms together.\n",
        "  # Calculate the value of the cost function (i.e., what's inside the brackets)\n",
        "  inside_brackets = (y) * term_1 + ( 1 - y ) * term_2\n",
        "\n",
        "  #Verify the shape of inside_brackets.\n",
        "  print(f'The size of the term inside the brackets is {inside_brackets.shape}')\n",
        "\n",
        "  # You should have a cost value for each one of your predictions. We won't\n",
        "  # use the individual values, though. We'll aggregate the information from\n",
        "  # all our predictions by calculating the mean! (i.e., 1/n_terms * terms_sum)\n",
        "  # This single value is J\n",
        "  J = inside_brackets.mean()\n",
        "\n",
        "  return J"
      ],
      "metadata": {
        "id": "H5fDeL36EauO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a way of quantifying how good our predictions are. The final thing needed for us to train our algorithm is figuring out a way to update the parameters in a way that improves the average quality of our predictions.\n",
        "\n",
        "<br><br>**Warning**: we'll go into a bit of math below <br><br>\n",
        "\n",
        "Let's look at the change in a single parameter within $\\theta$: $\\beta_1$ (given $X_{1,i} = X_1$, $\\;\\hat{p}_{i} = \\hat{p}$, $\\;y_{i} = y$). If we want to know what the effect of changing the value of $\\beta_1$ will have on the log loss function we can find this with the partial derivative:\n",
        "<center>$\n",
        "        \\dfrac{\\partial J}{\\partial \\beta_1}\n",
        "$</center>\n",
        "\n",
        "This may not seem very helpful by itself - after all, $\\beta_1$ isn't even in the expression of $J$. But if we use the chain rule, we can rewrite the expression as:\n",
        "<center>\n",
        "        $\\dfrac{\\partial J}{\\partial \\hat{p}} \\cdot\n",
        "        \\dfrac{\\partial \\hat{p}}{\\partial \\theta} \\cdot\n",
        "        \\dfrac{\\partial \\theta}{\\partial \\beta_1}$\n",
        "</center>\n",
        "\n",
        "We'll spare you the math (feel free to verify it youself, however!):\n",
        "\n",
        "<center>$\\dfrac{\\partial J}{\\partial \\hat{p}} =  \\dfrac{\\hat{p} - y}{\\hat{p}(1-\\hat{p})}, \\quad\n",
        "        \\dfrac{\\partial \\hat{p}}{\\partial \\theta} = \\hat{p} (1-\\hat{p}), \\quad\n",
        "        \\dfrac{\\partial \\theta}{\\partial \\beta_1} = X_1 $\n",
        "</center>\n",
        "\n",
        "and thus\n",
        "<center>$\n",
        "        \\dfrac{\\partial J}{\\partial \\beta_1} = (\\hat{p} - y) \\cdot X_1\n",
        "$</center>\n",
        "\n",
        "We can calculate the partial derivative for each parameter in $\\theta$ which, as you may have realized, is simply the $\\theta$ gradient of $J$: $\\nabla_{\\theta}(J)$\n",
        "\n",
        "With all of this information, we can now write $\\nabla_{\\theta} J$ in terms of the error, the feature vector, and the number of samples we're training on!\n",
        "\n",
        "<a name=\"grad_eq\"></a>\n",
        "\n",
        "<center>$\\nabla_{\\mathbf{\\theta}^{(k)}} \\, J(\\mathbf{\\theta^{(k)}}) = \\dfrac{1}{n} \\sum\\limits_{i=1}^{n}{ \\left ( \\hat{p}^{(k)}_{i} - y_{i} \\right ) \\mathbf{X}_{i}}$</center>\n",
        "\n",
        "Note that here $k$ represents the iteration of the parameters we are currently on.\n",
        "\n",
        "We now have a gradient we can calculate and use in the batch gradient descent method! The updated parameters will thus be:\n",
        "\n",
        "<a name=\"grad_descent\"></a>\n",
        "\n",
        "\\begin{align}\n",
        "{\\mathbf{\\theta}^{(k+1)}} = {\\mathbf{\\theta}^{(k)}} - \\eta\\,\\nabla_{\\theta^{(k)}}J(\\theta^{(k)})\n",
        "\\end{align}\n",
        "\n",
        "Where $\\eta$ is the learning rate parameter. It's also worth pointing out that $\\;\\hat{p}^{(k)}_i = \\sigma\\left(\\theta^{(k)}, X_i\\right) $"
      ],
      "metadata": {
        "id": "aO4Bkm1gFV3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to easily calculate the input to the logistic regression, we'll multiply the $\\theta$ vector with the X data, and as we have a non-zero bias  $\\beta_0$ we'd like to have an X matrix whose first column is filled with ones.\n",
        "\n",
        "\\begin{align}\n",
        "    X_{\\small{with\\ bias}} = \\begin{pmatrix}\n",
        "        1 & X_{1,0} & X_{2,0}\\\\\n",
        "        1 & X_{1,1} & X_{2,1}\\\\\n",
        "        &...&\\\\\n",
        "        1 & X_{1,n} & X_{2,n}\n",
        "        \\end{pmatrix}\n",
        "\\end{align}\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "ML4uik7sbdMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q7) Prepare the `X_with_bias` matrix.**"
      ],
      "metadata": {
        "id": "sqwV5qgrisB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints: Making an an array filled with ones, hints on concatenation\n",
        "\n",
        "'''\n",
        "Making the ones array\n",
        "\n",
        "Making an array with ones and the same number of entries as rows in your input\n",
        "data: You can use numpy.ones( (array_dimensions) ) in order to generate an array with\n",
        "the given array_dimensions shape. e.g., np.ones((4,)) => array([1,1,1,1])\n",
        "\n",
        "Accessing the number of rows: dataframes have the \"shape\" attribute implemented.\n",
        "For our penguin data, the input vector shape should be (274,2), and so using\n",
        "shape[0] should return the right length for our ones array\n",
        "''';\n",
        "\n",
        "\n",
        "'''\n",
        "Concatenation\n",
        "\n",
        "You can quickly concatenate your arrays using np.c_[array1,array2]. Note that\n",
        "the order matters, so make sure array1 is the array filled with ones :). Also,\n",
        "np.c_ uses square brackets! [] - you'll get an error if you use regular\n",
        "brackets ().\n",
        "\n",
        "numpy.c_ will automagically understand that the second array is a dataframe -\n",
        "you don't need to worry about transforming it into a numpy array for today!\n",
        "\n",
        "''';"
      ],
      "metadata": {
        "id": "PlipJo530lPp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the ones array\n",
        "ones_array = np.ones(data.shape[0],)\n",
        "\n",
        "# Make the x_with_bias matrix\n",
        "X_with_bias = np.c_[ones_array, data[['bill_length_mm', 'bill_depth_mm']]]"
      ],
      "metadata": {
        "id": "A_-GIW9cCTFn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvs9M3E1-uLi",
        "outputId": "0ddbd9aa-41c5-4728-e371-a889447d7ef5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "276"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print your x with bias matrix to make sure it looks the way it's supposed to\n",
        "print(X_with_bias[:10])"
      ],
      "metadata": {
        "id": "QiqtcQj5IIH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ad2cae-61f2-4f09-8427-1f84832d8242"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.  39.1 18.7]\n",
            " [ 1.  39.5 17.4]\n",
            " [ 1.  40.3 18. ]\n",
            " [ 1.   nan  nan]\n",
            " [ 1.  36.7 19.3]\n",
            " [ 1.  39.3 20.6]\n",
            " [ 1.  38.9 17.8]\n",
            " [ 1.  39.2 19.6]\n",
            " [ 1.  34.1 18.1]\n",
            " [ 1.  42.  20.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our X_with_bias matrix looks like this: \\\\\n",
        "[[ 1.        $\\quad$ -0.69346042 $\\quad$ 0.92572752] \\\\\n",
        " [ 1.        $\\quad$ -0.6164717  $\\quad$ 0.28005659] \\\\\n",
        " [ 1.        $\\quad$ -0.46249427 $\\quad$ 0.57805856] \\\\\n",
        " [ 1.        $\\quad$ -1.15539273 $\\quad$ 1.22372949] \\\\\n",
        " [ 1.        $\\quad$ -0.65496606 $\\quad$ 1.86940041] \\\\\n",
        " [ 1.        $\\quad$ -0.73195478 $\\quad$ 0.47872457] \\\\\n",
        " [ 1.        $\\quad$ -0.67421324 $\\quad$ 1.37273047] \\\\\n",
        " [ 1.        $\\quad$ -1.65581939 $\\quad$ 0.62772555] \\\\\n",
        " [ 1.        $\\quad$ -0.13529222 $\\quad$ 1.67073244] \\\\\n",
        " [ 1.        $\\quad$ -0.94367375 $\\quad$ 0.13105561]]"
      ],
      "metadata": {
        "id": "wN1zdxPLkhO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q8) Write a function called `predict` that takes in the parameter vector $\\theta$ and the `X_with_bias` matrix and evaluates the logistic function for each of the samples.**"
      ],
      "metadata": {
        "id": "cThmFWcB0v-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint: Pseudocode Snippet\n",
        "\n",
        "'''\n",
        "Pseudocode below:\n",
        "\n",
        "define predict_function(x_with_bias, theta_vector):\n",
        "  argument_for_logistic_function = dot_product(x_with_bias, theta_vector)\n",
        "  return logistic_function(argument_for_logistic_function)\n",
        "\n",
        "''';"
      ],
      "metadata": {
        "id": "opqgiTM2L0jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your predict function here\n",
        "def predict_function(X_with_bias, theta):\n",
        "    # Find the dot product of X_with_bias and theta\n",
        "    dot_product = np.dot(X_with_bias,theta)\n",
        "\n",
        "    # Use your logistic function!\n",
        "    output = logistic(dot_product)\n",
        "\n",
        "    return output # Return the value you get"
      ],
      "metadata": {
        "id": "tBLryApsbatR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's test your predict function!\n",
        "\n",
        "# Set up debug data and parameters\n",
        "debug_data = np.c_[np.ones(5), np.linspace(-1,1,10).reshape((-1,2))]\n",
        "debug_theta = np.array([0.2,0.1,0.9])\n",
        "\n",
        "print(predict_function(debug_data, debug_theta))"
      ],
      "metadata": {
        "id": "6QIweEz8OKPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca3f1d6-1ad5-4554-c635-80773279c8ab"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.35434369 0.46118934 0.57172409 0.67553632 0.76454801]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If everything is set up correctly and you didn't change the debug data and theta, the output for your predict function should be:\n",
        "\n",
        "`[0.35434369 0.46118934 0.57172409 0.67553632 0.76454801]`"
      ],
      "metadata": {
        "id": "HQ6oK6ewOcHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q9) Now that you have a `predict` function, write a `gradient_calc` function that calculates the gradient for the logistic function.**\n",
        "\n",
        "*Hint: You'll have to feed `theta`, `X`, and `y` to the `gradient_calc` function.*\n",
        "\n",
        "*Hint: You can use [this equation](#grad_eq) to calculate the gradient of the cost function.*"
      ],
      "metadata": {
        "id": "p6cPbu4LvVES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint: Pseudocode Snippet\n",
        "\n",
        "'''\n",
        "\n",
        "define gradient_calculator_function(y, X_with_bias, theta_vector):\n",
        "  # predicted values using theta and inputs\n",
        "  prediction = predict(x_with_bias,theta_vector)\n",
        "\n",
        "  number_of_predictions = len(prediction)\n",
        "\n",
        "  assert number_of_predictions == len(y)\n",
        "\n",
        "  error = prediction - y\n",
        "\n",
        "  X_transpose = transpose(X)\n",
        "\n",
        "  return dot_product(X_transpose, error) / number_of_predictions\n",
        "\n",
        "''';\n",
        "\n"
      ],
      "metadata": {
        "id": "XRQNz-2nPGVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_calculator(y, X_with_bias, theta):\n",
        "    # Find predicted values using the predict function\n",
        "    prediction = predict_function(X_with_bias, theta)\n",
        "\n",
        "    # Assert that you have the same number of predictions as you do targets\n",
        "    # Otherwise, something went wrong!\n",
        "    assert len(prediction) == len(y)\n",
        "\n",
        "    # Calculate the error\n",
        "    error = prediction - y\n",
        "\n",
        "    # Find the dot product with the input matrix and divide by the number of\n",
        "    # predictions\n",
        "    output =  np.dot(X_with_bias.T, error)/len(y)\n",
        "    return output"
      ],
      "metadata": {
        "id": "BtnANN5WvVuy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's test the gradient calculator\n",
        "# Begin by creating dummy labels\n",
        "debug_labels = np.array([0,0,0,1,1])\n",
        "\n",
        "# And call the function you defined with the dummy labels and data we made before\n",
        "print(gradient_calculator(debug_labels, debug_data, debug_theta))"
      ],
      "metadata": {
        "id": "sMs0pmFcVo1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38338c2-3a99-45fd-dd15-b4922b01d217"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.16546829 -0.19307376 -0.15630302]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you kept the same dummy data we included by default in the notebook, you should get `[ 0.16546829 -0.19307376 -0.15630302]` as the output of your gradient calculator! <font size=+3>üíª</font>"
      ],
      "metadata": {
        "id": "0wc43bGxV-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now write a function that will train a logistic regression algorithm!\n",
        "\n",
        "Your `logistic_regression` function needs to:\n",
        "* Take in a set of training input/output data, validation input/output data, a number of iterations to train for, a set of initial parameters $\\theta$, and a learning rate $\\eta$\n",
        "* At each iteration:\n",
        " * Generate a set of predictions on the training data. Hint: You may use your function `predict` on inputs `X_train` from the training set.\n",
        " * Calculate and store the loss function for the training data at each iteration. Hint: You may use your function `log_loss` on inputs `X_train` and outputs `y_train` from the training set.\n",
        " * Calculate the gradient. Hint: You may use your function `grad_calc`.\n",
        " * Update the $\\theta$ parameters. Hint: You need to implement [this equation](#grad_descent).\n",
        " * Generate a set of predictions on the validation data using the updated parameters. Hint: You may use your function `predict` on inputs `X_valid` from the validation set.\n",
        " * Calculate and store the loss function for the validation data. Hint: You may use your function `log_loss` on inputs `X_valid` and outputs `y_valid` from the validation set.\n",
        " * Bonus: Calculate and store the accuracy of the model on the training and validation data as a metric!\n",
        "* Return the final set of parameters $\\theta$ & the stored training/validation loss function values (and the accuracy, if you did the bonus)\n",
        "\n"
      ],
      "metadata": {
        "id": "PU4A5HVKuAGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q10) Write the `logistic_regression` function**"
      ],
      "metadata": {
        "id": "182qtGB7i_vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint: Pseudocode Snippet\n",
        "\n",
        "'''\n",
        "define logistic_regression(\n",
        "                           X_train,\n",
        "                           y_train,\n",
        "                           X_validation,\n",
        "                           y_validation,\n",
        "                           theta_vector,\n",
        "                           number_of_iterations,\n",
        "                           learning_rate_eta,\n",
        "                          ):\n",
        "  #initialize the list of losses\n",
        "  training_losses = list()\n",
        "  validation_losses = list()\n",
        "\n",
        "  for iteration in range(number_of_iterations):\n",
        "    train_set_predictions = predict(X_train, theta_vector)\n",
        "    train_loss = log_loss(train_set_predictions, y_train)\n",
        "    training_losses.append(train_loss)\n",
        "\n",
        "    gradient = gradient_calculator(y_train, X_train, theta_vector)\n",
        "    theta_vector = theta_vector - gradient * learning_rate_eta\n",
        "\n",
        "    validation_set_predictions = predict(X_validation, theta_vector)\n",
        "    validation_loss = log_loss(validation_set_predictions, y_validation)\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    print(Completed (iteration)/(number_of_iterations)*100%)\n",
        "\n",
        "    return [training_losses, validation_losses], theta\n",
        "''';"
      ],
      "metadata": {
        "id": "eNfODgtZYm2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression(X_train,\n",
        "                        y_train,\n",
        "                        X_validation,\n",
        "                        y_validation,\n",
        "                        theta,\n",
        "                        num_iters,\n",
        "                        learning_rate_eta,\n",
        "                      ):\n",
        "  # Initialize the list of losses\n",
        "  training_losses = list()\n",
        "  validation_losses = list()\n",
        "\n",
        "  # Loop through as many times as defined in the function call\n",
        "  for iteration in range(num_iters):\n",
        "\n",
        "    #--------Training-------\n",
        "    # Get predictions on training dataset\n",
        "    train_set_predictions = predict_function(X_train, theta)\n",
        "\n",
        "    # Calculate the loss\n",
        "    train_loss = log_loss(train_set_predictions, y_train)\n",
        "\n",
        "    # Add it to the list of training losses to keep track of it\n",
        "    training_losses.append(train_loss)\n",
        "\n",
        "    # Calculate the Gradient\n",
        "    gradient = gradient_calculator(y_train, X_train, theta)\n",
        "\n",
        "    # Find the new value of theta\n",
        "    theta = theta - gradient * learning_rate_eta\n",
        "\n",
        "    #--------Validation-----------\n",
        "    # Get predictions on the validation dataset\n",
        "    validation_set_predictions = predict_function(X_validation, theta)\n",
        "\n",
        "    # Calculate the validation loss\n",
        "    validation_loss = log_loss(validation_set_predictions, y_validation)\n",
        "\n",
        "    # Add it to the list of validation losses to keep track of it\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    # Progress Indicator\n",
        "    if (iteration/num_iters * 100) % 5 == 0:\n",
        "      print(f'\\rCompleted {(iteration)/(num_iter)*100}%', end='')\n",
        "\n",
        "  print('\\rCompleted 100%')\n",
        "  return [training_losses, validation_losses], theta"
      ],
      "metadata": {
        "id": "HDsR5TxPt-0Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬°¬°¬°Important Note!!!**\n",
        "\n",
        "The notebook assumes that you will return\n",
        "1. a Losses list, where Losses[0] is the training loss and Losses[1] is the validation loss\n",
        "2. a tuple with the 3 final coefficients ($\\beta_0$, $\\beta_1$, $\\beta_2$)\n",
        "\n",
        "---------------------"
      ],
      "metadata": {
        "id": "EWMDLk7wFB0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our logistic regression function, we're all set to train our algorithm! Or _are_ we?\n",
        "\n",
        "There's an **important** data step that we've neglected up to this point - we need to **split the data** into the train, validation, and test datasets.\n",
        "\n",
        "<center>train <font size=+3> ‚úÇÔ∏è </font> validation <font size=+3> ‚úÇÔ∏è </font> test</center>"
      ],
      "metadata": {
        "id": "2ep5FQYBmqG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "total_size = len(X_with_bias)\n",
        "\n",
        "test_size = int(total_size * test_ratio)\n",
        "validation_size = int(total_size * validation_ratio)\n",
        "train_size = total_size - test_size - validation_size\n",
        "\n",
        "rnd_indices = rnd_gen.permutation(total_size)\n",
        "\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y.iloc[rnd_indices[:train_size]]\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y.iloc[rnd_indices[train_size:-test_size]]\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y.iloc[rnd_indices[-test_size:]]"
      ],
      "metadata": {
        "id": "CVrXzjYA2iil",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "a6e2c809-b07f-4afa-bf29-062b4c38b120"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "positional indexers are out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1675\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4087\u001b[0m         \"\"\"\n\u001b[0;32m-> 4088\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4089\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4068\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   4069\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexers/utils.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-13be4a06e787>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_with_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_with_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1703\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m             \u001b[0;31m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready!\n",
        "\n",
        "###**Q11) Train your logistic regression algorithm. We recommend you use 500 iterations, $\\eta$=0.1**\n",
        "\n",
        "*Hint: It's time to use the `logistic_regression` function you defined in Q5.*"
      ],
      "metadata": {
        "id": "33IhRpME8LOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_iters = 500\n",
        "learning_rate_eta = 0.1\n",
        "\n",
        "losses, coeffs = logistic_regression(X_train,\n",
        "                        y_train,\n",
        "                        X_valid,\n",
        "                        y_valid,\n",
        "                        theta,\n",
        "                        num_iters,\n",
        "                        learning_rate_eta,\n",
        "                      )"
      ],
      "metadata": {
        "id": "dWAr0ORYEYi2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "763d58d8-6dec-43c8-9572-1b08a527fd4e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the term inside the brackets is (166,)\n",
            "The size of the term inside the brackets is (54,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-923e3434e6ed>:7: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'num_iter' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b9456a11b81e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearning_rate_eta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m losses, coeffs = logistic_regression(X_train,\n\u001b[0m\u001b[1;32m      5\u001b[0m                         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-9811700a36c6>\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(X_train, y_train, X_validation, y_validation, theta, num_iters, learning_rate_eta)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Progress Indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_iters\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\rCompleted {(iteration)/(num_iter)*100}%'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\rCompleted 100%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_iter' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how our model did while learning!"
      ],
      "metadata": {
        "id": "e7WHcpPiEcIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to produce the Loss Function Visualization Graphs\n",
        "fig, ax = plt.subplots(figsize=(9,6), dpi=100)\n",
        "ax.plot(losses[0], color='blue', label='Training', linewidth=3);\n",
        "ax.plot(losses[1], color='black', label='Validation', linewidth=3);\n",
        "ax.legend();\n",
        "ax.set_ylabel('Log Loss')\n",
        "ax.set_xlabel('Iterations')\n",
        "ax.set_title('Loss Function Graph')\n",
        "ax.autoscale(axis='x', tight=True)\n",
        "fig.tight_layout();"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T_ImydMTKkfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get predictions from our model for the training, validation, and testing\n",
        "# datasets\n",
        "y_hat_train = (predict(X_train, coeffs)>=.5).astype(int)\n",
        "y_hat_valid = (predict(X_valid, coeffs)>=.5).astype(int)\n",
        "y_hat_test = (predict(X_test, coeffs)>=.5).astype(int)\n",
        "\n",
        "y_sets = [ [y_hat_train, y_train],\n",
        "           [y_hat_valid, y_valid],\n",
        "           [y_hat_test, y_test] ]\n",
        "\n",
        "def accuracy_score(y_hat, y):\n",
        "    assert(y_hat.size==y.size)\n",
        "    return (y_hat == y).sum()/y.size\n",
        "accuracies=[]\n",
        "[accuracies.append(accuracy_score(y_set[0],y_set[1])) for y_set in y_sets]\n",
        "\n",
        "printout= (f'Training Accuracy:{accuracies[0]:.1%} \\n'\n",
        "           f'Validation Accuracy:{accuracies[1]:.1%} \\n'\n",
        "           f'Test Accuracy:{accuracies[2]:.1%} \\n')\n",
        "\n",
        "# Add the testing accuracy only once you're sure that your model works!\n",
        "print(printout)"
      ],
      "metadata": {
        "id": "4wXFzZPjFjOn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "978db7f6-b7d0-437f-9ee4-002f81aca70c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'predict' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-0f411395ec48>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's get predictions from our model for the training, validation, and testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_hat_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_hat_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_hat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations on training a logistic regression algorithm from scratch!\n",
        "\n",
        "Your loss function graph should look something similar to this...\n",
        "<img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EUqSnwtsU7VEkUul4oqhj6cBy1FIGMsGAfTXTmXQke1N3g?download=1'>\n",
        "\n",
        "And the accuracies we got during development of the notebook are:\n",
        "\n",
        "`Training Accuracy:99.4%`  <br>\n",
        "`Validation Accuracy:100.0%` <br>\n",
        "`Test Accuracy:100.0% `\n",
        "\n",
        "Once you're done with the upcoming environmental science applications notebook, feel free to come back to take a look at the challenges üòÄ"
      ],
      "metadata": {
        "id": "4zfXs8M8Osie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenges\n",
        "\n",
        "* **C1)** Add more features to try to improve our accuracies!\n",
        "\n",
        "* **C2)** Add early stopping to the training algorithm! (e.g., stop training when the accuracy is greater than a target accuracy)"
      ],
      "metadata": {
        "id": "VAa4bzT7PHRG"
      }
    }
  ]
}