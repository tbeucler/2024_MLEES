{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheophileZuber/2024_MLEES/blob/main/Copie_de_S1_2_Training_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Week 1 Notebook 2 ‚Äì Training Models**\n",
        "\n",
        "This week's notebook is based off of the exercises in Chapter 4 of G√©ron's book."
      ],
      "metadata": {
        "id": "5Tt5C4PoIRl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Setup\n",
        "Let's begin like in the last notebook: importing a few common modules, ensuring MatplotLib plots figures inline and preparing a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so once again we strongly recommend you use Python 3 instead), as well as Scikit-Learn ‚â•0.20.\n",
        "\n",
        "You don't need to worry about understanding everything that is written in this section."
      ],
      "metadata": {
        "id": "666iBNeL8-7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_OXSp49IOF2",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Run this cell for preliminary requirements. Double click it if you want to check out the source :)\n",
        "\n",
        "# Python ‚â•3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "# Scikit-Learn ‚â•0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To make this notebook's output stable across runs\n",
        "rnd_seed = 42\n",
        "rnd_gen = np.random.default_rng(rnd_seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"classification\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "#Ensure the palmerspenguins dataset is installed\n",
        "%pip install palmerpenguins --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Setup"
      ],
      "metadata": {
        "id": "RtuO7Elb9LuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will be working with the [*Palmer Penguins dataset*](https://allisonhorst.github.io/palmerpenguins/articles/intro.html). Each entry in the dataset includes the penguin's species, island, sex, flipper length, body mass, bill length, bill depth, and the year the study was carried out. Let's take a moment and observe our subjects! <br>\n",
        "\n",
        "<center> <font size=+30>üêß</font><br>\n",
        "In order: Ad√©lie (Pygoscelis adeliae),  Chinstrap (Pygoscelis antarcticus), and Gentoo (Pygoscelis papua) penguins <br>\n",
        "\n",
        "<img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EY2OrrxSOSlIiQZ4FQ719YAB80_joiBs9e58jtlSf4H_eQ?download=1' width=32% >\n",
        "<img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EVuvzIGBs_JGihnUSWBGQ1IBjv-ZtUDUo7cXeWtyx9g6Og?download=1' width=32%></img>\n",
        "<img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EXrZM1rJOXRLlmdPTm-BP2gBCgs1qfQiknp29lX4p_7GtQ?download=1' width=32%></img>\n",
        "\n",
        "</center>\n",
        "\n",
        "As you can imagine, this dataset is normally used to train *multiclass*/*multinomial* classification algorithms and not *binary* classification algorithms, since there *are* more than 2 classes.\n",
        "\n",
        "\"*Three classes, even!*\" - an observant TA\n",
        "\n",
        "For this exercise, however, we will implement the binary classification algorithm referred to as the *logistic regression* algorithm (also called logit regression)."
      ],
      "metadata": {
        "id": "wKsvLXdmzqD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load the Palmer Penguins Dataset!\n",
        "from palmerpenguins import load_penguins\n",
        "data = load_penguins()"
      ],
      "metadata": {
        "id": "emWru72owjEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like with the Titanic dataset in the previous notebook, the data here is loaded as a Pandas DataFrame. Feel free to play around with it in the cell below!"
      ],
      "metadata": {
        "id": "kbk8zvwOf2-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The following code will make the dataframe be shown in an interactive table\n",
        "# inside of Google colab. Use data.head(5) if you're running this locally\n",
        "\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "AR2NqgIdTcuk",
        "outputId": "cee0fce7-a6ae-44ae-ade5-958196e4bbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
              "0       Adelie  Torgersen            39.1           18.7              181.0   \n",
              "1       Adelie  Torgersen            39.5           17.4              186.0   \n",
              "2       Adelie  Torgersen            40.3           18.0              195.0   \n",
              "3       Adelie  Torgersen             NaN            NaN                NaN   \n",
              "4       Adelie  Torgersen            36.7           19.3              193.0   \n",
              "..         ...        ...             ...            ...                ...   \n",
              "339  Chinstrap      Dream            55.8           19.8              207.0   \n",
              "340  Chinstrap      Dream            43.5           18.1              202.0   \n",
              "341  Chinstrap      Dream            49.6           18.2              193.0   \n",
              "342  Chinstrap      Dream            50.8           19.0              210.0   \n",
              "343  Chinstrap      Dream            50.2           18.7              198.0   \n",
              "\n",
              "     body_mass_g     sex  year  \n",
              "0         3750.0    male  2007  \n",
              "1         3800.0  female  2007  \n",
              "2         3250.0  female  2007  \n",
              "3            NaN     NaN  2007  \n",
              "4         3450.0  female  2007  \n",
              "..           ...     ...   ...  \n",
              "339       4000.0    male  2009  \n",
              "340       3400.0  female  2009  \n",
              "341       3775.0    male  2009  \n",
              "342       4100.0    male  2009  \n",
              "343       3775.0  female  2009  \n",
              "\n",
              "[344 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94911484-3187-48f9-92aa-8f3b2dc94312\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>male</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>Dream</td>\n",
              "      <td>55.8</td>\n",
              "      <td>19.8</td>\n",
              "      <td>207.0</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>male</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>Dream</td>\n",
              "      <td>43.5</td>\n",
              "      <td>18.1</td>\n",
              "      <td>202.0</td>\n",
              "      <td>3400.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>Dream</td>\n",
              "      <td>49.6</td>\n",
              "      <td>18.2</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3775.0</td>\n",
              "      <td>male</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>Dream</td>\n",
              "      <td>50.8</td>\n",
              "      <td>19.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>4100.0</td>\n",
              "      <td>male</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>Dream</td>\n",
              "      <td>50.2</td>\n",
              "      <td>18.7</td>\n",
              "      <td>198.0</td>\n",
              "      <td>3775.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>344 rows √ó 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94911484-3187-48f9-92aa-8f3b2dc94312')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94911484-3187-48f9-92aa-8f3b2dc94312 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94911484-3187-48f9-92aa-8f3b2dc94312');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9672762-1f89-473e-8b2c-23a503e1e5ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9672762-1f89-473e-8b2c-23a503e1e5ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9672762-1f89-473e-8b2c-23a503e1e5ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5b5a9e96-1e28-4d75-b3b4-e2f57de6f281\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5b5a9e96-1e28-4d75-b3b4-e2f57de6f281 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 344,\n  \"fields\": [\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Adelie\",\n          \"Gentoo\",\n          \"Chinstrap\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"island\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Torgersen\",\n          \"Biscoe\",\n          \"Dream\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bill_length_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.4595837139265315,\n        \"min\": 32.1,\n        \"max\": 59.6,\n        \"num_unique_values\": 164,\n        \"samples\": [\n          49.4,\n          43.8,\n          43.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bill_depth_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9747931568167818,\n        \"min\": 13.1,\n        \"max\": 21.5,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          16.9,\n          18.7,\n          18.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flipper_length_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.061713679356888,\n        \"min\": 172.0,\n        \"max\": 231.0,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          201.0,\n          180.0,\n          211.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body_mass_g\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 801.9545356980958,\n        \"min\": 2700.0,\n        \"max\": 6300.0,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          4350.0,\n          4150.0,\n          5700.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2007,\n        \"max\": 2009,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2007,\n          2008\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            },
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/81954c9606dcf997/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.1,\n            'f': \"39.1\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3750.0,\n            'f': \"3750.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.5,\n            'f': \"39.5\",\n        },\n{\n            'v': 17.4,\n            'f': \"17.4\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 40.3,\n            'f': \"40.3\",\n        },\n{\n            'v': 18.0,\n            'f': \"18.0\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3250.0,\n            'f': \"3250.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 36.7,\n            'f': \"36.7\",\n        },\n{\n            'v': 19.3,\n            'f': \"19.3\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.3,\n            'f': \"39.3\",\n        },\n{\n            'v': 20.6,\n            'f': \"20.6\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.9,\n            'f': \"38.9\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3625.0,\n            'f': \"3625.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 7,\n            'f': \"7\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.2,\n            'f': \"39.2\",\n        },\n{\n            'v': 19.6,\n            'f': \"19.6\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4675.0,\n            'f': \"4675.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 8,\n            'f': \"8\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 34.1,\n            'f': \"34.1\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3475.0,\n            'f': \"3475.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 9,\n            'f': \"9\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 42.0,\n            'f': \"42.0\",\n        },\n{\n            'v': 20.2,\n            'f': \"20.2\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 4250.0,\n            'f': \"4250.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 10,\n            'f': \"10\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 37.8,\n            'f': \"37.8\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 11,\n            'f': \"11\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 37.8,\n            'f': \"37.8\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 180.0,\n            'f': \"180.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 12,\n            'f': \"12\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 17.6,\n            'f': \"17.6\",\n        },\n{\n            'v': 182.0,\n            'f': \"182.0\",\n        },\n{\n            'v': 3200.0,\n            'f': \"3200.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 13,\n            'f': \"13\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.6,\n            'f': \"38.6\",\n        },\n{\n            'v': 21.2,\n            'f': \"21.2\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 14,\n            'f': \"14\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 34.6,\n            'f': \"34.6\",\n        },\n{\n            'v': 21.1,\n            'f': \"21.1\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 15,\n            'f': \"15\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 36.6,\n            'f': \"36.6\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 16,\n            'f': \"16\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.7,\n            'f': \"38.7\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 17,\n            'f': \"17\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 42.5,\n            'f': \"42.5\",\n        },\n{\n            'v': 20.7,\n            'f': \"20.7\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 4500.0,\n            'f': \"4500.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 18,\n            'f': \"18\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 34.4,\n            'f': \"34.4\",\n        },\n{\n            'v': 18.4,\n            'f': \"18.4\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 3325.0,\n            'f': \"3325.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 19,\n            'f': \"19\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 46.0,\n            'f': \"46.0\",\n        },\n{\n            'v': 21.5,\n            'f': \"21.5\",\n        },\n{\n            'v': 194.0,\n            'f': \"194.0\",\n        },\n{\n            'v': 4200.0,\n            'f': \"4200.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 20,\n            'f': \"20\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.8,\n            'f': \"37.8\",\n        },\n{\n            'v': 18.3,\n            'f': \"18.3\",\n        },\n{\n            'v': 174.0,\n            'f': \"174.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 21,\n            'f': \"21\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.7,\n            'f': \"37.7\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 180.0,\n            'f': \"180.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 22,\n            'f': \"22\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.9,\n            'f': \"35.9\",\n        },\n{\n            'v': 19.2,\n            'f': \"19.2\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 23,\n            'f': \"23\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.2,\n            'f': \"38.2\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 24,\n            'f': \"24\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.8,\n            'f': \"38.8\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 180.0,\n            'f': \"180.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 25,\n            'f': \"25\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.3,\n            'f': \"35.3\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 26,\n            'f': \"26\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 40.6,\n            'f': \"40.6\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 183.0,\n            'f': \"183.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 27,\n            'f': \"27\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 40.5,\n            'f': \"40.5\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3200.0,\n            'f': \"3200.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 28,\n            'f': \"28\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.9,\n            'f': \"37.9\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 172.0,\n            'f': \"172.0\",\n        },\n{\n            'v': 3150.0,\n            'f': \"3150.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 29,\n            'f': \"29\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 40.5,\n            'f': \"40.5\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 180.0,\n            'f': \"180.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 30,\n            'f': \"30\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.5,\n            'f': \"39.5\",\n        },\n{\n            'v': 16.7,\n            'f': \"16.7\",\n        },\n{\n            'v': 178.0,\n            'f': \"178.0\",\n        },\n{\n            'v': 3250.0,\n            'f': \"3250.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 31,\n            'f': \"31\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.2,\n            'f': \"37.2\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 178.0,\n            'f': \"178.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 32,\n            'f': \"32\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.5,\n            'f': \"39.5\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 33,\n            'f': \"33\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.9,\n            'f': \"40.9\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 34,\n            'f': \"34\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.4,\n            'f': \"36.4\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3325.0,\n            'f': \"3325.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 35,\n            'f': \"35\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.2,\n            'f': \"39.2\",\n        },\n{\n            'v': 21.1,\n            'f': \"21.1\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 36,\n            'f': \"36\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 38.8,\n            'f': \"38.8\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 37,\n            'f': \"37\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 42.2,\n            'f': \"42.2\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 180.0,\n            'f': \"180.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 38,\n            'f': \"38\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.6,\n            'f': \"37.6\",\n        },\n{\n            'v': 19.3,\n            'f': \"19.3\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 39,\n            'f': \"39\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.8,\n            'f': \"39.8\",\n        },\n{\n            'v': 19.1,\n            'f': \"19.1\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 4650.0,\n            'f': \"4650.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 40,\n            'f': \"40\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.5,\n            'f': \"36.5\",\n        },\n{\n            'v': 18.0,\n            'f': \"18.0\",\n        },\n{\n            'v': 182.0,\n            'f': \"182.0\",\n        },\n{\n            'v': 3150.0,\n            'f': \"3150.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 41,\n            'f': \"41\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.8,\n            'f': \"40.8\",\n        },\n{\n            'v': 18.4,\n            'f': \"18.4\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 42,\n            'f': \"42\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.0,\n            'f': \"36.0\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3100.0,\n            'f': \"3100.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 43,\n            'f': \"43\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 44.1,\n            'f': \"44.1\",\n        },\n{\n            'v': 19.7,\n            'f': \"19.7\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 44,\n            'f': \"44\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.0,\n            'f': \"37.0\",\n        },\n{\n            'v': 16.9,\n            'f': \"16.9\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3000.0,\n            'f': \"3000.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 45,\n            'f': \"45\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.6,\n            'f': \"39.6\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 4600.0,\n            'f': \"4600.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 46,\n            'f': \"46\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 182.0,\n            'f': \"182.0\",\n        },\n{\n            'v': 3425.0,\n            'f': \"3425.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 47,\n            'f': \"47\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.5,\n            'f': \"37.5\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 179.0,\n            'f': \"179.0\",\n        },\n{\n            'v': 2975.0,\n            'f': \"2975.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 48,\n            'f': \"48\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.0,\n            'f': \"36.0\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 49,\n            'f': \"49\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 42.3,\n            'f': \"42.3\",\n        },\n{\n            'v': 21.2,\n            'f': \"21.2\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 50,\n            'f': \"50\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 39.6,\n            'f': \"39.6\",\n        },\n{\n            'v': 17.7,\n            'f': \"17.7\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 51,\n            'f': \"51\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 40.1,\n            'f': \"40.1\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 52,\n            'f': \"52\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.0,\n            'f': \"35.0\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 53,\n            'f': \"53\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 42.0,\n            'f': \"42.0\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 200.0,\n            'f': \"200.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 54,\n            'f': \"54\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 34.5,\n            'f': \"34.5\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 2900.0,\n            'f': \"2900.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 55,\n            'f': \"55\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.4,\n            'f': \"41.4\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 56,\n            'f': \"56\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 39.0,\n            'f': \"39.0\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 57,\n            'f': \"57\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 40.6,\n            'f': \"40.6\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 58,\n            'f': \"58\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 36.5,\n            'f': \"36.5\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 2850.0,\n            'f': \"2850.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 59,\n            'f': \"59\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.6,\n            'f': \"37.6\",\n        },\n{\n            'v': 19.1,\n            'f': \"19.1\",\n        },\n{\n            'v': 194.0,\n            'f': \"194.0\",\n        },\n{\n            'v': 3750.0,\n            'f': \"3750.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 60,\n            'f': \"60\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.7,\n            'f': \"35.7\",\n        },\n{\n            'v': 16.9,\n            'f': \"16.9\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3150.0,\n            'f': \"3150.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 61,\n            'f': \"61\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.3,\n            'f': \"41.3\",\n        },\n{\n            'v': 21.1,\n            'f': \"21.1\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 62,\n            'f': \"62\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.6,\n            'f': \"37.6\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 63,\n            'f': \"63\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 18.2,\n            'f': \"18.2\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 64,\n            'f': \"64\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 36.4,\n            'f': \"36.4\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 2850.0,\n            'f': \"2850.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 65,\n            'f': \"65\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.6,\n            'f': \"41.6\",\n        },\n{\n            'v': 18.0,\n            'f': \"18.0\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 66,\n            'f': \"66\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.5,\n            'f': \"35.5\",\n        },\n{\n            'v': 16.2,\n            'f': \"16.2\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3350.0,\n            'f': \"3350.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 67,\n            'f': \"67\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 19.1,\n            'f': \"19.1\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 4100.0,\n            'f': \"4100.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 68,\n            'f': \"68\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 35.9,\n            'f': \"35.9\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3050.0,\n            'f': \"3050.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 69,\n            'f': \"69\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 41.8,\n            'f': \"41.8\",\n        },\n{\n            'v': 19.4,\n            'f': \"19.4\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 4450.0,\n            'f': \"4450.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 70,\n            'f': \"70\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 33.5,\n            'f': \"33.5\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 71,\n            'f': \"71\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.7,\n            'f': \"39.7\",\n        },\n{\n            'v': 18.4,\n            'f': \"18.4\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 72,\n            'f': \"72\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.6,\n            'f': \"39.6\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 73,\n            'f': \"73\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 45.8,\n            'f': \"45.8\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 74,\n            'f': \"74\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 35.5,\n            'f': \"35.5\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 75,\n            'f': \"75\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 42.8,\n            'f': \"42.8\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4250.0,\n            'f': \"4250.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 76,\n            'f': \"76\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 40.9,\n            'f': \"40.9\",\n        },\n{\n            'v': 16.8,\n            'f': \"16.8\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 77,\n            'f': \"77\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 37.2,\n            'f': \"37.2\",\n        },\n{\n            'v': 19.4,\n            'f': \"19.4\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 78,\n            'f': \"78\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 36.2,\n            'f': \"36.2\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 79,\n            'f': \"79\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 42.1,\n            'f': \"42.1\",\n        },\n{\n            'v': 19.1,\n            'f': \"19.1\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4000.0,\n            'f': \"4000.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 80,\n            'f': \"80\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 34.6,\n            'f': \"34.6\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3200.0,\n            'f': \"3200.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 81,\n            'f': \"81\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 42.9,\n            'f': \"42.9\",\n        },\n{\n            'v': 17.6,\n            'f': \"17.6\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 82,\n            'f': \"82\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 36.7,\n            'f': \"36.7\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 83,\n            'f': \"83\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 35.1,\n            'f': \"35.1\",\n        },\n{\n            'v': 19.4,\n            'f': \"19.4\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 4200.0,\n            'f': \"4200.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 84,\n            'f': \"84\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.3,\n            'f': \"37.3\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3350.0,\n            'f': \"3350.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 85,\n            'f': \"85\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 41.3,\n            'f': \"41.3\",\n        },\n{\n            'v': 20.3,\n            'f': \"20.3\",\n        },\n{\n            'v': 194.0,\n            'f': \"194.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 86,\n            'f': \"86\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.3,\n            'f': \"36.3\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 87,\n            'f': \"87\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.9,\n            'f': \"36.9\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 88,\n            'f': \"88\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 38.3,\n            'f': \"38.3\",\n        },\n{\n            'v': 19.2,\n            'f': \"19.2\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 89,\n            'f': \"89\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 38.9,\n            'f': \"38.9\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 90,\n            'f': \"90\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 35.7,\n            'f': \"35.7\",\n        },\n{\n            'v': 18.0,\n            'f': \"18.0\",\n        },\n{\n            'v': 202.0,\n            'f': \"202.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 91,\n            'f': \"91\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 205.0,\n            'f': \"205.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 92,\n            'f': \"92\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 34.0,\n            'f': \"34.0\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 93,\n            'f': \"93\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.6,\n            'f': \"39.6\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 4450.0,\n            'f': \"4450.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 94,\n            'f': \"94\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.2,\n            'f': \"36.2\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 95,\n            'f': \"95\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.8,\n            'f': \"40.8\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 96,\n            'f': \"96\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 38.1,\n            'f': \"38.1\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 97,\n            'f': \"97\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.3,\n            'f': \"40.3\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 4350.0,\n            'f': \"4350.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 98,\n            'f': \"98\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 33.1,\n            'f': \"33.1\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 178.0,\n            'f': \"178.0\",\n        },\n{\n            'v': 2900.0,\n            'f': \"2900.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 99,\n            'f': \"99\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 43.2,\n            'f': \"43.2\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 4100.0,\n            'f': \"4100.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 100,\n            'f': \"100\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 35.0,\n            'f': \"35.0\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 3725.0,\n            'f': \"3725.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 101,\n            'f': \"101\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 41.0,\n            'f': \"41.0\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        },\n{\n            'v': 4725.0,\n            'f': \"4725.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 102,\n            'f': \"102\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.7,\n            'f': \"37.7\",\n        },\n{\n            'v': 16.0,\n            'f': \"16.0\",\n        },\n{\n            'v': 183.0,\n            'f': \"183.0\",\n        },\n{\n            'v': 3075.0,\n            'f': \"3075.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 103,\n            'f': \"103\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.8,\n            'f': \"37.8\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 4250.0,\n            'f': \"4250.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 104,\n            'f': \"104\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 37.9,\n            'f': \"37.9\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 2925.0,\n            'f': \"2925.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 105,\n            'f': \"105\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 39.7,\n            'f': \"39.7\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 106,\n            'f': \"106\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.6,\n            'f': \"38.6\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 3750.0,\n            'f': \"3750.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 107,\n            'f': \"107\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.2,\n            'f': \"38.2\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 108,\n            'f': \"108\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.1,\n            'f': \"38.1\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3175.0,\n            'f': \"3175.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 109,\n            'f': \"109\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 43.2,\n            'f': \"43.2\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 4775.0,\n            'f': \"4775.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 110,\n            'f': \"110\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 38.1,\n            'f': \"38.1\",\n        },\n{\n            'v': 16.5,\n            'f': \"16.5\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3825.0,\n            'f': \"3825.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 111,\n            'f': \"111\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 45.6,\n            'f': \"45.6\",\n        },\n{\n            'v': 20.3,\n            'f': \"20.3\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 4600.0,\n            'f': \"4600.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 112,\n            'f': \"112\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 39.7,\n            'f': \"39.7\",\n        },\n{\n            'v': 17.7,\n            'f': \"17.7\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3200.0,\n            'f': \"3200.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 113,\n            'f': \"113\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 42.2,\n            'f': \"42.2\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 4275.0,\n            'f': \"4275.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 114,\n            'f': \"114\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 39.6,\n            'f': \"39.6\",\n        },\n{\n            'v': 20.7,\n            'f': \"20.7\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 115,\n            'f': \"115\",\n        },\n\"Adelie\",\n\"Biscoe\",\n{\n            'v': 42.7,\n            'f': \"42.7\",\n        },\n{\n            'v': 18.3,\n            'f': \"18.3\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 4075.0,\n            'f': \"4075.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 116,\n            'f': \"116\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.6,\n            'f': \"38.6\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 2900.0,\n            'f': \"2900.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 117,\n            'f': \"117\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 37.3,\n            'f': \"37.3\",\n        },\n{\n            'v': 20.5,\n            'f': \"20.5\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 3775.0,\n            'f': \"3775.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 118,\n            'f': \"118\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 35.7,\n            'f': \"35.7\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3350.0,\n            'f': \"3350.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 119,\n            'f': \"119\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3325.0,\n            'f': \"3325.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 120,\n            'f': \"120\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 36.2,\n            'f': \"36.2\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3150.0,\n            'f': \"3150.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 121,\n            'f': \"121\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 37.7,\n            'f': \"37.7\",\n        },\n{\n            'v': 19.8,\n            'f': \"19.8\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 122,\n            'f': \"122\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 40.2,\n            'f': \"40.2\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 176.0,\n            'f': \"176.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 123,\n            'f': \"123\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 41.4,\n            'f': \"41.4\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 202.0,\n            'f': \"202.0\",\n        },\n{\n            'v': 3875.0,\n            'f': \"3875.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 124,\n            'f': \"124\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 35.2,\n            'f': \"35.2\",\n        },\n{\n            'v': 15.9,\n            'f': \"15.9\",\n        },\n{\n            'v': 186.0,\n            'f': \"186.0\",\n        },\n{\n            'v': 3050.0,\n            'f': \"3050.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 125,\n            'f': \"125\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 40.6,\n            'f': \"40.6\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 4000.0,\n            'f': \"4000.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 126,\n            'f': \"126\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.8,\n            'f': \"38.8\",\n        },\n{\n            'v': 17.6,\n            'f': \"17.6\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3275.0,\n            'f': \"3275.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 127,\n            'f': \"127\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 41.5,\n            'f': \"41.5\",\n        },\n{\n            'v': 18.3,\n            'f': \"18.3\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 128,\n            'f': \"128\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 39.0,\n            'f': \"39.0\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3050.0,\n            'f': \"3050.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 129,\n            'f': \"129\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 44.1,\n            'f': \"44.1\",\n        },\n{\n            'v': 18.0,\n            'f': \"18.0\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4000.0,\n            'f': \"4000.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 130,\n            'f': \"130\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 38.5,\n            'f': \"38.5\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3325.0,\n            'f': \"3325.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 131,\n            'f': \"131\",\n        },\n\"Adelie\",\n\"Torgersen\",\n{\n            'v': 43.1,\n            'f': \"43.1\",\n        },\n{\n            'v': 19.2,\n            'f': \"19.2\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 132,\n            'f': \"132\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.8,\n            'f': \"36.8\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 133,\n            'f': \"133\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.5,\n            'f': \"37.5\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 4475.0,\n            'f': \"4475.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 134,\n            'f': \"134\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 38.1,\n            'f': \"38.1\",\n        },\n{\n            'v': 17.6,\n            'f': \"17.6\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3425.0,\n            'f': \"3425.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 135,\n            'f': \"135\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 41.1,\n            'f': \"41.1\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 136,\n            'f': \"136\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 35.6,\n            'f': \"35.6\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3175.0,\n            'f': \"3175.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 137,\n            'f': \"137\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.2,\n            'f': \"40.2\",\n        },\n{\n            'v': 20.1,\n            'f': \"20.1\",\n        },\n{\n            'v': 200.0,\n            'f': \"200.0\",\n        },\n{\n            'v': 3975.0,\n            'f': \"3975.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 138,\n            'f': \"138\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.0,\n            'f': \"37.0\",\n        },\n{\n            'v': 16.5,\n            'f': \"16.5\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 139,\n            'f': \"139\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.7,\n            'f': \"39.7\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 4250.0,\n            'f': \"4250.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 140,\n            'f': \"140\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.2,\n            'f': \"40.2\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 141,\n            'f': \"141\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.6,\n            'f': \"40.6\",\n        },\n{\n            'v': 17.2,\n            'f': \"17.2\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3475.0,\n            'f': \"3475.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 142,\n            'f': \"142\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 32.1,\n            'f': \"32.1\",\n        },\n{\n            'v': 15.5,\n            'f': \"15.5\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 3050.0,\n            'f': \"3050.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 143,\n            'f': \"143\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 40.7,\n            'f': \"40.7\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3725.0,\n            'f': \"3725.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 144,\n            'f': \"144\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.3,\n            'f': \"37.3\",\n        },\n{\n            'v': 16.8,\n            'f': \"16.8\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 3000.0,\n            'f': \"3000.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 145,\n            'f': \"145\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.0,\n            'f': \"39.0\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 146,\n            'f': \"146\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 39.2,\n            'f': \"39.2\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 4250.0,\n            'f': \"4250.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 147,\n            'f': \"147\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.6,\n            'f': \"36.6\",\n        },\n{\n            'v': 18.4,\n            'f': \"18.4\",\n        },\n{\n            'v': 184.0,\n            'f': \"184.0\",\n        },\n{\n            'v': 3475.0,\n            'f': \"3475.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 148,\n            'f': \"148\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.0,\n            'f': \"36.0\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 149,\n            'f': \"149\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 37.8,\n            'f': \"37.8\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3750.0,\n            'f': \"3750.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 150,\n            'f': \"150\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 36.0,\n            'f': \"36.0\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 151,\n            'f': \"151\",\n        },\n\"Adelie\",\n\"Dream\",\n{\n            'v': 41.5,\n            'f': \"41.5\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 4000.0,\n            'f': \"4000.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 152,\n            'f': \"152\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.1,\n            'f': \"46.1\",\n        },\n{\n            'v': 13.2,\n            'f': \"13.2\",\n        },\n{\n            'v': 211.0,\n            'f': \"211.0\",\n        },\n{\n            'v': 4500.0,\n            'f': \"4500.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 153,\n            'f': \"153\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.0,\n            'f': \"50.0\",\n        },\n{\n            'v': 16.3,\n            'f': \"16.3\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5700.0,\n            'f': \"5700.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 154,\n            'f': \"154\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.7,\n            'f': \"48.7\",\n        },\n{\n            'v': 14.1,\n            'f': \"14.1\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4450.0,\n            'f': \"4450.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 155,\n            'f': \"155\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.0,\n            'f': \"50.0\",\n        },\n{\n            'v': 15.2,\n            'f': \"15.2\",\n        },\n{\n            'v': 218.0,\n            'f': \"218.0\",\n        },\n{\n            'v': 5700.0,\n            'f': \"5700.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 156,\n            'f': \"156\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.6,\n            'f': \"47.6\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5400.0,\n            'f': \"5400.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 157,\n            'f': \"157\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.5,\n            'f': \"46.5\",\n        },\n{\n            'v': 13.5,\n            'f': \"13.5\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4550.0,\n            'f': \"4550.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 158,\n            'f': \"158\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.4,\n            'f': \"45.4\",\n        },\n{\n            'v': 14.6,\n            'f': \"14.6\",\n        },\n{\n            'v': 211.0,\n            'f': \"211.0\",\n        },\n{\n            'v': 4800.0,\n            'f': \"4800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 159,\n            'f': \"159\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.7,\n            'f': \"46.7\",\n        },\n{\n            'v': 15.3,\n            'f': \"15.3\",\n        },\n{\n            'v': 219.0,\n            'f': \"219.0\",\n        },\n{\n            'v': 5200.0,\n            'f': \"5200.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 160,\n            'f': \"160\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.3,\n            'f': \"43.3\",\n        },\n{\n            'v': 13.4,\n            'f': \"13.4\",\n        },\n{\n            'v': 209.0,\n            'f': \"209.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 161,\n            'f': \"161\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.8,\n            'f': \"46.8\",\n        },\n{\n            'v': 15.4,\n            'f': \"15.4\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5150.0,\n            'f': \"5150.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 162,\n            'f': \"162\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 40.9,\n            'f': \"40.9\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4650.0,\n            'f': \"4650.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 163,\n            'f': \"163\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.0,\n            'f': \"49.0\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 164,\n            'f': \"164\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.5,\n            'f': \"45.5\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4650.0,\n            'f': \"4650.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 165,\n            'f': \"165\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.4,\n            'f': \"48.4\",\n        },\n{\n            'v': 14.6,\n            'f': \"14.6\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 5850.0,\n            'f': \"5850.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 166,\n            'f': \"166\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.8,\n            'f': \"45.8\",\n        },\n{\n            'v': 14.6,\n            'f': \"14.6\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4200.0,\n            'f': \"4200.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 167,\n            'f': \"167\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.3,\n            'f': \"49.3\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 5850.0,\n            'f': \"5850.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 168,\n            'f': \"168\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 42.0,\n            'f': \"42.0\",\n        },\n{\n            'v': 13.5,\n            'f': \"13.5\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 169,\n            'f': \"169\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.2,\n            'f': \"49.2\",\n        },\n{\n            'v': 15.2,\n            'f': \"15.2\",\n        },\n{\n            'v': 221.0,\n            'f': \"221.0\",\n        },\n{\n            'v': 6300.0,\n            'f': \"6300.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 170,\n            'f': \"170\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.2,\n            'f': \"46.2\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 209.0,\n            'f': \"209.0\",\n        },\n{\n            'v': 4800.0,\n            'f': \"4800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 171,\n            'f': \"171\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.7,\n            'f': \"48.7\",\n        },\n{\n            'v': 15.1,\n            'f': \"15.1\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 5350.0,\n            'f': \"5350.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 172,\n            'f': \"172\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.2,\n            'f': \"50.2\",\n        },\n{\n            'v': 14.3,\n            'f': \"14.3\",\n        },\n{\n            'v': 218.0,\n            'f': \"218.0\",\n        },\n{\n            'v': 5700.0,\n            'f': \"5700.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 173,\n            'f': \"173\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.1,\n            'f': \"45.1\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 174,\n            'f': \"174\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.5,\n            'f': \"46.5\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 175,\n            'f': \"175\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.3,\n            'f': \"46.3\",\n        },\n{\n            'v': 15.8,\n            'f': \"15.8\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5050.0,\n            'f': \"5050.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 176,\n            'f': \"176\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 42.9,\n            'f': \"42.9\",\n        },\n{\n            'v': 13.1,\n            'f': \"13.1\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 177,\n            'f': \"177\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.1,\n            'f': \"46.1\",\n        },\n{\n            'v': 15.1,\n            'f': \"15.1\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5100.0,\n            'f': \"5100.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 178,\n            'f': \"178\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.5,\n            'f': \"44.5\",\n        },\n{\n            'v': 14.3,\n            'f': \"14.3\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4100.0,\n            'f': \"4100.0\",\n        },\nNaN,\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 179,\n            'f': \"179\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.8,\n            'f': \"47.8\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5650.0,\n            'f': \"5650.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 180,\n            'f': \"180\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.2,\n            'f': \"48.2\",\n        },\n{\n            'v': 14.3,\n            'f': \"14.3\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4600.0,\n            'f': \"4600.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 181,\n            'f': \"181\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.0,\n            'f': \"50.0\",\n        },\n{\n            'v': 15.3,\n            'f': \"15.3\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 182,\n            'f': \"182\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.3,\n            'f': \"47.3\",\n        },\n{\n            'v': 15.3,\n            'f': \"15.3\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 5250.0,\n            'f': \"5250.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 183,\n            'f': \"183\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 42.8,\n            'f': \"42.8\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 209.0,\n            'f': \"209.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 184,\n            'f': \"184\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.1,\n            'f': \"45.1\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 207.0,\n            'f': \"207.0\",\n        },\n{\n            'v': 5050.0,\n            'f': \"5050.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 185,\n            'f': \"185\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 59.6,\n            'f': \"59.6\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 6050.0,\n            'f': \"6050.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 186,\n            'f': \"186\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.1,\n            'f': \"49.1\",\n        },\n{\n            'v': 14.8,\n            'f': \"14.8\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5150.0,\n            'f': \"5150.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 187,\n            'f': \"187\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.4,\n            'f': \"48.4\",\n        },\n{\n            'v': 16.3,\n            'f': \"16.3\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5400.0,\n            'f': \"5400.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 188,\n            'f': \"188\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 42.6,\n            'f': \"42.6\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 4950.0,\n            'f': \"4950.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 189,\n            'f': \"189\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.4,\n            'f': \"44.4\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 219.0,\n            'f': \"219.0\",\n        },\n{\n            'v': 5250.0,\n            'f': \"5250.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 190,\n            'f': \"190\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.0,\n            'f': \"44.0\",\n        },\n{\n            'v': 13.6,\n            'f': \"13.6\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4350.0,\n            'f': \"4350.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 191,\n            'f': \"191\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.7,\n            'f': \"48.7\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 5350.0,\n            'f': \"5350.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 192,\n            'f': \"192\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 42.7,\n            'f': \"42.7\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 193,\n            'f': \"193\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.6,\n            'f': \"49.6\",\n        },\n{\n            'v': 16.0,\n            'f': \"16.0\",\n        },\n{\n            'v': 225.0,\n            'f': \"225.0\",\n        },\n{\n            'v': 5700.0,\n            'f': \"5700.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 194,\n            'f': \"194\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.3,\n            'f': \"45.3\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 195,\n            'f': \"195\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.6,\n            'f': \"49.6\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4750.0,\n            'f': \"4750.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 196,\n            'f': \"196\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.5,\n            'f': \"50.5\",\n        },\n{\n            'v': 15.9,\n            'f': \"15.9\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 197,\n            'f': \"197\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.6,\n            'f': \"43.6\",\n        },\n{\n            'v': 13.9,\n            'f': \"13.9\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 4900.0,\n            'f': \"4900.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 198,\n            'f': \"198\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.5,\n            'f': \"45.5\",\n        },\n{\n            'v': 13.9,\n            'f': \"13.9\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4200.0,\n            'f': \"4200.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 199,\n            'f': \"199\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.5,\n            'f': \"50.5\",\n        },\n{\n            'v': 15.9,\n            'f': \"15.9\",\n        },\n{\n            'v': 225.0,\n            'f': \"225.0\",\n        },\n{\n            'v': 5400.0,\n            'f': \"5400.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 200,\n            'f': \"200\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.9,\n            'f': \"44.9\",\n        },\n{\n            'v': 13.3,\n            'f': \"13.3\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 5100.0,\n            'f': \"5100.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 201,\n            'f': \"201\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 15.8,\n            'f': \"15.8\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5300.0,\n            'f': \"5300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 202,\n            'f': \"202\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.6,\n            'f': \"46.6\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4850.0,\n            'f': \"4850.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 203,\n            'f': \"203\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.5,\n            'f': \"48.5\",\n        },\n{\n            'v': 14.1,\n            'f': \"14.1\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5300.0,\n            'f': \"5300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 204,\n            'f': \"204\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.1,\n            'f': \"45.1\",\n        },\n{\n            'v': 14.4,\n            'f': \"14.4\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 205,\n            'f': \"205\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.1,\n            'f': \"50.1\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 225.0,\n            'f': \"225.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 206,\n            'f': \"206\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.5,\n            'f': \"46.5\",\n        },\n{\n            'v': 14.4,\n            'f': \"14.4\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 4900.0,\n            'f': \"4900.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 207,\n            'f': \"207\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.0,\n            'f': \"45.0\",\n        },\n{\n            'v': 15.4,\n            'f': \"15.4\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5050.0,\n            'f': \"5050.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 208,\n            'f': \"208\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.8,\n            'f': \"43.8\",\n        },\n{\n            'v': 13.9,\n            'f': \"13.9\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 209,\n            'f': \"209\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.5,\n            'f': \"45.5\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 210,\n            'f': \"210\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.2,\n            'f': \"43.2\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4450.0,\n            'f': \"4450.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 211,\n            'f': \"211\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.4,\n            'f': \"50.4\",\n        },\n{\n            'v': 15.3,\n            'f': \"15.3\",\n        },\n{\n            'v': 224.0,\n            'f': \"224.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 212,\n            'f': \"212\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.3,\n            'f': \"45.3\",\n        },\n{\n            'v': 13.8,\n            'f': \"13.8\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4200.0,\n            'f': \"4200.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 213,\n            'f': \"213\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.2,\n            'f': \"46.2\",\n        },\n{\n            'v': 14.9,\n            'f': \"14.9\",\n        },\n{\n            'v': 221.0,\n            'f': \"221.0\",\n        },\n{\n            'v': 5300.0,\n            'f': \"5300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 214,\n            'f': \"214\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.7,\n            'f': \"45.7\",\n        },\n{\n            'v': 13.9,\n            'f': \"13.9\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 215,\n            'f': \"215\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 54.3,\n            'f': \"54.3\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 231.0,\n            'f': \"231.0\",\n        },\n{\n            'v': 5650.0,\n            'f': \"5650.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 216,\n            'f': \"216\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.8,\n            'f': \"45.8\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 219.0,\n            'f': \"219.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 217,\n            'f': \"217\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.8,\n            'f': \"49.8\",\n        },\n{\n            'v': 16.8,\n            'f': \"16.8\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5700.0,\n            'f': \"5700.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 218,\n            'f': \"218\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.2,\n            'f': \"46.2\",\n        },\n{\n            'v': 14.4,\n            'f': \"14.4\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4650.0,\n            'f': \"4650.0\",\n        },\nNaN,\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 219,\n            'f': \"219\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.5,\n            'f': \"49.5\",\n        },\n{\n            'v': 16.2,\n            'f': \"16.2\",\n        },\n{\n            'v': 229.0,\n            'f': \"229.0\",\n        },\n{\n            'v': 5800.0,\n            'f': \"5800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 220,\n            'f': \"220\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.5,\n            'f': \"43.5\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 221,\n            'f': \"221\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.7,\n            'f': \"50.7\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 223.0,\n            'f': \"223.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 222,\n            'f': \"222\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.7,\n            'f': \"47.7\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4750.0,\n            'f': \"4750.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 223,\n            'f': \"223\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.4,\n            'f': \"46.4\",\n        },\n{\n            'v': 15.6,\n            'f': \"15.6\",\n        },\n{\n            'v': 221.0,\n            'f': \"221.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 224,\n            'f': \"224\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.2,\n            'f': \"48.2\",\n        },\n{\n            'v': 15.6,\n            'f': \"15.6\",\n        },\n{\n            'v': 221.0,\n            'f': \"221.0\",\n        },\n{\n            'v': 5100.0,\n            'f': \"5100.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 225,\n            'f': \"225\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.5,\n            'f': \"46.5\",\n        },\n{\n            'v': 14.8,\n            'f': \"14.8\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 5200.0,\n            'f': \"5200.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 226,\n            'f': \"226\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.4,\n            'f': \"46.4\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 227,\n            'f': \"227\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.6,\n            'f': \"48.6\",\n        },\n{\n            'v': 16.0,\n            'f': \"16.0\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5800.0,\n            'f': \"5800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 228,\n            'f': \"228\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.5,\n            'f': \"47.5\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 209.0,\n            'f': \"209.0\",\n        },\n{\n            'v': 4600.0,\n            'f': \"4600.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 229,\n            'f': \"229\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 51.1,\n            'f': \"51.1\",\n        },\n{\n            'v': 16.3,\n            'f': \"16.3\",\n        },\n{\n            'v': 220.0,\n            'f': \"220.0\",\n        },\n{\n            'v': 6000.0,\n            'f': \"6000.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 230,\n            'f': \"230\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 13.8,\n            'f': \"13.8\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 4750.0,\n            'f': \"4750.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 231,\n            'f': \"231\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 16.4,\n            'f': \"16.4\",\n        },\n{\n            'v': 223.0,\n            'f': \"223.0\",\n        },\n{\n            'v': 5950.0,\n            'f': \"5950.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 232,\n            'f': \"232\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.1,\n            'f': \"49.1\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4625.0,\n            'f': \"4625.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 233,\n            'f': \"233\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 52.5,\n            'f': \"52.5\",\n        },\n{\n            'v': 15.6,\n            'f': \"15.6\",\n        },\n{\n            'v': 221.0,\n            'f': \"221.0\",\n        },\n{\n            'v': 5450.0,\n            'f': \"5450.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 234,\n            'f': \"234\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.4,\n            'f': \"47.4\",\n        },\n{\n            'v': 14.6,\n            'f': \"14.6\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4725.0,\n            'f': \"4725.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 235,\n            'f': \"235\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.0,\n            'f': \"50.0\",\n        },\n{\n            'v': 15.9,\n            'f': \"15.9\",\n        },\n{\n            'v': 224.0,\n            'f': \"224.0\",\n        },\n{\n            'v': 5350.0,\n            'f': \"5350.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 236,\n            'f': \"236\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.9,\n            'f': \"44.9\",\n        },\n{\n            'v': 13.8,\n            'f': \"13.8\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4750.0,\n            'f': \"4750.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 237,\n            'f': \"237\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.8,\n            'f': \"50.8\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 228.0,\n            'f': \"228.0\",\n        },\n{\n            'v': 5600.0,\n            'f': \"5600.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 238,\n            'f': \"238\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.4,\n            'f': \"43.4\",\n        },\n{\n            'v': 14.4,\n            'f': \"14.4\",\n        },\n{\n            'v': 218.0,\n            'f': \"218.0\",\n        },\n{\n            'v': 4600.0,\n            'f': \"4600.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 239,\n            'f': \"239\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 51.3,\n            'f': \"51.3\",\n        },\n{\n            'v': 14.2,\n            'f': \"14.2\",\n        },\n{\n            'v': 218.0,\n            'f': \"218.0\",\n        },\n{\n            'v': 5300.0,\n            'f': \"5300.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 240,\n            'f': \"240\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.5,\n            'f': \"47.5\",\n        },\n{\n            'v': 14.0,\n            'f': \"14.0\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4875.0,\n            'f': \"4875.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 241,\n            'f': \"241\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 52.1,\n            'f': \"52.1\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5550.0,\n            'f': \"5550.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 242,\n            'f': \"242\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.5,\n            'f': \"47.5\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 218.0,\n            'f': \"218.0\",\n        },\n{\n            'v': 4950.0,\n            'f': \"4950.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 243,\n            'f': \"243\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 52.2,\n            'f': \"52.2\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 228.0,\n            'f': \"228.0\",\n        },\n{\n            'v': 5400.0,\n            'f': \"5400.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 244,\n            'f': \"244\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.5,\n            'f': \"45.5\",\n        },\n{\n            'v': 14.5,\n            'f': \"14.5\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4750.0,\n            'f': \"4750.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 245,\n            'f': \"245\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.5,\n            'f': \"49.5\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 224.0,\n            'f': \"224.0\",\n        },\n{\n            'v': 5650.0,\n            'f': \"5650.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 246,\n            'f': \"246\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.5,\n            'f': \"44.5\",\n        },\n{\n            'v': 14.7,\n            'f': \"14.7\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4850.0,\n            'f': \"4850.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 247,\n            'f': \"247\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.8,\n            'f': \"50.8\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 226.0,\n            'f': \"226.0\",\n        },\n{\n            'v': 5200.0,\n            'f': \"5200.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 248,\n            'f': \"248\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.4,\n            'f': \"49.4\",\n        },\n{\n            'v': 15.8,\n            'f': \"15.8\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4925.0,\n            'f': \"4925.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 249,\n            'f': \"249\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.9,\n            'f': \"46.9\",\n        },\n{\n            'v': 14.6,\n            'f': \"14.6\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 4875.0,\n            'f': \"4875.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 250,\n            'f': \"250\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.4,\n            'f': \"48.4\",\n        },\n{\n            'v': 14.4,\n            'f': \"14.4\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        },\n{\n            'v': 4625.0,\n            'f': \"4625.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 251,\n            'f': \"251\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 51.1,\n            'f': \"51.1\",\n        },\n{\n            'v': 16.5,\n            'f': \"16.5\",\n        },\n{\n            'v': 225.0,\n            'f': \"225.0\",\n        },\n{\n            'v': 5250.0,\n            'f': \"5250.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 252,\n            'f': \"252\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.5,\n            'f': \"48.5\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 219.0,\n            'f': \"219.0\",\n        },\n{\n            'v': 4850.0,\n            'f': \"4850.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 253,\n            'f': \"253\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 55.9,\n            'f': \"55.9\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 228.0,\n            'f': \"228.0\",\n        },\n{\n            'v': 5600.0,\n            'f': \"5600.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 254,\n            'f': \"254\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.2,\n            'f': \"47.2\",\n        },\n{\n            'v': 15.5,\n            'f': \"15.5\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 4975.0,\n            'f': \"4975.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 255,\n            'f': \"255\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.1,\n            'f': \"49.1\",\n        },\n{\n            'v': 15.0,\n            'f': \"15.0\",\n        },\n{\n            'v': 228.0,\n            'f': \"228.0\",\n        },\n{\n            'v': 5500.0,\n            'f': \"5500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 256,\n            'f': \"256\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.3,\n            'f': \"47.3\",\n        },\n{\n            'v': 13.8,\n            'f': \"13.8\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 4725.0,\n            'f': \"4725.0\",\n        },\nNaN,\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 257,\n            'f': \"257\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.8,\n            'f': \"46.8\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 5500.0,\n            'f': \"5500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 258,\n            'f': \"258\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 41.7,\n            'f': \"41.7\",\n        },\n{\n            'v': 14.7,\n            'f': \"14.7\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4700.0,\n            'f': \"4700.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 259,\n            'f': \"259\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 53.4,\n            'f': \"53.4\",\n        },\n{\n            'v': 15.8,\n            'f': \"15.8\",\n        },\n{\n            'v': 219.0,\n            'f': \"219.0\",\n        },\n{\n            'v': 5500.0,\n            'f': \"5500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 260,\n            'f': \"260\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.3,\n            'f': \"43.3\",\n        },\n{\n            'v': 14.0,\n            'f': \"14.0\",\n        },\n{\n            'v': 208.0,\n            'f': \"208.0\",\n        },\n{\n            'v': 4575.0,\n            'f': \"4575.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 261,\n            'f': \"261\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.1,\n            'f': \"48.1\",\n        },\n{\n            'v': 15.1,\n            'f': \"15.1\",\n        },\n{\n            'v': 209.0,\n            'f': \"209.0\",\n        },\n{\n            'v': 5500.0,\n            'f': \"5500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 262,\n            'f': \"262\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.5,\n            'f': \"50.5\",\n        },\n{\n            'v': 15.2,\n            'f': \"15.2\",\n        },\n{\n            'v': 216.0,\n            'f': \"216.0\",\n        },\n{\n            'v': 5000.0,\n            'f': \"5000.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 263,\n            'f': \"263\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.8,\n            'f': \"49.8\",\n        },\n{\n            'v': 15.9,\n            'f': \"15.9\",\n        },\n{\n            'v': 229.0,\n            'f': \"229.0\",\n        },\n{\n            'v': 5950.0,\n            'f': \"5950.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 264,\n            'f': \"264\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 43.5,\n            'f': \"43.5\",\n        },\n{\n            'v': 15.2,\n            'f': \"15.2\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 4650.0,\n            'f': \"4650.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 265,\n            'f': \"265\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 51.5,\n            'f': \"51.5\",\n        },\n{\n            'v': 16.3,\n            'f': \"16.3\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5500.0,\n            'f': \"5500.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 266,\n            'f': \"266\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.2,\n            'f': \"46.2\",\n        },\n{\n            'v': 14.1,\n            'f': \"14.1\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 4375.0,\n            'f': \"4375.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 267,\n            'f': \"267\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 55.1,\n            'f': \"55.1\",\n        },\n{\n            'v': 16.0,\n            'f': \"16.0\",\n        },\n{\n            'v': 230.0,\n            'f': \"230.0\",\n        },\n{\n            'v': 5850.0,\n            'f': \"5850.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 268,\n            'f': \"268\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 44.5,\n            'f': \"44.5\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 217.0,\n            'f': \"217.0\",\n        },\n{\n            'v': 4875.0,\n            'f': \"4875.0\",\n        },\nNaN,\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 269,\n            'f': \"269\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 48.8,\n            'f': \"48.8\",\n        },\n{\n            'v': 16.2,\n            'f': \"16.2\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 6000.0,\n            'f': \"6000.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 270,\n            'f': \"270\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 47.2,\n            'f': \"47.2\",\n        },\n{\n            'v': 13.7,\n            'f': \"13.7\",\n        },\n{\n            'v': 214.0,\n            'f': \"214.0\",\n        },\n{\n            'v': 4925.0,\n            'f': \"4925.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 271,\n            'f': \"271\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\nNaN,\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 272,\n            'f': \"272\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 46.8,\n            'f': \"46.8\",\n        },\n{\n            'v': 14.3,\n            'f': \"14.3\",\n        },\n{\n            'v': 215.0,\n            'f': \"215.0\",\n        },\n{\n            'v': 4850.0,\n            'f': \"4850.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 273,\n            'f': \"273\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 50.4,\n            'f': \"50.4\",\n        },\n{\n            'v': 15.7,\n            'f': \"15.7\",\n        },\n{\n            'v': 222.0,\n            'f': \"222.0\",\n        },\n{\n            'v': 5750.0,\n            'f': \"5750.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 274,\n            'f': \"274\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 14.8,\n            'f': \"14.8\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 5200.0,\n            'f': \"5200.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 275,\n            'f': \"275\",\n        },\n\"Gentoo\",\n\"Biscoe\",\n{\n            'v': 49.9,\n            'f': \"49.9\",\n        },\n{\n            'v': 16.1,\n            'f': \"16.1\",\n        },\n{\n            'v': 213.0,\n            'f': \"213.0\",\n        },\n{\n            'v': 5400.0,\n            'f': \"5400.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 276,\n            'f': \"276\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.5,\n            'f': \"46.5\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 277,\n            'f': \"277\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.0,\n            'f': \"50.0\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 278,\n            'f': \"278\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.3,\n            'f': \"51.3\",\n        },\n{\n            'v': 19.2,\n            'f': \"19.2\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 279,\n            'f': \"279\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.4,\n            'f': \"45.4\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 188.0,\n            'f': \"188.0\",\n        },\n{\n            'v': 3525.0,\n            'f': \"3525.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 280,\n            'f': \"280\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.7,\n            'f': \"52.7\",\n        },\n{\n            'v': 19.8,\n            'f': \"19.8\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 3725.0,\n            'f': \"3725.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 281,\n            'f': \"281\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 282,\n            'f': \"282\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.1,\n            'f': \"46.1\",\n        },\n{\n            'v': 18.2,\n            'f': \"18.2\",\n        },\n{\n            'v': 178.0,\n            'f': \"178.0\",\n        },\n{\n            'v': 3250.0,\n            'f': \"3250.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 283,\n            'f': \"283\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.3,\n            'f': \"51.3\",\n        },\n{\n            'v': 18.2,\n            'f': \"18.2\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 3750.0,\n            'f': \"3750.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 284,\n            'f': \"284\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.0,\n            'f': \"46.0\",\n        },\n{\n            'v': 18.9,\n            'f': \"18.9\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 285,\n            'f': \"285\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.3,\n            'f': \"51.3\",\n        },\n{\n            'v': 19.9,\n            'f': \"19.9\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 286,\n            'f': \"286\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.6,\n            'f': \"46.6\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 287,\n            'f': \"287\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.7,\n            'f': \"51.7\",\n        },\n{\n            'v': 20.3,\n            'f': \"20.3\",\n        },\n{\n            'v': 194.0,\n            'f': \"194.0\",\n        },\n{\n            'v': 3775.0,\n            'f': \"3775.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 288,\n            'f': \"288\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 47.0,\n            'f': \"47.0\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 185.0,\n            'f': \"185.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 289,\n            'f': \"289\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.0,\n            'f': \"52.0\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 290,\n            'f': \"290\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.9,\n            'f': \"45.9\",\n        },\n{\n            'v': 17.1,\n            'f': \"17.1\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3575.0,\n            'f': \"3575.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 291,\n            'f': \"291\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.5,\n            'f': \"50.5\",\n        },\n{\n            'v': 19.6,\n            'f': \"19.6\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 292,\n            'f': \"292\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.3,\n            'f': \"50.3\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 293,\n            'f': \"293\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 58.0,\n            'f': \"58.0\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 294,\n            'f': \"294\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.4,\n            'f': \"46.4\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 295,\n            'f': \"295\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.2,\n            'f': \"49.2\",\n        },\n{\n            'v': 18.2,\n            'f': \"18.2\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 4400.0,\n            'f': \"4400.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 296,\n            'f': \"296\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 42.4,\n            'f': \"42.4\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 181.0,\n            'f': \"181.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 297,\n            'f': \"297\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 48.5,\n            'f': \"48.5\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 298,\n            'f': \"298\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 43.2,\n            'f': \"43.2\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 2900.0,\n            'f': \"2900.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 299,\n            'f': \"299\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.6,\n            'f': \"50.6\",\n        },\n{\n            'v': 19.4,\n            'f': \"19.4\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 300,\n            'f': \"300\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.7,\n            'f': \"46.7\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3300.0,\n            'f': \"3300.0\",\n        },\n\"female\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 301,\n            'f': \"301\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.0,\n            'f': \"52.0\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 4150.0,\n            'f': \"4150.0\",\n        },\n\"male\",\n{\n            'v': 2007,\n            'f': \"2007\",\n        }],\n [{\n            'v': 302,\n            'f': \"302\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.5,\n            'f': \"50.5\",\n        },\n{\n            'v': 18.4,\n            'f': \"18.4\",\n        },\n{\n            'v': 200.0,\n            'f': \"200.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 303,\n            'f': \"303\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.5,\n            'f': \"49.5\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 200.0,\n            'f': \"200.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 304,\n            'f': \"304\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.4,\n            'f': \"46.4\",\n        },\n{\n            'v': 17.8,\n            'f': \"17.8\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3700.0,\n            'f': \"3700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 305,\n            'f': \"305\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.8,\n            'f': \"52.8\",\n        },\n{\n            'v': 20.0,\n            'f': \"20.0\",\n        },\n{\n            'v': 205.0,\n            'f': \"205.0\",\n        },\n{\n            'v': 4550.0,\n            'f': \"4550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 306,\n            'f': \"306\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 40.9,\n            'f': \"40.9\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3200.0,\n            'f': \"3200.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 307,\n            'f': \"307\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 54.2,\n            'f': \"54.2\",\n        },\n{\n            'v': 20.8,\n            'f': \"20.8\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 308,\n            'f': \"308\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 42.5,\n            'f': \"42.5\",\n        },\n{\n            'v': 16.7,\n            'f': \"16.7\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3350.0,\n            'f': \"3350.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 309,\n            'f': \"309\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.0,\n            'f': \"51.0\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        },\n{\n            'v': 4100.0,\n            'f': \"4100.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 310,\n            'f': \"310\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.7,\n            'f': \"49.7\",\n        },\n{\n            'v': 18.6,\n            'f': \"18.6\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 311,\n            'f': \"311\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 47.5,\n            'f': \"47.5\",\n        },\n{\n            'v': 16.8,\n            'f': \"16.8\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 3900.0,\n            'f': \"3900.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 312,\n            'f': \"312\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 47.6,\n            'f': \"47.6\",\n        },\n{\n            'v': 18.3,\n            'f': \"18.3\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3850.0,\n            'f': \"3850.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 313,\n            'f': \"313\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.0,\n            'f': \"52.0\",\n        },\n{\n            'v': 20.7,\n            'f': \"20.7\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4800.0,\n            'f': \"4800.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 314,\n            'f': \"314\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.9,\n            'f': \"46.9\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 192.0,\n            'f': \"192.0\",\n        },\n{\n            'v': 2700.0,\n            'f': \"2700.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 315,\n            'f': \"315\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 53.5,\n            'f': \"53.5\",\n        },\n{\n            'v': 19.9,\n            'f': \"19.9\",\n        },\n{\n            'v': 205.0,\n            'f': \"205.0\",\n        },\n{\n            'v': 4500.0,\n            'f': \"4500.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 316,\n            'f': \"316\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.0,\n            'f': \"49.0\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 317,\n            'f': \"317\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.2,\n            'f': \"46.2\",\n        },\n{\n            'v': 17.5,\n            'f': \"17.5\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 318,\n            'f': \"318\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.9,\n            'f': \"50.9\",\n        },\n{\n            'v': 19.1,\n            'f': \"19.1\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 3550.0,\n            'f': \"3550.0\",\n        },\n\"male\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 319,\n            'f': \"319\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.5,\n            'f': \"45.5\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 3500.0,\n            'f': \"3500.0\",\n        },\n\"female\",\n{\n            'v': 2008,\n            'f': \"2008\",\n        }],\n [{\n            'v': 320,\n            'f': \"320\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.9,\n            'f': \"50.9\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 196.0,\n            'f': \"196.0\",\n        },\n{\n            'v': 3675.0,\n            'f': \"3675.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 321,\n            'f': \"321\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.8,\n            'f': \"50.8\",\n        },\n{\n            'v': 18.5,\n            'f': \"18.5\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 4450.0,\n            'f': \"4450.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 322,\n            'f': \"322\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.1,\n            'f': \"50.1\",\n        },\n{\n            'v': 17.9,\n            'f': \"17.9\",\n        },\n{\n            'v': 190.0,\n            'f': \"190.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 323,\n            'f': \"323\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.0,\n            'f': \"49.0\",\n        },\n{\n            'v': 19.6,\n            'f': \"19.6\",\n        },\n{\n            'v': 212.0,\n            'f': \"212.0\",\n        },\n{\n            'v': 4300.0,\n            'f': \"4300.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 324,\n            'f': \"324\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.5,\n            'f': \"51.5\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3250.0,\n            'f': \"3250.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 325,\n            'f': \"325\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.8,\n            'f': \"49.8\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3675.0,\n            'f': \"3675.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 326,\n            'f': \"326\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 48.1,\n            'f': \"48.1\",\n        },\n{\n            'v': 16.4,\n            'f': \"16.4\",\n        },\n{\n            'v': 199.0,\n            'f': \"199.0\",\n        },\n{\n            'v': 3325.0,\n            'f': \"3325.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 327,\n            'f': \"327\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.4,\n            'f': \"51.4\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 201.0,\n            'f': \"201.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 328,\n            'f': \"328\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.7,\n            'f': \"45.7\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3600.0,\n            'f': \"3600.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 329,\n            'f': \"329\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.7,\n            'f': \"50.7\",\n        },\n{\n            'v': 19.7,\n            'f': \"19.7\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 330,\n            'f': \"330\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 42.5,\n            'f': \"42.5\",\n        },\n{\n            'v': 17.3,\n            'f': \"17.3\",\n        },\n{\n            'v': 187.0,\n            'f': \"187.0\",\n        },\n{\n            'v': 3350.0,\n            'f': \"3350.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 331,\n            'f': \"331\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 52.2,\n            'f': \"52.2\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 197.0,\n            'f': \"197.0\",\n        },\n{\n            'v': 3450.0,\n            'f': \"3450.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 332,\n            'f': \"332\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.2,\n            'f': \"45.2\",\n        },\n{\n            'v': 16.6,\n            'f': \"16.6\",\n        },\n{\n            'v': 191.0,\n            'f': \"191.0\",\n        },\n{\n            'v': 3250.0,\n            'f': \"3250.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 333,\n            'f': \"333\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.3,\n            'f': \"49.3\",\n        },\n{\n            'v': 19.9,\n            'f': \"19.9\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        },\n{\n            'v': 4050.0,\n            'f': \"4050.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 334,\n            'f': \"334\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.2,\n            'f': \"50.2\",\n        },\n{\n            'v': 18.8,\n            'f': \"18.8\",\n        },\n{\n            'v': 202.0,\n            'f': \"202.0\",\n        },\n{\n            'v': 3800.0,\n            'f': \"3800.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 335,\n            'f': \"335\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.6,\n            'f': \"45.6\",\n        },\n{\n            'v': 19.4,\n            'f': \"19.4\",\n        },\n{\n            'v': 194.0,\n            'f': \"194.0\",\n        },\n{\n            'v': 3525.0,\n            'f': \"3525.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 336,\n            'f': \"336\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 51.9,\n            'f': \"51.9\",\n        },\n{\n            'v': 19.5,\n            'f': \"19.5\",\n        },\n{\n            'v': 206.0,\n            'f': \"206.0\",\n        },\n{\n            'v': 3950.0,\n            'f': \"3950.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 337,\n            'f': \"337\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 46.8,\n            'f': \"46.8\",\n        },\n{\n            'v': 16.5,\n            'f': \"16.5\",\n        },\n{\n            'v': 189.0,\n            'f': \"189.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 338,\n            'f': \"338\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 45.7,\n            'f': \"45.7\",\n        },\n{\n            'v': 17.0,\n            'f': \"17.0\",\n        },\n{\n            'v': 195.0,\n            'f': \"195.0\",\n        },\n{\n            'v': 3650.0,\n            'f': \"3650.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 339,\n            'f': \"339\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 55.8,\n            'f': \"55.8\",\n        },\n{\n            'v': 19.8,\n            'f': \"19.8\",\n        },\n{\n            'v': 207.0,\n            'f': \"207.0\",\n        },\n{\n            'v': 4000.0,\n            'f': \"4000.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 340,\n            'f': \"340\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 43.5,\n            'f': \"43.5\",\n        },\n{\n            'v': 18.1,\n            'f': \"18.1\",\n        },\n{\n            'v': 202.0,\n            'f': \"202.0\",\n        },\n{\n            'v': 3400.0,\n            'f': \"3400.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 341,\n            'f': \"341\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 49.6,\n            'f': \"49.6\",\n        },\n{\n            'v': 18.2,\n            'f': \"18.2\",\n        },\n{\n            'v': 193.0,\n            'f': \"193.0\",\n        },\n{\n            'v': 3775.0,\n            'f': \"3775.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 342,\n            'f': \"342\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.8,\n            'f': \"50.8\",\n        },\n{\n            'v': 19.0,\n            'f': \"19.0\",\n        },\n{\n            'v': 210.0,\n            'f': \"210.0\",\n        },\n{\n            'v': 4100.0,\n            'f': \"4100.0\",\n        },\n\"male\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }],\n [{\n            'v': 343,\n            'f': \"343\",\n        },\n\"Chinstrap\",\n\"Dream\",\n{\n            'v': 50.2,\n            'f': \"50.2\",\n        },\n{\n            'v': 18.7,\n            'f': \"18.7\",\n        },\n{\n            'v': 198.0,\n            'f': \"198.0\",\n        },\n{\n            'v': 3775.0,\n            'f': \"3775.0\",\n        },\n\"female\",\n{\n            'v': 2009,\n            'f': \"2009\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"species\"], [\"string\", \"island\"], [\"number\", \"bill_length_mm\"], [\"number\", \"bill_depth_mm\"], [\"number\", \"flipper_length_mm\"], [\"number\", \"body_mass_g\"], [\"string\", \"sex\"], [\"number\", \"year\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-80edcdee-c8e2-475a-ba28-923a9084bc3d\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80edcdee-c8e2-475a-ba28-923a9084bc3d')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-80edcdee-c8e2-475a-ba28-923a9084bc3d button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    "
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we mentioned before, there are three species of penguin in the dataset. However, today we'll be implementing a _binary classification algorithm_, which means we need to have exactly two target classes! Let's go ahead and filter the data so that we keep the Adelie and Gentoo species."
      ],
      "metadata": {
        "id": "nDFjkxZE1BA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define the species that we're interested in\n",
        "species = ['Adelie','Gentoo']\n",
        "\n",
        "# And use the .loc method in Pandas to keep only the two species mentioned above\n",
        "data = data.loc[data['species'].isin(species)]"
      ],
      "metadata": {
        "id": "kTUHBGUT1dTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Today, we'll be learning to classify the penguins based on the length and depth of their bills.  Run the cell and take a look at the data! üîé\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# Dimensions for interactive plot\n",
        "dims = ['bill_length_mm', 'bill_depth_mm']\n",
        "colors = ['orange','black','lightseagreen']\n",
        "\n",
        "fig = px.scatter_matrix(\n",
        "                        data,\n",
        "                        dimensions=dims,\n",
        "                        color=\"species\",\n",
        "                        color_discrete_sequence = colors\n",
        "                        )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fa4m4iPxgpu9",
        "outputId": "bd325232-faf7-454b-ef05-9892e670a1d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"884584bc-64a5-44e7-a2cf-0ae547f11a8e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"884584bc-64a5-44e7-a2cf-0ae547f11a8e\")) {                    Plotly.newPlot(                        \"884584bc-64a5-44e7-a2cf-0ae547f11a8e\",                        [{\"dimensions\":[{\"axis\":{\"matches\":true},\"label\":\"bill_length_mm\",\"values\":[39.1,39.5,40.3,null,36.7,39.3,38.9,39.2,34.1,42.0,37.8,37.8,41.1,38.6,34.6,36.6,38.7,42.5,34.4,46.0,37.8,37.7,35.9,38.2,38.8,35.3,40.6,40.5,37.9,40.5,39.5,37.2,39.5,40.9,36.4,39.2,38.8,42.2,37.6,39.8,36.5,40.8,36.0,44.1,37.0,39.6,41.1,37.5,36.0,42.3,39.6,40.1,35.0,42.0,34.5,41.4,39.0,40.6,36.5,37.6,35.7,41.3,37.6,41.1,36.4,41.6,35.5,41.1,35.9,41.8,33.5,39.7,39.6,45.8,35.5,42.8,40.9,37.2,36.2,42.1,34.6,42.9,36.7,35.1,37.3,41.3,36.3,36.9,38.3,38.9,35.7,41.1,34.0,39.6,36.2,40.8,38.1,40.3,33.1,43.2,35.0,41.0,37.7,37.8,37.9,39.7,38.6,38.2,38.1,43.2,38.1,45.6,39.7,42.2,39.6,42.7,38.6,37.3,35.7,41.1,36.2,37.7,40.2,41.4,35.2,40.6,38.8,41.5,39.0,44.1,38.5,43.1,36.8,37.5,38.1,41.1,35.6,40.2,37.0,39.7,40.2,40.6,32.1,40.7,37.3,39.0,39.2,36.6,36.0,37.8,36.0,41.5]},{\"axis\":{\"matches\":true},\"label\":\"bill_depth_mm\",\"values\":[18.7,17.4,18.0,null,19.3,20.6,17.8,19.6,18.1,20.2,17.1,17.3,17.6,21.2,21.1,17.8,19.0,20.7,18.4,21.5,18.3,18.7,19.2,18.1,17.2,18.9,18.6,17.9,18.6,18.9,16.7,18.1,17.8,18.9,17.0,21.1,20.0,18.5,19.3,19.1,18.0,18.4,18.5,19.7,16.9,18.8,19.0,18.9,17.9,21.2,17.7,18.9,17.9,19.5,18.1,18.6,17.5,18.8,16.6,19.1,16.9,21.1,17.0,18.2,17.1,18.0,16.2,19.1,16.6,19.4,19.0,18.4,17.2,18.9,17.5,18.5,16.8,19.4,16.1,19.1,17.2,17.6,18.8,19.4,17.8,20.3,19.5,18.6,19.2,18.8,18.0,18.1,17.1,18.1,17.3,18.9,18.6,18.5,16.1,18.5,17.9,20.0,16.0,20.0,18.6,18.9,17.2,20.0,17.0,19.0,16.5,20.3,17.7,19.5,20.7,18.3,17.0,20.5,17.0,18.6,17.2,19.8,17.0,18.5,15.9,19.0,17.6,18.3,17.1,18.0,17.9,19.2,18.5,18.5,17.6,17.5,17.5,20.1,16.5,17.9,17.1,17.2,15.5,17.0,16.8,18.7,18.6,18.4,17.8,18.1,17.1,18.5]}],\"hovertemplate\":\"species=Adelie\\u003cbr\\u003e%{xaxis.title.text}=%{x}\\u003cbr\\u003e%{yaxis.title.text}=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Adelie\",\"marker\":{\"color\":\"orange\",\"symbol\":\"circle\"},\"name\":\"Adelie\",\"showlegend\":true,\"type\":\"splom\"},{\"dimensions\":[{\"axis\":{\"matches\":true},\"label\":\"bill_length_mm\",\"values\":[46.1,50.0,48.7,50.0,47.6,46.5,45.4,46.7,43.3,46.8,40.9,49.0,45.5,48.4,45.8,49.3,42.0,49.2,46.2,48.7,50.2,45.1,46.5,46.3,42.9,46.1,44.5,47.8,48.2,50.0,47.3,42.8,45.1,59.6,49.1,48.4,42.6,44.4,44.0,48.7,42.7,49.6,45.3,49.6,50.5,43.6,45.5,50.5,44.9,45.2,46.6,48.5,45.1,50.1,46.5,45.0,43.8,45.5,43.2,50.4,45.3,46.2,45.7,54.3,45.8,49.8,46.2,49.5,43.5,50.7,47.7,46.4,48.2,46.5,46.4,48.6,47.5,51.1,45.2,45.2,49.1,52.5,47.4,50.0,44.9,50.8,43.4,51.3,47.5,52.1,47.5,52.2,45.5,49.5,44.5,50.8,49.4,46.9,48.4,51.1,48.5,55.9,47.2,49.1,47.3,46.8,41.7,53.4,43.3,48.1,50.5,49.8,43.5,51.5,46.2,55.1,44.5,48.8,47.2,null,46.8,50.4,45.2,49.9]},{\"axis\":{\"matches\":true},\"label\":\"bill_depth_mm\",\"values\":[13.2,16.3,14.1,15.2,14.5,13.5,14.6,15.3,13.4,15.4,13.7,16.1,13.7,14.6,14.6,15.7,13.5,15.2,14.5,15.1,14.3,14.5,14.5,15.8,13.1,15.1,14.3,15.0,14.3,15.3,15.3,14.2,14.5,17.0,14.8,16.3,13.7,17.3,13.6,15.7,13.7,16.0,13.7,15.0,15.9,13.9,13.9,15.9,13.3,15.8,14.2,14.1,14.4,15.0,14.4,15.4,13.9,15.0,14.5,15.3,13.8,14.9,13.9,15.7,14.2,16.8,14.4,16.2,14.2,15.0,15.0,15.6,15.6,14.8,15.0,16.0,14.2,16.3,13.8,16.4,14.5,15.6,14.6,15.9,13.8,17.3,14.4,14.2,14.0,17.0,15.0,17.1,14.5,16.1,14.7,15.7,15.8,14.6,14.4,16.5,15.0,17.0,15.5,15.0,13.8,16.1,14.7,15.8,14.0,15.1,15.2,15.9,15.2,16.3,14.1,16.0,15.7,16.2,13.7,null,14.3,15.7,14.8,16.1]}],\"hovertemplate\":\"species=Gentoo\\u003cbr\\u003e%{xaxis.title.text}=%{x}\\u003cbr\\u003e%{yaxis.title.text}=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Gentoo\",\"marker\":{\"color\":\"black\",\"symbol\":\"circle\"},\"name\":\"Gentoo\",\"showlegend\":true,\"type\":\"splom\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"species\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"dragmode\":\"select\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('884584bc-64a5-44e7-a2cf-0ae547f11a8e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a dataframe with all the information that we need. Let's go ahead and extract the bill length and depth to use as input data, storing it in $x$.\n",
        "Then we'll store the labels (i.e., the _targets_) in $y$.\n",
        "### **Q1) Extract the bill length and bill depth to use as the input vector $x$, and store the label (i.e., the target data) in $y$**\n"
      ],
      "metadata": {
        "id": "kGI9Ruq6BRPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints - Data Loading and Filtering\n",
        "\n",
        "'''\n",
        "Loading data into X:\n",
        "\n",
        "You can access multiple columns of a pandas dataframe using a list! The snippet\n",
        "below will return the species and island associated with each penguin in the\n",
        "database.\n",
        "\n",
        "In the cell below, you want to load the bill length and bull depth columns.\n",
        "Make sure you use the right column name! Copy it from the dataframe view we\n",
        "printed before, and make sure there aren't any extra spaces\n",
        "''';\n",
        "data[['species','island']];\n",
        "\n",
        "'''\n",
        "Finding the NaN row indices\n",
        "\n",
        "Pandas has a built-in function to determine if the value is a NaN (Not a Number)\n",
        "value.\n",
        "\n",
        "mydata.notna() will return True wherever the data isn't a NaN value, but we need\n",
        "to check if each row has _any_ NaN values - that's what the _all(axis=1)_ does.\n",
        "''';"
      ],
      "metadata": {
        "id": "9kwuG96d5GrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the bill length and depth into X\n",
        "X = data[['bill_length_mm','bill_depth_mm']]\n",
        "\n",
        "# Find out the rows where you don't have an valid input (i.e., rows with a nan value)\n",
        "indices = X.notna().all(axis=1)\n",
        "\n",
        "# Filter out the datapoints using the indices we found\n",
        "X = X[indices]\n",
        "\n",
        "# We'll also normalize the data using the mean and standard deviation\n",
        "X = (X - X.mean())/X.std()"
      ],
      "metadata": {
        "id": "mRognoEcPUmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at the input dataset - if you did everything right, you'll\n",
        "# have 274 entries and printing out x.shape will return (274,2)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "0IoLpmkLugIR",
        "outputId": "47f4266f-5242-4330-d44c-fbfdee02a28c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(274, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have our input data, but we need a target to predict. We previously filtered the data to only include Ad√©lie and Gentoo penguins, but we still have them as strings! Let's convert them to a binary representation (i.e., 0 or 1). Make sure you have the same penguins as in your input!\n",
        "\n",
        "### **Q2) Convert the species label to a binary classification, and filter the target data to match the input data.**"
      ],
      "metadata": {
        "id": "S63cMjGKLpd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints - Boolean Representation & Type Conversion\n",
        "\n",
        "'''\n",
        "Boolean Representation\n",
        "\n",
        "You can access the species data by calling data['species']\n",
        "\n",
        "== is the operator that lets you check if the data is equal to another value\n",
        "\n",
        "data['island'] == Torgesen\n",
        "will return True for each row if the penguin was studied in Torgesen, and False\n",
        "if it was studied in another island\n",
        "''';\n",
        "\n",
        "'''\n",
        "Type Conversion\n",
        "\n",
        "Pandas dataframes include a method to change the type of the data being called.\n",
        "\n",
        "data['bill_length_mm'].astype(int) will return the bill length data as integers\n",
        "''';"
      ],
      "metadata": {
        "id": "s3psibnt08RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert species data into boolean form by checking if the species is Ad√©lie\n",
        "y = (data['species'] == 'Ad√©lie')\n",
        "\n",
        "# Filter out the points for which we have NaN values. Reuse the indices from Q1!\n",
        "y = y[indices]\n",
        "\n",
        "# Convert the boolean data into an integer\n",
        "y = y.astype(int)"
      ],
      "metadata": {
        "id": "TEJwe-AvLvN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out y! If everything is implemented correctly, you should see a panda\n",
        "# series full of ones and zeroes with 274 rows\n",
        "print(y)"
      ],
      "metadata": {
        "id": "x9WveIx-1w5g",
        "outputId": "2089209a-be3a-4eb9-c242-9f4ee33c73ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "4      0\n",
            "5      0\n",
            "      ..\n",
            "270    0\n",
            "272    0\n",
            "273    0\n",
            "274    0\n",
            "275    0\n",
            "Name: species, Length: 274, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a set of binary classification data we can use to train an algorithm.\n",
        "\n",
        "As we saw during our reading, we need to define three things in order to train our algorithm:\n",
        "> $\\cdot$ the type of algorithm we will train, \\\\\n",
        "> $\\cdot$ the cost function (which will tell us how close our prediction is to the truth), and \\\\\n",
        "> $\\cdot$ a method for updating the parameters in our model according to the value of the cost function (e.g., the gradient descent method).\n",
        "\n",
        "Let's begin by defining the type of algorithm we will use. We will train a logistic regression model to differentiate between two classes. A reminder of how the logistic regression algorithm works is given below.\n",
        "<br><br><br>\n",
        "The logistic regression algorithm will thus take an input $t$ that is a linear combination of the features:\n",
        "\n",
        "<a name=\"logit\"></a>\n",
        "\n",
        "<center> $t_{\\small{n}} = \\beta_{\\small{0}} + \\beta_{\\small{1}} \\cdot X_{1,n} + \\beta_{\\small{2}} \\cdot X_{2,n}$ </center>\n",
        "\n",
        "where\n",
        "* $n$ is the ID of the sample\n",
        "* $X_{\\small{0}}$ represents the bill length\n",
        "* $X_{\\small{1}}$ represents the bill width\n",
        "\n",
        "This input is then fed into the logistic function, $\\sigma$:\n",
        "\\begin{align}\n",
        "\\sigma: t\\mapsto \\dfrac{1}{1+e^ {-t}}\n",
        "\\end{align}\n",
        "\n",
        "Let's define the logistic function for later use."
      ],
      "metadata": {
        "id": "jvNBaOWZ9fXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q4) Define the logistic function**"
      ],
      "metadata": {
        "id": "PzrhQ2E-zkDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint - Exponential Function\n",
        "'''\n",
        "Numpy includes the exponential function in its library as numpy.exp\n",
        "https://numpy.org/doc/stable/reference/generated/numpy.exp.html\n",
        "''';\n",
        "\n",
        "np.exp(2);"
      ],
      "metadata": {
        "id": "oBvebKZVDWx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic(in_val):\n",
        "    # Return the value of the logistic function\n",
        "    out_value = (1 + np.exp(-in_val))\n",
        "    return out_value"
      ],
      "metadata": {
        "id": "EdelvJlJzuE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the logistic function has been defined, we can plot it (this will help us remember what it looks like!) Run the code below - you won't have to fill anything in for this one üòÄ But feel free to show the code and read through it - some of the functions used can be helpful to you down the line!"
      ],
      "metadata": {
        "id": "WqIkC1wZ0gAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this to plot the logistic function!\n",
        "# Let's generate an array of 20 points with values from -4 to +4\n",
        "t = np.linspace(-4,4,20)\n",
        "\n",
        "# Initiate a figure and axes object using matplotlib\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Draw the X and Y axes\n",
        "ax.axvline(0, c='black', alpha=1)\n",
        "ax.axhline(0, c='black', alpha=1)\n",
        "\n",
        "# Draw the threshold line (y_val=0,5) and asymptote (y=1)\n",
        "[ax.axhline(y_val, c='black', alpha=0.5, linestyle='dotted') for y_val in (0.5,1)]\n",
        "\n",
        "# Scale things to make the graph look nicer\n",
        "plt.autoscale(axis='x', tight=True)\n",
        "\n",
        "# Plot the logistic function. X values from the t vector, y values from logistic(t)\n",
        "ax.plot(t, logistic(t));\n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$\\\\sigma\\\\  \\\\left(t\\\\right)$')\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "lgt9dI6b9Zwa",
        "cellView": "form",
        "outputId": "ca751050-9abb-4a49-b84f-421e7f52c109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the logistic function, we define inputs resulting in $\\sigma\\geq0.5$ as belonging to the ***one*** class, and any value below that is considered to belong to the ***zero*** class.\n",
        "\n",
        "We now have a function which lets us map the value of the bill length and width to the class to which the observation belongs (i.e., whether the length and width correspond to Ad√©lie or Gentoo penguins). However, there is a parameter vector **$\\theta$** with a number of parameters that we do not have a value for: <br> $\\theta = [ \\beta_{\\small{0}}, \\beta_{\\small{1}}$, $\\beta_{\\small{2}} ]$"
      ],
      "metadata": {
        "id": "0Ll1PKpjxqLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q5) Set up an array of random numbers between 0 and 1 representing the $\\theta$ vector.**\n"
      ],
      "metadata": {
        "id": "O_lT4EaK2ICa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints: Random Number Generation\n",
        "'''\n",
        "Random Number Generation\n",
        "Use `rnd_gen`! If you're not sure how to use it, consult the `default_rng`\n",
        "documentation at this address:\n",
        "https://numpy.org/doc/stable/reference/random/generator.html\n",
        "\n",
        "For instance, you may use the `random` method of `rnd_gen`.*\n",
        "''';\n",
        "\n",
        "'''\n",
        "The theta array should have 3 elements in it!\n",
        "''';"
      ],
      "metadata": {
        "id": "4ULzWzd750RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint: Code Snipppet\n",
        "'''\n",
        "rnd_gen.random((___,)) # length of array\n",
        "''';"
      ],
      "metadata": {
        "id": "R0uUE4VbEfgt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta = rnd_gen.random((0,1))"
      ],
      "metadata": {
        "id": "-Vk05y1C2VBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to determine whether a set of $\\beta$ values is better than the other, we need to quantify well the values are able to predict the class. This is where the cost function comes in.\n",
        "\n",
        "The cost function, $c$, will return a value close to zero when the prediction, $\\hat{p}$, is correct and a large value when it is wrong. In a binary classification problem, we can use the log loss function. For a single prediction and truth value, it is given by:\n",
        "\\begin{align}\n",
        "        \\text{c}(\\hat{p},y) = \\left\\{\n",
        "        \\begin{array}{cl}\n",
        "        -\\log(\\hat{p})& \\text{if}\\; y=1\\\\\n",
        "        -\\log(1-\\hat{p}) & \\text{if}\\; y=0\n",
        "        \\end{array}\n",
        "        \\right.\n",
        "    \\end{align}\n",
        "\n",
        "However, we want to apply the cost function to an n-dimensional set of predictions and truth values. Thankfully, we can find the average value of the log loss function $J$ for an an-dimensional set of $\\hat{y}$ & $y$ as follows:\n",
        "\n",
        "\\begin{align}\n",
        "        \\text{J}(\\mathbf{\\hat{p}},y) = - \\dfrac{1}{n} \\sum_{i=1}^{n}\n",
        "        \\left[ y_i\\cdot \\log\\left( \\hat{p}_i \\right) \\right] +\n",
        "        \\left[ \\left( 1 - y_i \\right) \\cdot \\log\\left( 1-\\hat{p}_i \\right) \\right]\n",
        "    \\end{align}\n",
        "\n",
        "We now have a formula that can be used to calculate the average cost over the training set of data.\n",
        "\n",
        "Now let's code üíª\n"
      ],
      "metadata": {
        "id": "s8KM_CeF2Ven"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q6) Define a log_loss function that takes in an arbitrarily large set of prediction and truths**\n",
        "\n",
        "*Hint 1: You need to encode the function $J$ above, for which Numpy's functions may be quite convenient (e.g., [`log`](https://numpy.org/doc/stable/reference/generated/numpy.log.html), [`mean`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html), etc.)*\n",
        "\n",
        "*Hint 2: Asserting the dimensions of the vector is a good way to check that your function is working correctly. [Here's a tutorial on how to use `assert`](https://swcarpentry.github.io/python-novice-inflammation/10-defensive/index.html#assertions). For instance, to assert that two vectors `X` and `y` have the same dimension, you may use:*\n",
        "```\n",
        "assert X.shape==y.shape\n",
        "```"
      ],
      "metadata": {
        "id": "XBLxwlSWMoo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint: Example code snippet\n",
        "'''\n",
        "J_vector  = -(y * np.log(p_hat + epsilon) + (1-y) * np.log(1-y_hat))\n",
        "J.mean()\n",
        "''';"
      ],
      "metadata": {
        "id": "Jmnzz4h_Cq01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(p_hat, y, epsilon=1e-7):\n",
        "\n",
        "  # Begin by calculating the two possibilities for the cost function, i.e.\n",
        "  # 1: -log(p_hat + epsilon), and 2: -log(1- p_hat). We added an epsilon term\n",
        "  # to -log(p_hat) because we can run into mathematical problems if p_hat = 0.\n",
        "  term_1 = -np.log( p_hat + epsilon )\n",
        "  term_2 = -np.log( 1- p_hat )\n",
        "\n",
        "  # We can almost calculate J! We'll need to 1) multiply term_1 by y, and\n",
        "  # 2) multiply term_2 by (1-y). We then add the new terms together.\n",
        "  # Calculate the value of the cost function (i.e., what's inside the brackets)\n",
        "  inside_brackets = (y) * term_1 + ( 1 - y ) * term_2\n",
        "\n",
        "  #Verify the shape of inside_brackets.\n",
        "  print(f'The size of the term inside the brackets is {inside_brackets.shape}')\n",
        "\n",
        "  # You should have a cost value for each one of your predictions. We won't\n",
        "  # use the individual values, though. We'll aggregate the information from\n",
        "  # all our predictions by calculating the mean! (i.e., 1/n_terms * terms_sum)\n",
        "  # This single value is J\n",
        "  J = inside_brackets.mean()\n",
        "  print(J)\n",
        "  return J\n",
        "\n"
      ],
      "metadata": {
        "id": "H5fDeL36EauO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a way of quantifying how good our predictions are. The final thing needed for us to train our algorithm is figuring out a way to update the parameters in a way that improves the average quality of our predictions.\n",
        "\n",
        "<br><br>**Warning**: we'll go into a bit of math below <br><br>\n",
        "\n",
        "Let's look at the change in a single parameter within $\\theta$: $\\beta_1$ (given $X_{1,i} = X_1$, $\\;\\hat{p}_{i} = \\hat{p}$, $\\;y_{i} = y$). If we want to know what the effect of changing the value of $\\beta_1$ will have on the log loss function we can find this with the partial derivative:\n",
        "<center>$\n",
        "        \\dfrac{\\partial J}{\\partial \\beta_1}\n",
        "$</center>\n",
        "\n",
        "This may not seem very helpful by itself - after all, $\\beta_1$ isn't even in the expression of $J$. But if we use the chain rule, we can rewrite the expression as:\n",
        "<center>\n",
        "        $\\dfrac{\\partial J}{\\partial \\hat{p}} \\cdot\n",
        "        \\dfrac{\\partial \\hat{p}}{\\partial \\theta} \\cdot\n",
        "        \\dfrac{\\partial \\theta}{\\partial \\beta_1}$\n",
        "</center>\n",
        "\n",
        "We'll spare you the math (feel free to verify it youself, however!):\n",
        "\n",
        "<center>$\\dfrac{\\partial J}{\\partial \\hat{p}} =  \\dfrac{\\hat{p} - y}{\\hat{p}(1-\\hat{p})}, \\quad\n",
        "        \\dfrac{\\partial \\hat{p}}{\\partial \\theta} = \\hat{p} (1-\\hat{p}), \\quad\n",
        "        \\dfrac{\\partial \\theta}{\\partial \\beta_1} = X_1 $\n",
        "</center>\n",
        "\n",
        "and thus\n",
        "<center>$\n",
        "        \\dfrac{\\partial J}{\\partial \\beta_1} = (\\hat{p} - y) \\cdot X_1\n",
        "$</center>\n",
        "\n",
        "We can calculate the partial derivative for each parameter in $\\theta$ which, as you may have realized, is simply the $\\theta$ gradient of $J$: $\\nabla_{\\theta}(J)$\n",
        "\n",
        "With all of this information, we can now write $\\nabla_{\\theta} J$ in terms of the error, the feature vector, and the number of samples we're training on!\n",
        "\n",
        "<a name=\"grad_eq\"></a>\n",
        "\n",
        "<center>$\\nabla_{\\mathbf{\\theta}^{(k)}} \\, J(\\mathbf{\\theta^{(k)}}) = \\dfrac{1}{n} \\sum\\limits_{i=1}^{n}{ \\left ( \\hat{p}^{(k)}_{i} - y_{i} \\right ) \\mathbf{X}_{i}}$</center>\n",
        "\n",
        "Note that here $k$ represents the iteration of the parameters we are currently on.\n",
        "\n",
        "We now have a gradient we can calculate and use in the batch gradient descent method! The updated parameters will thus be:\n",
        "\n",
        "<a name=\"grad_descent\"></a>\n",
        "\n",
        "\\begin{align}\n",
        "{\\mathbf{\\theta}^{(k+1)}} = {\\mathbf{\\theta}^{(k)}} - \\eta\\,\\nabla_{\\theta^{(k)}}J(\\theta^{(k)})\n",
        "\\end{align}\n",
        "\n",
        "Where $\\eta$ is the learning rate parameter. It's also worth pointing out that $\\;\\hat{p}^{(k)}_i = \\sigma\\left(\\theta^{(k)}, X_i\\right) $"
      ],
      "metadata": {
        "id": "aO4Bkm1gFV3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to easily calculate the input to the logistic regression, we'll multiply the $\\theta$ vector with the X data, and as we have a non-zero bias  $\\beta_0$ we'd like to have an X matrix whose first column is filled with ones.\n",
        "\n",
        "\\begin{align}\n",
        "    X_{\\small{with\\ bias}} = \\begin{pmatrix}\n",
        "        1 & X_{1,0} & X_{2,0}\\\\\n",
        "        1 & X_{1,1} & X_{2,1}\\\\\n",
        "        &...&\\\\\n",
        "        1 & X_{1,n} & X_{2,n}\n",
        "        \\end{pmatrix}\n",
        "\\end{align}\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "ML4uik7sbdMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q7) Prepare the `X_with_bias` matrix.**"
      ],
      "metadata": {
        "id": "sqwV5qgrisB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints: Making an an array filled with ones, hints on concatenation\n",
        "\n",
        "'''\n",
        "Making the ones array\n",
        "\n",
        "Making an array with ones and the same number of entries as rows in your input\n",
        "data: You can use numpy.ones( (array_dimensions) ) in order to generate an array with\n",
        "the given array_dimensions shape. e.g., np.ones((4,)) => array([1,1,1,1])\n",
        "\n",
        "Accessing the number of rows: dataframes have the \"shape\" attribute implemented.\n",
        "For our penguin data, the input vector shape should be (274,2), and so using\n",
        "shape[0] should return the right length for our ones array\n",
        "''';\n",
        "\n",
        "\n",
        "'''\n",
        "Concatenation\n",
        "\n",
        "You can quickly concatenate your arrays using np.c_[array1,array2]. Note that\n",
        "the order matters, so make sure array1 is the array filled with ones :). Also,\n",
        "np.c_ uses square brackets! [] - you'll get an error if you use regular\n",
        "brackets ().\n",
        "\n",
        "numpy.c_ will automagically understand that the second array is a dataframe -\n",
        "you don't need to worry about transforming it into a numpy array for today!\n",
        "\n",
        "''';"
      ],
      "metadata": {
        "id": "PlipJo530lPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the ones array\n",
        "ones_array = np.ones(X.shape[0])\n",
        "\n",
        "# Make the x_with_bias matrix\n",
        "X_with_bias = np.c_[ones_array,X]"
      ],
      "metadata": {
        "id": "A_-GIW9cCTFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print your x with bias matrix to make sure it looks the way it's supposed to\n",
        "print(X_with_bias[:10])"
      ],
      "metadata": {
        "id": "QiqtcQj5IIH6",
        "outputId": "108c5268-f8e6-414b-edbe-f14b0bc9737d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.         -0.69346042  0.92572752]\n",
            " [ 1.         -0.6164717   0.28005659]\n",
            " [ 1.         -0.46249427  0.57805856]\n",
            " [ 1.         -1.15539273  1.22372949]\n",
            " [ 1.         -0.65496606  1.86940041]\n",
            " [ 1.         -0.73195478  0.47872457]\n",
            " [ 1.         -0.67421324  1.37273047]\n",
            " [ 1.         -1.65581939  0.62772555]\n",
            " [ 1.         -0.13529222  1.67073244]\n",
            " [ 1.         -0.94367375  0.13105561]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our X_with_bias matrix looks like this: \\\\\n",
        "[[ 1.        $\\quad$ -0.69346042 $\\quad$ 0.92572752] \\\\\n",
        " [ 1.        $\\quad$ -0.6164717  $\\quad$ 0.28005659] \\\\\n",
        " [ 1.        $\\quad$ -0.46249427 $\\quad$ 0.57805856] \\\\\n",
        " [ 1.        $\\quad$ -1.15539273 $\\quad$ 1.22372949] \\\\\n",
        " [ 1.        $\\quad$ -0.65496606 $\\quad$ 1.86940041] \\\\\n",
        " [ 1.        $\\quad$ -0.73195478 $\\quad$ 0.47872457] \\\\\n",
        " [ 1.        $\\quad$ -0.67421324 $\\quad$ 1.37273047] \\\\\n",
        " [ 1.        $\\quad$ -1.65581939 $\\quad$ 0.62772555] \\\\\n",
        " [ 1.        $\\quad$ -0.13529222 $\\quad$ 1.67073244] \\\\\n",
        " [ 1.        $\\quad$ -0.94367375 $\\quad$ 0.13105561]]"
      ],
      "metadata": {
        "id": "wN1zdxPLkhO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q8) Write a function called `predict` that takes in the parameter vector $\\theta$ and the `X_with_bias` matrix and evaluates the logistic function for each of the samples.**"
      ],
      "metadata": {
        "id": "cThmFWcB0v-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint: Pseudocode Snippet\n",
        "\n",
        "'''\n",
        "Pseudocode below:\n",
        "\n",
        "define predict_function(x_with_bias, theta_vector):\n",
        "  argument_for_logistic_function = dot_product(x_with_bias, theta_vector)\n",
        "  return logistic_function(argument_for_logistic_function)\n",
        "\n",
        "''';"
      ],
      "metadata": {
        "id": "opqgiTM2L0jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your predict function here\n",
        "def predict_function(X_with_bias,theta):\n",
        "    # Find the dot product of X_with_bias and theta\n",
        "    dot_product = np.dot(X_with_bias,theta)\n",
        "\n",
        "    # Use your logistic function!\n",
        "    output = logistic(dot_product)\n",
        "\n",
        "    return output # Return the value you get"
      ],
      "metadata": {
        "id": "tBLryApsbatR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's test your predict function!\n",
        "\n",
        "# Set up debug data and parameters\n",
        "debug_data = np.c_[np.ones(5), np.linspace(-1,1,10).reshape((-1,2))]\n",
        "debug_theta = np.array([0.2,0.1,0.9])\n",
        "\n",
        "print(predict_function(debug_data, debug_theta))"
      ],
      "metadata": {
        "id": "6QIweEz8OKPO",
        "outputId": "96ea7e8c-6468-4ccf-8df5-751883bd0653",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.8221188  2.16830684 1.74909543 1.4803053  1.30796234]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If everything is set up correctly and you didn't change the debug data and theta, the output for your predict function should be:\n",
        "\n",
        "`[0.35434369 0.46118934 0.57172409 0.67553632 0.76454801]`"
      ],
      "metadata": {
        "id": "HQ6oK6ewOcHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q9) Now that you have a `predict` function, write a `gradient_calc` function that calculates the gradient for the logistic function.**\n",
        "\n",
        "*Hint: You'll have to feed `theta`, `X`, and `y` to the `gradient_calc` function.*\n",
        "\n",
        "*Hint: You can use [this equation](#grad_eq) to calculate the gradient of the cost function.*"
      ],
      "metadata": {
        "id": "p6cPbu4LvVES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint: Pseudocode Snippet\n",
        "\n",
        "'''\n",
        "\n",
        "define gradient_calculator_function(y, X_with_bias, theta_vector):\n",
        "  # predicted values using theta and inputs\n",
        "  prediction = predict(x_with_bias,theta_vector)\n",
        "\n",
        "  number_of_predictions = len(prediction)\n",
        "\n",
        "  assert number_of_predictions == len(y)\n",
        "\n",
        "  error = prediction - y\n",
        "\n",
        "  X_transpose = transpose(X)\n",
        "\n",
        "  return dot_product(X_transpose, error) / number_of_predictions\n",
        "\n",
        "''';\n",
        "\n"
      ],
      "metadata": {
        "id": "XRQNz-2nPGVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_calculator(y, X_with_bias, theta_vector):\n",
        "    # Find predicted values using the predict function\n",
        "    prediction = predict_function(X_with_bias,theta_vector)\n",
        "\n",
        "    # Assert that you have the same number of predictions as you do targets\n",
        "    # Otherwise, something went wrong!\n",
        "    assert len(prediction) == len(y)\n",
        "\n",
        "    # Calculate the error\n",
        "    error = prediction - y\n",
        "\n",
        "    # Find the dot product with the input matrix and divide by the number of\n",
        "    # predictions\n",
        "    X_transpose = np.transpose(X)\n",
        "\n",
        "    output = np.dot(error,X_transpose ) / number_of_predictions\n",
        "    return output"
      ],
      "metadata": {
        "id": "BtnANN5WvVuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's test the gradient calculator\n",
        "# Begin by creating dummy labels\n",
        "debug_labels = np.array([0,0,0,1,1])\n",
        "\n",
        "# And call the function you defined with the dummy labels and data we made before\n",
        "print(gradient_calculator(debug_labels, debug_data, debug_theta))"
      ],
      "metadata": {
        "id": "sMs0pmFcVo1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "fd9538ef-c8c4-469b-f9df-38b70988b1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "shapes (5,) and (2,274) not aligned: 5 (dim 0) != 2 (dim 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-389106083d6f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# And call the function you defined with the dummy labels and data we made before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_theta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-7f8a1b485321>\u001b[0m in \u001b[0;36mgradient_calculator\u001b[0;34m(y, X_with_bias, theta_vector)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mX_transpose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_transpose\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber_of_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (5,) and (2,274) not aligned: 5 (dim 0) != 2 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you kept the same dummy data we included by default in the notebook, you should get `[ 0.16546829 -0.19307376 -0.15630302]` as the output of your gradient calculator! <font size=+3>üíª</font>"
      ],
      "metadata": {
        "id": "0wc43bGxV-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now write a function that will train a logistic regression algorithm!\n",
        "\n",
        "Your `logistic_regression` function needs to:\n",
        "* Take in a set of training input/output data, validation input/output data, a number of iterations to train for, a set of initial parameters $\\theta$, and a learning rate $\\eta$\n",
        "* At each iteration:\n",
        " * Generate a set of predictions on the training data. Hint: You may use your function `predict` on inputs `X_train` from the training set.\n",
        " * Calculate and store the loss function for the training data at each iteration. Hint: You may use your function `log_loss` on inputs `X_train` and outputs `y_train` from the training set.\n",
        " * Calculate the gradient. Hint: You may use your function `grad_calc`.\n",
        " * Update the $\\theta$ parameters. Hint: You need to implement [this equation](#grad_descent).\n",
        " * Generate a set of predictions on the validation data using the updated parameters. Hint: You may use your function `predict` on inputs `X_valid` from the validation set.\n",
        " * Calculate and store the loss function for the validation data. Hint: You may use your function `log_loss` on inputs `X_valid` and outputs `y_valid` from the validation set.\n",
        " * Bonus: Calculate and store the accuracy of the model on the training and validation data as a metric!\n",
        "* Return the final set of parameters $\\theta$ & the stored training/validation loss function values (and the accuracy, if you did the bonus)\n",
        "\n"
      ],
      "metadata": {
        "id": "PU4A5HVKuAGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q10) Write the `logistic_regression` function**"
      ],
      "metadata": {
        "id": "182qtGB7i_vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint: Pseudocode Snippet\n",
        "\n",
        "'''\n",
        "define logistic_regression(\n",
        "                           X_train,\n",
        "                           y_train,\n",
        "                           X_validation,\n",
        "                           y_validation,\n",
        "                           theta_vector,\n",
        "                           number_of_iterations,\n",
        "                           learning_rate_eta,\n",
        "                          ):\n",
        "  #initialize the list of losses\n",
        "  training_losses = list()\n",
        "  validation_losses = list()\n",
        "\n",
        "  for iteration in range(number_of_iterations):\n",
        "    train_set_predictions = predict(X_train, theta_vector)\n",
        "    train_loss = log_loss(train_set_predictions, y_train)\n",
        "    training_losses.append(train_loss)\n",
        "\n",
        "    gradient = gradient_calculator(y_train, X_train, theta_vector)\n",
        "    theta_vector = theta_vector - gradient * learning_rate_eta\n",
        "\n",
        "    validation_set_predictions = predict(X_validation, theta_vector)\n",
        "    validation_loss = log_loss(validation_set_predictions, y_validation)\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    print(Completed (iteration)/(number_of_iterations)*100%)\n",
        "\n",
        "    return [training_losses, validation_losses], theta\n",
        "''';"
      ],
      "metadata": {
        "id": "eNfODgtZYm2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression(X_train,\n",
        "                        y_train,\n",
        "                        X_validation,\n",
        "                        y_validation,\n",
        "                        theta_vector,\n",
        "                        num_iters,\n",
        "                        number_of_iterations,\n",
        "                        learning_rate_eta\n",
        "                      ):\n",
        "  # Initialize the list of losses\n",
        "  training_losses = list()\n",
        "  validation_losses = list()\n",
        "\n",
        "  # Loop through as many times as defined in the function call\n",
        "  for iteration in range(number_of_iterations):\n",
        "\n",
        "    #--------Training-------\n",
        "    # Get predictions on training dataset\n",
        "    train_set_predictions = predict(X_train, theta_vector)\n",
        "\n",
        "    # Calculate the loss\n",
        "    train_loss = log_loss(train_set_predictions, y_train)\n",
        "\n",
        "    # Add it to the list of training losses to keep track of it\n",
        "    training_losses.append(train_loss)\n",
        "\n",
        "    # Calculate the Gradient\n",
        "    gradient = gradient_calculator(y_train, X_train, theta_vector)\n",
        "\n",
        "    # Find the new value of theta\n",
        "    theta_vector = theta_vector - gradient * learning_rate_eta\n",
        "\n",
        "    #--------Validation-----------\n",
        "    # Get predictions on the validation dataset\n",
        "    validation_set_predictions = predict(X_validation, theta_vector)\n",
        "\n",
        "    # Calculate the validation loss\n",
        "    validation_loss = log_loss(validation_set_predictions, y_validation)\n",
        "\n",
        "    # Add it to the list of validation losses to keep track of it\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    # Progress Indicator\n",
        "    if (iteration/num_iters * 100) % 5 == 0:\n",
        "      print(f'\\rCompleted {(iteration)/(num_iter)*100}%', end='')\n",
        "\n",
        "  print('\\rCompleted 100%')\n",
        "  return [training_losses, validation_losses], theta"
      ],
      "metadata": {
        "id": "HDsR5TxPt-0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬°¬°¬°Important Note!!!**\n",
        "\n",
        "The notebook assumes that you will return\n",
        "1. a Losses list, where Losses[0] is the training loss and Losses[1] is the validation loss\n",
        "2. a tuple with the 3 final coefficients ($\\beta_0$, $\\beta_1$, $\\beta_2$)\n",
        "\n",
        "---------------------"
      ],
      "metadata": {
        "id": "EWMDLk7wFB0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our logistic regression function, we're all set to train our algorithm! Or _are_ we?\n",
        "\n",
        "There's an **important** data step that we've neglected up to this point - we need to **split the data** into the train, validation, and test datasets.\n",
        "\n",
        "<center>train <font size=+3> ‚úÇÔ∏è </font> validation <font size=+3> ‚úÇÔ∏è </font> test</center>"
      ],
      "metadata": {
        "id": "2ep5FQYBmqG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "total_size = len(X_with_bias)\n",
        "\n",
        "test_size = int(total_size * test_ratio)\n",
        "validation_size = int(total_size * validation_ratio)\n",
        "train_size = total_size - test_size - validation_size\n",
        "\n",
        "rnd_indices = rnd_gen.permutation(total_size)\n",
        "\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y.iloc[rnd_indices[:train_size]]\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y.iloc[rnd_indices[train_size:-test_size]]\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y.iloc[rnd_indices[-test_size:]]"
      ],
      "metadata": {
        "id": "CVrXzjYA2iil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready!\n",
        "\n",
        "###**Q11) Train your logistic regression algorithm. We recommend you use 500 iterations, $\\eta$=0.1**\n",
        "\n",
        "*Hint: It's time to use the `logistic_regression` function you defined in Q5.*"
      ],
      "metadata": {
        "id": "33IhRpME8LOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the code\n",
        "losses, coeffs = logistic_regression(X_train,\n",
        "                        y_train,\n",
        "                        X_validation,\n",
        "                        y_validation,\n",
        "                        theta_vector,\n",
        "                        num_iters,\n",
        "                        500,\n",
        "                        0.1\n",
        "                          )"
      ],
      "metadata": {
        "id": "dWAr0ORYEYi2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b6d5e907-5a15-4745-9aad-a0881bdbcf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_validation' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-03863b66acb5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m losses, coeffs = logistic_regression(X_train,\n\u001b[1;32m      3\u001b[0m                         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                         \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                         \u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mtheta_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_validation' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how our model did while learning!"
      ],
      "metadata": {
        "id": "e7WHcpPiEcIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to produce the Loss Function Visualization Graphs\n",
        "fig, ax = plt.subplots(figsize=(9,6), dpi=100)\n",
        "ax.plot(losses[0], color='blue', label='Training', linewidth=3);\n",
        "ax.plot(losses[1], color='black', label='Validation', linewidth=3);\n",
        "ax.legend();\n",
        "ax.set_ylabel('Log Loss')\n",
        "ax.set_xlabel('Iterations')\n",
        "ax.set_title('Loss Function Graph')\n",
        "ax.autoscale(axis='x', tight=True)\n",
        "fig.tight_layout();"
      ],
      "metadata": {
        "id": "T_ImydMTKkfh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "6630fe61-da1f-426a-af58-a546157732c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'losses' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-dd6976351bab>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Run this cell to produce the Loss Function Visualization Graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get predictions from our model for the training, validation, and testing\n",
        "# datasets\n",
        "y_hat_train = (predict(X_train, coeffs)>=.5).astype(int)\n",
        "y_hat_valid = (predict(X_valid, coeffs)>=.5).astype(int)\n",
        "y_hat_test = (predict(X_test, coeffs)>=.5).astype(int)\n",
        "\n",
        "y_sets = [ [y_hat_train, y_train],\n",
        "           [y_hat_valid, y_valid],\n",
        "           [y_hat_test, y_test] ]\n",
        "\n",
        "def accuracy_score(y_hat, y):\n",
        "    assert(y_hat.size==y.size)\n",
        "    return (y_hat == y).sum()/y.size\n",
        "accuracies=[]\n",
        "[accuracies.append(accuracy_score(y_set[0],y_set[1])) for y_set in y_sets]\n",
        "\n",
        "printout= (f'Training Accuracy:{accuracies[0]:.1%} \\n'\n",
        "           f'Validation Accuracy:{accuracies[1]:.1%} \\n'\n",
        "           f'Test Accuracy:{accuracies[2]:.1%} \\n')\n",
        "\n",
        "# Add the testing accuracy only once you're sure that your model works!\n",
        "print(printout)"
      ],
      "metadata": {
        "id": "4wXFzZPjFjOn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "9349a341-82f0-469c-b679-ed748eafba0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'predict' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0f411395ec48>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's get predictions from our model for the training, validation, and testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_hat_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_hat_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_hat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations on training a logistic regression algorithm from scratch!\n",
        "\n",
        "Your loss function graph should look something similar to this...\n",
        "<img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EUqSnwtsU7VEkUul4oqhj6cBy1FIGMsGAfTXTmXQke1N3g?download=1'>\n",
        "\n",
        "And the accuracies we got during development of the notebook are:\n",
        "\n",
        "`Training Accuracy:99.4%`  <br>\n",
        "`Validation Accuracy:100.0%` <br>\n",
        "`Test Accuracy:100.0% `\n",
        "\n",
        "Once you're done with the upcoming environmental science applications notebook, feel free to come back to take a look at the challenges üòÄ"
      ],
      "metadata": {
        "id": "4zfXs8M8Osie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenges\n",
        "\n",
        "* **C1)** Add more features to try to improve our accuracies!\n",
        "\n",
        "* **C2)** Add early stopping to the training algorithm! (e.g., stop training when the accuracy is greater than a target accuracy)"
      ],
      "metadata": {
        "id": "VAa4bzT7PHRG"
      }
    }
  ]
}